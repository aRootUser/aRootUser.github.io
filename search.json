[{"title":"RPC通信机制","url":"/2018/06/05/2018-6-5/","content":"<Excerpt in index | 首页摘要>\n初步实现简单RPC\n<!-- more -->\n\n先简单的说一下流程：客户端和服务端在两个不同的节点上、客户端想要调用远程服务端的方法、通过调用重写后的invoke方法使其获得远程方法的一个返回值、返回的是一个方法、具体见代码\n\n\n```java\n//定义要调用的远程接口名称\n\npublic interface RemoteMethed{\n    String remoteMethed(String name);\n}\n\n\n\n//远程方法实现类\npublic class RemoteMethedImpl implements RemoteMethed {\n    public String remoteMethed(String name) {\n        return \"excute remote methed \" + name;\n    }\n}\n\n\n\n//消息中心的实现类\npublic class ServiceCenterImpl implements ServerCenter{\n    private static ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n\n    private static final HashMap<String, Class> serviceRegistry = new HashMap<String, Class>();\n\n    private static boolean isRunning = false;\n\n    private static int port;\n\n    public ServiceCenterImpl(int port) {\n        this.port = port;\n    }\n\n    public void stop() {\n        isRunning = false;\n        executor.shutdown();\n    }\n\n    public void start() throws IOException {\n        ServerSocket server = new ServerSocket();\n        server.bind(new InetSocketAddress(port));\n        System.out.println(\"start server\");\n        try {\n            while (true) {\n                // 1.监听客户端的TCP连接，接到TCP连接后将其封装成task，由线程池执行\n                executor.execute(new ServiceTask(server.accept()));\n            }\n        } finally {\n                server.close();\n        }\n    }\n   \n    public void register(Class serviceInterface, Class impl) {\n        //map<string,class>+添加接口的全限定名和对应的子类的字节码文件\n        serviceRegistry.put(serviceInterface.getName(), impl);\n    }\n\n    public boolean isRunning() {\n        return isRunning;\n    }\n\n    public int getPort() {\n        return port;\n    }\n\n    private static class ServiceTask implements Runnable {\n        Socket clent = null;\n        public ServiceTask(Socket client) {\n            this.clent = client;\n        }\n\n        public void run() {\n            ObjectInputStream input = null;\n            ObjectOutputStream output = null;\n            try {\n                // 2.将客户端发送的码流反序列化成对象，反射调用服务实现者，获取执行结果\n                input = new ObjectInputStream(clent.getInputStream());\n                String serviceName = input.readUTF();\n                String methodName = input.readUTF();\n                //Class<?>它是个通配泛型，?可以代表任何类型\n                //getClass，利用这个方法就可以获得一个实例的类型类。类型类指的是代表一个类型的类\n                Class<?>[] parameterTypes = (Class<?>[]) input.readObject();\n                Object[] arguments = (Object[]) input.readObject();\n                Class serviceClass = serviceRegistry.get(serviceName);\n                if (serviceClass == null) {\n                    throw new ClassNotFoundException(serviceName + \" not found\");\n                }\n                //获得methodName方法，方法参数为parameterTypes\n                //表示方法的对象数组\n                Method method = serviceClass.getMethod(methodName, parameterTypes);\n                //向上转型只能够调用子类重写的方法，子类独有的方法在父类中根本没有定义，所以父类无法找到子类独有的方法\n                Object result = method.invoke(serviceClass.newInstance(), arguments);\n                Class a=int.class;\n                a.getConstructors();\n                // 3.将执行结果反序列化，通过socket发送给客户端\n                output = new ObjectOutputStream(clent.getOutputStream());\n                output.writeObject(result);\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                if (output != null) {\n                    try {\n                        output.close();\n                    } catch (IOException e) {\n                        e.printStackTrace();\n                    }\n                }\n                if (input != null) {\n                    try {\n                        input.close();\n                    } catch (IOException e) {\n                        e.printStackTrace();\n                    }\n                }\n                if (clent != null) {\n                    try {\n                        clent.close();\n                    } catch (IOException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n\n        }\n    }\n}\n\n\n//定义客户端代理类\npublic class RPCClient <T>{\n    //<T>T相当于返回任意类型 代理哪个类就把哪个类的类加载器放进去\n    //在实例化泛型类时，必须指定T的具体类型\n    public static <T> T getRemoteProxyObj( Class<?> serviceInterface, final InetSocketAddress addr) {\n        // 1.将本地的接口调用转换成JDK的动态代理，在动态代理中实现接口的远程调用\n        //返回动态代理的接口\n        //把接口传进去、通过proxy代理再次访问接口方法时会调用对应的invoke方法\n        return (T) Proxy.newProxyInstance(serviceInterface.getClassLoader(), new Class<?>[]{serviceInterface},\n                new InvocationHandler() {\n                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                        Socket socket = null;\n                        ObjectOutputStream output = null;\n                        ObjectInputStream input = null;\n                        try {\n                            // 2.创建Socket客户端，根据指定地址连接远程服务提供者\n                            socket = new Socket();\n                            socket.connect(addr);\n                            // 3.将远程服务调用所需的接口类、方法名、参数列表等编码后发送给服务提供者\n                            output = new ObjectOutputStream(socket.getOutputStream());\n                            output.writeUTF(serviceInterface.getName());\n                            output.writeUTF(method.getName());\n                            output.writeObject(method.getParameterTypes());\n                            output.writeObject(args);\n                            // 4.同步阻塞等待服务器返回应答，获取应答后返回\n                            input = new ObjectInputStream(socket.getInputStream());\n                            //返回接口中的方法\n                            return input.readObject();\n                        } finally {\n                            if (socket != null) socket.close();\n                            if (output != null) output.close();\n                            if (input != null) input.close();\n                        }\n                    }\n                });\n    }\n}\n\n\n```\n进一步扩展：注册中心用zookeeper来实现、用netty来实现进程间的通信、任重而道远啊、、\n\n\n\n\n\n\n\n","tags":["java"],"categories":["大数据"]},{"title":"安全检测","url":"/2018/05/03/2018-5-3 /","content":"<Excerpt in index | 首页摘要>\n某比赛要求在施工通过监控对没带安全帽的人进行报警\n<!-- more -->\n先吐槽一下比赛的主办方、给的测试视屏画质极低拍摄极为敷衍、有些人连人眼都无法识别是否带了安全帽、这小小的比赛大概整了整个51假期吧、\n## 简单介绍\n这里主要提供一下思路、传统ssd(高配电脑fater-rcnn走起)+inception3、你可能会问为什么不直接用ssd进行二次训练就好了、我当初也是这么想的这不是很简单么、\n然后我先把视频一帧帧的读取并转化成图像然后手动lable(这里有个问题就是一个图像中有多个人这样训练的时候会不会造成无法收敛？我觉得会有很大的影响)、\n然后训练这个像打了码一样的图片(再次吐槽一下主办方)、结果连人都识别不出来！！！内心极度奔溃、然后就用了独创非主流方法\n## 具体步骤(非主流方法请勿模仿、)\n鉴于之前连人都识别出来的问题、我就直接调用ssd先去除人、然后对有戴和没戴安全帽的进行训练(通过inception3)、然后运行通过ssd的目标检测结果输入到inception3中进行判别\n判别的结果传给之前的显示字符串然后进行输出、下面附上源码(目录与object_detection一致)\n\n```python\n#视频的读取得到识别物体后显示出来\nimport os\nimport cv2\nimport time\nimport numpy as np\nimport tensorflow as tf\n\nfrom utils.app_utils import FPS\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_util\n\nCWD_PATH = os.getcwd()\n\nMODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\nPATH_TO_CKPT = os.path.join(CWD_PATH, 'object_detection', MODEL_NAME, 'frozen_inference_graph.pb')\nPATH_TO_LABELS = os.path.join(CWD_PATH, 'object_detection', 'data', 'mscoco_label_map.pbtxt')\n\nNUM_CLASSES = 2\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,\n                                                            use_display_name=True)\n\ncategory_index = label_map_util.create_category_index(categories)\n\ndef detect_objects(image_np, sess, detection_graph):\n    # 增加输入图像的维度: [1, None, None, 3]\n    image_np_expanded = np.expand_dims(image_np, axis=0)\n    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n    # 得到检测框\n    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n    #得到他的得分\n    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n    # Actual detection.\n    # 这里的class是包含多个识别种类的二维数组\n    #[[100,4]]boxes 每个框的位置坐标,    scores 100个 ,     classes 100个 ,    num_detections 100个\n    (boxes, scores, classes, num_detections) = sess.run(\n        [boxes, scores, classes, num_detections],\n        feed_dict={image_tensor: image_np_expanded})\n    # Visualization of the results of a detection.\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        image_np,\n        np.squeeze(boxes),\n        np.squeeze(classes).astype(np.int32),\n        np.squeeze(scores),\n        category_index,\n        use_normalized_coordinates=True,\n        line_thickness=4,\n        min_score_thresh=0.5)\n    return image_np\n\nif __name__ == '__main__':\n    detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    sess = tf.Session(graph=detection_graph)\n    video_capture = cv2.VideoCapture('b.mp4')\n    fps = FPS().start()\n    frame_width = int(video_capture.get(3))\n    frame_height = int(video_capture.get(4))\n    # define video output\n    out = cv2.VideoWriter('outpy.mp4', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n    count = 0\n    while video_capture.isOpened():\n        ret, frame = video_capture.read()\n        t = time.time()\n        detected_image = detect_objects(frame, sess, detection_graph)\n        fps.update()\n        cv2.imshow('Video', detected_image)\n\t\t#本来想来做个更加流畅的优化、就是格一个帧进行识别、但还是会阻塞\n        #if count % 100 == 0:\n        #    print(count)\n        # write to video file\n        #out.write(detected_image)\n        # print('[INFO] elapsed time: {:.2f}'.format(time.time() - t))\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n    fps.stop()\n    video_capture.release()\n    sess.close()\n    cv2.destroyAllWindows()\n\n```\n```python\n#visualization_untils\n#第160行进行如下修改、check为inception3的入口、将图片和坐标传入\n  if use_normalized_coordinates:\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                  ymin * im_height, ymax * im_height)\n    \n    name=check(image.copy(), left, right, top, bottom)\n\t\n\t\n##188 行处\t\n#name为全局变量、接受inception3识别结果的字符串\ndraw.text(\n        (left + margin, text_bottom - text_height - margin),\n        name,\n        fill='black',\n        font=font)\n\n```\n\n```python\n\n#check模块、inception3的入口\nimport tensorflow as tf\nimport numpy as np\nfrom pylab import array\n\ndef check(image,left, right, top, bottom):\n    got = array(image)\n    crop_img = got[int(top):int(bottom), int(left):int(right), 0:3]\n\t#载入之前自己训练的模型\n    with tf.gfile.FastGFile('output_graph.pb', 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        tf.import_graph_def(graph_def, name='')\n\n    with tf.Session() as sess:\n        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n\t\t#将传入的图片格式转化一下\n        first = tf.image.convert_image_dtype(crop_img, dtype=tf.float32)\n        # jpeg 进行编码\n        # eval()想当于将tensorflow的存储格式中提取出来以数组的格式\n        encode = tf.image.encode_jpeg(first.eval())\n        #将编码好的图片传入以decodejpeg的格式\n        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': encode.eval()})  # 图片格式是jpeg格式\n        predictions = np.squeeze(predictions)  # 把结果转为1维数据\n        top_k = predictions.argsort()[::-1]\n        if top_k[0]==1:\n            human_string=\"unsafe\"\n        else:\n            human_string=\"safe\"\n        return human_string\n        #返回给画框的代码\n```\n\n## 总结\n看似十分完美流程的过程在实际运行时由于笔记本配置低下(好想要GPU的台式机！！)、换了一台配置稍微高一点的本、但还是崩了、tensorflow开两个session的内存消耗比想象中的要大、开\n看来这操作只能是活在梦里了、希望以后能想出一种底层之间的优化(相比之前的已经做了很多IO的优化、但主要问题还是这是线性的操作、一定有卡顿来进行二次判断)\n\n## 更新！！！\n终于找到了问题所在！！原来每一帧的图像传入后都要重新加载一次graph！！所以导致内存直接爆炸！改动后可以跑的动了、但比较吃配置配置高一点的话可以更加流畅吧、\n具体改动如下、其余的改动就是要在每个调用的visualization_utils中的函数里传入初始化的graph、具体修改如下、整个项目会放到github上\n\n```python\n#主要是对main函数下的修改vediondetection.py\n\nif __name__ == '__main__':\n    #tf.Graph()生成新的图\n    detection_graph = tf.Graph()\n    inceptionsess =tf.Graph()\n    with inceptionsess.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.FastGFile('output_graph.pb', 'rb') as f:\n            serialized_graph = f.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n\n    with detection_graph.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    sess = tf.Session(graph=detection_graph)\n    video_capture = cv2.VideoCapture('b.mp4')\n    fps = FPS().start()\n    frame_width = int(video_capture.get(3))\n    frame_height = int(video_capture.get(4))\n    # define video output\n    out = cv2.VideoWriter('outpy.mp4', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n    count = 0\n    while video_capture.isOpened():\n        ret, frame = video_capture.read()\n        t = time.time()\n        detected_image = detect_objects(frame, sess, detection_graph,inceptionsess)\n        fps.update()\n        out.write(detected_image)\n        cv2.imshow('Video', detected_image)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    fps.stop()\n    video_capture.release()\n    sess.close()\n    cv2.destroyAllWindows()\n```\n\n\n```python\n#对checker类的方法进行的改动\n\ndef check(image,left, right, top, bottom,inceptionsess):\n    got = array(image)\n    crop_img = got[int(top):int(bottom), int(left):int(right), 0:3]\n    # with tf.gfile.FastGFile('output_graph.pb', 'rb') as f:\n    #     graph_def = tf.GraphDef()\n    #     graph_def.ParseFromString(f.read())\n    #     tf.import_graph_def(graph_def, name='')\n    with tf.Session(graph=inceptionsess) as sess:\n        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n        # jpeg 进行编码\n        # \"\"\"Return the value of the tensor represented by this handle.\"\"\n        encode = tf.image.encode_jpeg(crop_img)\n        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': encode.eval()})  # 图片格式是jpg格式\n        predictions = np.squeeze(predictions)  # 把结果转为1维数据\n        top_k = predictions.argsort()[::-1]\n        if top_k[0]==1:\n            human_string=\"unsafe\"\n        else:\n            human_string=\"safe\"\n        return human_string\n\n```\n\n","tags":["图像识别"],"categories":["深度学习"]},{"title":"定点识别","url":"/2018/04/08/2018-4-8/","content":"<Excerpt in index | 首页摘要>\n基于object_detection训练自己的模型\n<!-- more -->\n花了不知道多少天、、主要参加一个定点识别的比赛、算是把模型搞定了、虽然结果十分的令人喜感（哈哈、不说了）、、难度有一点大（主要是各种天坑、在这里记录一下）\n\n这是阿里天池的比赛、比赛给出上万张图片主要是服装、要在每个图片上识别出服装每个关键点、并将识别结果的坐标输出、比如左袖口什么的、差不多有24个标签吧、训练集给出的是每个图片的所有关键点的坐标、我的思路是先根据坐标\n转化成矩形框(同时对x和y加上自己定义的距离数)、然后通过object_detection确定定位的位置、最后在进行输出(求两个x和两个y的平均来得到中心点)、具体步骤如下：\n\n## 根据lable切分图片\n\n这个脚本主要是根据lable对图片进行切分、根据lable创建若干个文件夹、切好的图片放到每个对应的文件加下、切分完得到几十万张图片(此刻的内心是奔溃的)、\n```python\nimport csv\nimport cv2\nimport os\n\npath=os.getcwd()\n#自己定义框的宽度wide\ndef drawcnts_and_cut(original_img,x,y,wide):\n    x1=x-wide\n    x2=x+wide\n    y1=y-wide\n    y2=y+wide\n    crop_img = original_img[y1:y2, x1:x2]\n    return  crop_img\n\ndef start(img_path,save_path,x,y):\n    original_img= cv2.imread(img_path)\n    crop_img = drawcnts_and_cut(original_img,int(x),int(y),25)\n    cv2.imwrite(save_path, crop_img)\ndef datatranslate(data):\n    splited=str(data).split()\n    return splited[0],splited[1]\n\t\n#自己根据标签数量来改\nlable=['class1', 'class2']\t\ncsv_reader = csv.reader(open('train\\\\input.csv', encoding='utf-8'))\nnum=0\nfor row in csv_reader:\n    for i in range(2,26,1):\n        photo=row[0]\n        data=row[i]\n        category=lable[i]\n        splited = str(row[i]).split(\"_\")\n        print(photo)\n        print(num)\n        if int(splited[0])!=-1:\n            lib = path + \"\\\\train\\\\\"+photo\n            savepath=path+\"\\\\output\\\\\"+str(category)+\"\\\\\"+str(category)+\"+\"+str(num)+\".jpg\"\n            num+=1\n            start(lib,savepath,splited[0],splited[1])\n\t\t\t\n```\n\n\n## 将图片转化为对应的xml文件\n\n默认的边框大小为整个图片的d、长度和宽度可以从图片中获取、最终批量的生成xml文件（突然想起比赛的图片切分后生成的30万个文件、还只能分批次的复制、一复制就卡屏、迷醉、、）\n```python\nimport os, sys\nimport glob\nfrom PIL import Image\n\n#根据实际来添加class\nlist=[\"class1\",\"class2\"]\nfor a in list:\n    path=os.getcwd()\n    #图像存储位置\n    src_img_dir = path+\"\\\\input2\\\\\"+a\n    # xml文件存放位置\n    src_xml_dir = path+\"\\\\input2\\\\\"+a\n    img_Lists = glob.glob(src_img_dir + '\\*.jpg')\n    img_basenames = [] \n    for item in img_Lists:\n        img_basenames.append(os.path.basename(item))\n    img_names = [] \n    for item in img_basenames:\n        temp1, temp2 = os.path.splitext(item)\n        img_names.append(temp1)\n    for img in img_names:\n        im = Image.open((src_img_dir + '/' + img + '.jpg'))\n        width, height = im.size\n        xml_file = open((src_xml_dir + '/' + img + '.xml'), 'w')\n        xml_file.write('<annotation>\\n')\n        xml_file.write('    <folder>'+a+'</folder>\\n')\n        xml_file.write('    <filename>' + str(img) + '.jpg' + '</filename>\\n')\n        xml_file.write('    <path>' + path +\"\\\\input2\\\\\"+a+\"\\\\\"+ str(img) + '.jpg'+ '</path>\\n')\n        xml_file.write('    <size>\\n')\n        xml_file.write('        <width>' + str(width) + '</width>\\n')\n        xml_file.write('        <height>' + str(height) + '</height>\\n')\n        xml_file.write('        <depth>3</depth>\\n')\n        xml_file.write('    </size>\\n')\n        xml_file.write('        <segmented>0</segmented>\\n')\n        xml_file.write('    <object>\\n')\n        xml_file.write('        <name>' + str(img) + '</name>\\n')\n        xml_file.write('        <pose>Unspecified</pose>\\n')\n        xml_file.write('        <truncated>1</truncated>\\n')\n        xml_file.write('        <difficult>0</difficult>\\n')\n        xml_file.write('        <bndbox>\\n')\n        xml_file.write('            <xmin>' + \"0\" + '</xmin>\\n')\n        xml_file.write('            <ymin>' + \"0\" + '</ymin>\\n')\n        xml_file.write('            <xmax>' + str(width) + '</xmax>\\n')\n        xml_file.write('            <ymax>' + str(height) + '</ymax>\\n')\n        xml_file.write('        </bndbox>\\n')\n        xml_file.write('    </object>\\n')\n        xml_file.write('</annotation>')\n\t\t\n```\n##\txml转csv文件合并csv文件\n\n要使用如下脚本将xml文件转化为csv文件、最后再把每个目录下的csv文件进行合并（注意删除重复的lable）\n\n```python\n#xml转csv文件合并csv文件\n\nimport os\nimport glob\nimport pandas as pd\nimport xml.etree.ElementTree as ET\ntag=['class1','class2']\nnum=0\n\ndef xml_to_csv(path):\n    xml_list = []\n    for xml_file in glob.glob(path + '/*.xml'):\n        tree = ET.parse(xml_file)\n        root = tree.getroot()\n        for member in root.findall('object'):\n            value = (root.find('filename').text,\n                     int(root.find('size')[0].text),\n                     int(root.find('size')[1].text),\n                     root.find('folder').text,\n                     int(member[4][0].text),\n                     int(member[4][1].text),\n                     int(member[4][2].text),\n                     int(member[4][3].text)\n                     )\n            xml_list.append(value)\n    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n    xml_df = pd.DataFrame(xml_list, columns=column_name)\n    return xml_df\n\n\ndef main():\n    for a in tag:\n        image_path = os.path.join(os.getcwd(), 'input2\\\\'+a)\n        xml_df = xml_to_csv(image_path)\n        xml_df.to_csv('data\\\\'+str(a)+'.csv',index=None)\n        print('Successfully converted xml to csv.')\n\n\nmain()\n```\n通过shell批量合并csv\n```shell\n@echo off\nE:\ncd add\ndir\ncopy *.csv all_keywords.csv\necho 合并成功！'\npause\n```\n\n## 调用object_detection前的准备\n\n下面是很有参考性的博客和官方的地址\n[https://blog.csdn.net/honk2012/article/details/79099651](https://blog.csdn.net/honk2012/article/details/79099651)\n[https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)\n可以翻墙的话推荐下面这篇、这个towardsdatascience还是很不错的\n[https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9)\n基本后面的训练和模型的调用都是在github上的、想普通的个人电脑用ssd的一个mobile就行了、别的根本跑不动、batch设置的越大每次迭代的时间越长、如果太大电脑配置不够的话你就可以重新开机了、、\n顺便说说几个坑官方步骤中的 protoc object_detection/protos/*.proto --python_out=. 如果是在window下要下载3.4版本的3.5会有bug\nobject_detection初始化一定要先执行、不然会给你各种报错、、\n官方文档中export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim  如果是windows下执行要用这个命令(查了很久用了很多的坑爹方法、只能说项目对windows不友好)SET PYTHONPATH=%cd%;%cd%\\slim  执行目录还是不变\n注意这几个坑基本就会很顺畅了、还有一些其他小坑一时想不起来、想到了再加、\n\n\n\n\n\n","tags":["图像识别"],"categories":["深度学习"]},{"title":"博客搬家","url":"/2018/03/23/2018-3-23/","content":"<Excerpt in index | 首页摘要>\n无意间看到了Hexo的这个黑蓝主题、实在是太cool了！！抽空用了两个晚上搬家\n<!-- more -->\n原来的博客一直是用的是jekyll(差点又拼错、)、还是很方便不过还是有很多弊端\n\n1、代码高亮、现在看看原来的博客这代码高亮、、简直无法直视、虽然后来另外装了插件但还是惨不忍睹(主要是这个主题的高亮真的是太漂亮了、看了会上瘾、、)\n2、由于原来的博客用的是老外的主题为了实现想要的效果文字间的空格符有点受不了、十分影响美观、还有字体(这里支持一下国产、、)\n3、这个主题有分类功能、随着博客的增多查找也比原来的方便、\n4、也是主要原因、、就是想换、笑死、、、\n\n现在终于换好了、过程也十分折腾、也遇到了各种坑、什么Hexo的版本问题、server要独立安装、、、希望这博客可以用几年吧、、同时再次感谢maochunguang提供的主题\n\n前端真的是一个十分神奇的东西、、但真的没工夫投在上面学了、还有评论功能、看了大佬的主题demo觉得加了评论就不是十分洁简了、于是就不做了（绝不是因为懒）、、\n\n最后注意我的背景:它是会变的哦、、、\n","tags":["other"],"categories":["other"]},{"title":"基于卷积的图片识别","url":"/2018/03/21/2018-3-22/","content":"<Excerpt in index | 首页摘要>\n这篇博客主要介绍通过Tesorflow来实现对图片的识别\n<!-- more -->\n\n学习深度学习断断续续也将近半年了、从去年暑假接触tensorflow一步步从入门到放弃、又继续现在才算明白每一步做的是什么、本来想深入研究词向量分析做一个在线翻译的小项目和属于自己的siri（这一定非常cool）、在导师的建议下先从图像识别做起、语义模型的确太复杂了只能怪中国语言博大精深（笑死、、）可能做了一两年最终的结果将会出乎意料的喜感、不得不赞叹一下油管、、在线翻译实在是太强大了要是哪天能在谷歌工作就好了、不知不觉敲了好多废话、该写总结了\n以下是写的很详细详细的链接、看不懂的可以再细细的看这个链接看个权重的动态图就行了、绝对精髓\n[https://www.2cto.com/kf/201607/522441.html](https://www.2cto.com/kf/201607/522441.html)\n\n首先从输入的图片开始、mnist是28x28的单颜色通道的图片、训练时读取的是[batchsize,784]的数组、要转化为tensorflow卷积支持的输入格式[batchsize,28,28,1]、第二、三个表示几乘几的图片、最后一个表示颜色通道、这里为1因为是灰度图、接下来定义卷积的权重、就是你要定义一个移动的的过滤器来扫描这个图片以及若干个内核来存储扫描器与图片权值相乘再加上偏置值的一个结果、最终就可以得到卷积层的输出、需要定义的参数参考这篇博客十分的详细\n[https://www.cnblogs.com/qggg/p/6832342.html](https://www.cnblogs.com/qggg/p/6832342.html)\n\n卷积层得到输入后将其导入池化层、池化层大大减小了变量的个数（真的十分敬佩模型的创始人、真的太厉害了）、池化层也有类似的过滤器如果用的是max_pool相当于扫描一个区域、选出区域中最大的一个值输出、按照步长移动再扫描输出、从而最终达到简化参数的目的、池化层输出后将结果导入全连结层、然后就是固定的套路了、\n\n具体代码如下\n```python\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n\nmnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)\nbatch_size=100\nn_batch=mnist.train.num_examples//batch_size\n\n\ndef weight_init(shape):\n    init=tf.truncated_normal(shape=shape,stddev=0.1)\n    return tf.Variable(init)\n\ndef bias_init(shape):\n    init=tf.constant(0.1,shape=shape)\n    return  tf.Variable(init)\n\ndef conv2d(input,w):\n    return tf.nn.conv2d(input,w,strides=[1,1,1,1],padding='SAME')\n\ndef pool(input):\n    return tf.nn.max_pool(input,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n\nx=tf.placeholder(tf.float32,[None,784])\ny=tf.placeholder(tf.float32,[None,10])\n#全0填充从一开始移动\ninput=tf.reshape(x,[-1,28,28,1])\n#定义卷积的深度为32\n#第一层卷积的输入[128,28,28,1]\nw_conv1=weight_init([5,5,1,16])\nb_conv1=weight_init([16])\n#定义的是same有0来填充每次管道的核心将会一次经过每个像素点\nconv1=tf.nn.relu(conv2d(input,w_conv1)+b_conv1)\n#第一层卷积输出[128,28,28,16]\n\n#池化层只在指定的2，3维度上进行池化\n#得到池化层的输出[128,14,14,16]\npool1=pool(conv1)\n\n#对应池化层的输出所以第三位为32此处定义深度为64\nw_conv2=weight_init([5,5,16,64])\nb_conv2=weight_init([64])\n\n#卷积的输出[128,14,14,64]\nconv2=tf.nn.relu(conv2d(pool1,w_conv2)+b_conv2)\n#得到池化的最终输出[128,7,7,64]\npool2=pool(conv2)\n\n#定义全连结层的权重\nweight=weight_init([7*7*64,500])\nbias=bias_init([500])\n\nnormal=tf.reshape(pool2,[-1,7*7*64])\n#[-1,1024]\noutput1=tf.nn.relu(tf.matmul(normal,weight)+bias)\nkeep=tf.placeholder(tf.float32)\n#定义dropout防止过拟合对提高准确率有很大的帮助\ndrop=tf.nn.dropout(output1,keep)\n\nweight2=weight_init([500,10])\nbias2=bias_init([10])\n#最终得到的输出数组的每一个权值不一定是0，1、Softmax然后会正则化这些权重值、使它们的总和等于1、以此构造一个有效的概率分布\nprediction=tf.nn.softmax(tf.matmul(drop,weight2)+bias2)\n\ncross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n#这里用AdamOptimizer的效果要比梯度下降要好\ntrain_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction=tf.equal(tf.arg_max(prediction,1),tf.arg_max(y,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(100):\n        for batch in range(50):\n            batch_xs,batch_ys =mnist.train.next_batch(batch_size)\n            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep:0.7})\n        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep:1.0})\n        print('iter'+str(epoch)+\"  correct \"+str(acc))\n    input_image = mnist.train.images[11:12]\n    # 可视化卷积层学习到的特征\n    # 输入一张图片\n    cnn1=sess.run(w_conv1, feed_dict={x:input_image})\n    conv1_reshape = sess.run(tf.reshape(cnn1, [5, 5, 1, 16]))\n    plt.figure()\n    # 放在两行两列第一个位置#将舍去数组的后两位\n    plt.subplot(2, 2, 1)\n    # 将舍去数组的后两位\n    plt.imshow(conv1_reshape[:,:,0,0])\n    plt.title('Conv1 16x28x28')\n    plt.show()\n\n```\n## 参数的计算\n假设N*N为输入图像的size、F*F是filter(卷积核)的size、stride(即卷积核每次移动的像素)是滑动的步长。\n那么一次卷积之后输出的第一个维度为(N-F)/stride +1\n\n下面是一篇关于交叉熵的问题的博客\n[http://blog.csdn.net/john_xyz/article/details/61211422](http://blog.csdn.net/john_xyz/article/details/61211422)\n笔记本配置比较一般、渴望gpu来拯救、由于训练的比较慢又要不断调整参数最终准确率在97%以上是没问题的\n## 图像识别\n一般做图像识别用到的模型在github上都开源出来了、比如inception3就有基于Tensorflow的了、用inception3训练自己模型时卷积层的参数大致是不变的改变的是顶部神经元的参数\n前面的操作差不多做的是特征提取、所以用自己的数据训练后得到的结果还是不错的、\n下面是谷歌物体识别的连接、下面的模型可以拿来直接用不用自己一层一层搭网络、里面也有已经训练好的模型(当自己想要做点什么的时候谷歌都做好了、、、)\n[https://github.com/tensorflow/models/tree/master/research/object_detection](https://github.com/tensorflow/models/tree/master/research/object_detection)\n环境搭建推荐linux、windows的坑太多浪费了好长时间、官方给的教程十分精辟、要注意每次敲命令行要严格！！！对应注释中给的目录\n最后还可以训练自己的数据集、教程官方github上也有、网上的教程也十分多参照一下就好了（不想再做验证性工作了）、、\n","tags":["cnn"],"categories":["深度学习"]},{"title":"Java Future","url":"/2018/02/22/2018-2-22/","content":"<Excerpt in index | 首页摘要>\n这篇博客主要简单介绍future模式的原理\n<!-- more -->\n**future模式的作用:** 在多线程开发中、当客户端通过发送一个请求去得到某个资源、服务端异步的在后台另起 一个线程去获取资源、而客户端无需一直等待取资源的过程、仍然可以做其他的事情、具体的过程图如下\n<img src=\"http://aRootUser.github.io/img/8/1.png\">\n**具体代码实现过程：** 定义Data接口、Realdata和futuredata都要实现这个接口、在futureClient中定义main方法、首先调用FutureClient中的call\n方法(通过wait等待被唤醒)、另起一个线程(在这个线程中装载realdata、在realdata中延迟5秒来模拟数据查询)、当数据查询完毕后装载数据\n在FutureData的setRealdata中来通过notify唤醒之前wait的方法最终得到查询结果、\n```java\n\npublic interface Data {\n\tString call();\n}\n\npublic class FutureClient{\n\tpublic static void main(String[] args) {\n\t\tFutureClient fc=new FutureClient();\n\t\t//返回futuredata、调用call方法\n\t\tData data=fc.call(\"8888\");\n\t\tSystem.out.println(\"请求成功做其他事\");\n\t\tString result=data.call();\n\t\tSystem.out.println(\"查询结果为\"+result);\n\t}\n//返回一个接口\n\tpublic Data call(String a) {\n\t\tFutureData fd=new FutureData();\n\t\tnew Thread(new Runnable() {\n\t\t\tpublic void run() {\n\t\t\t\tRealData rd=new RealData(a);\n\t\t\t\tfd.setRealdata(rd);\n\t\t\t}\n\t\t}).start();\n\t\tSystem.out.println(\"返回futuredata对象\");\n\t\treturn fd;\n\t}\n}\n\n\npublic class RealData implements Data{\n\tString result;\n\t//构造方法来实现查询\n\tpublic RealData(String realdata) {\n\t\tSystem.out.println(\"查询号码\"+realdata);\n\t\ttry {\n\t\t\tThread.sleep(5000);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(\"查询完毕\");\n\t\tresult=\"1\";\n\t}\n\tpublic String call(){\n\t\treturn result;\n\t}\n\n}\n\n\npublic class FutureData implements Data{\n\tString data;\n\tRealData realdata;\n\tboolean isready=false;\n\tpublic synchronized void setRealdata(RealData realData){\n\t\tif(isready){\n\t\t\treturn;\n\t\t}\n\t\t//如果没装载进行装载真实对象\n\t\tthis.realdata=realData;\n\t\tisready=true;\n\t\tnotify();\n\t\tSystem.out.println(\"唤醒另一个线程\");\n\t}\n\tpublic  synchronized String call() {\n\t\twhile(!isready) {\n\t\t\ttry {\n\t\t\t\tSystem.out.println(\"futuredata.call\");\n\t\t\t\twait();\n\t\t\t\tSystem.out.println(\"线程已被唤醒\");\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\treturn this.realdata.call();\n\t}\n}\n\n//运行结果如下\n//返回futuredata对象\n//请求成功做其他事\n//查询号码8888\n//查询完毕\n//唤醒另一个线程\n//线程已被唤醒\n//查询结果为1\n\n```\n\n\n\n\n\n\n\n\n","categories":["大数据"]},{"title":"Lstm入门","url":"/2018/02/10/2018-2-10/","content":"<Excerpt in index | 首页摘要>\nlstm来实现手写数字识别\n<!-- more -->\n\n## lstm 简 介\nlstm的设计解决了传统RNN对于长期时间依赖的局限性、通过训练遗忘门来决定丢弃没有用的信息、记忆门来更新lstm的状态并把状态传递给下一个lstm、每个lstm的输入包括上一个lstm的输出和状态、更多细节参考下面的博客\n[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n## lstm实现手写数字识别的基本步骤(基于tensorflow)\n由于输入的是(28,28,batchsize)的三维的数据、所以要对其进行切分将其转换成(28*batchsize,28)二维的数据然后再一行一行的将其输入值lstm、lstm内部的具体实现tensorflow内部已经封装好了只用初始化和定义遗忘率、最后lstm的最后一个输出进行softmax归一化、\n梯度下降来迭代参数从而使模型达到较高的准确率、下面的代码可以达到97%左右的准确率\n基于tensorflow的python实现\n```python\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\n\nmnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n#设置每次训练批次数\nbatchsize=128\n\nweights=tf.Variable(tf.random_normal([28,10]))\nbases=tf.Variable(tf.random_normal([10]))\ndef setrnn(input):\n    #将输入转化为(128batches*18steps,28input)[1,0,2]表示交换的序列\n    input=tf.transpose(input,[1,0,2])\n\t#将数据转化为二维度第二维为28\n    input=tf.reshape(input,[-1,28])\n\t#将每一个图片按照行进行切分一共28行\n    split=tf.split(input,28,0)\n    lstm=tf.nn.rnn_cell.BasicLSTMCell(28,forget_bias=0.1,state_is_tuple=True)\n    output,state=tf.nn.static_rnn(lstm,split,dtype=tf.float32)\n    result=tf.matmul(output[-1],weights)+bases\n    return  result\n\nx=tf.placeholder(\"float\",[None,28,28])\ny=tf.placeholder(\"float\",[None,10])\nRnn=setrnn(x)\npredit=Rnn\nloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predit,labels=y))\noptm=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n#计算准确率\ncorrecrresult=tf.equal(tf.argmax(y,1),tf.argmax(predit,1))\ncorrectmean=tf.reduce_mean((tf.cast(correcrresult,tf.float32)))\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\t#一共进行多少次迭代\n    for a in range(900):\n\t    #一次跌代的图片数量\n        total=1000\n        for i in range(total):\n            batch_x ,batchy=mnist.train.next_batch(batchsize)\n            batchx=batch_x.reshape((batchsize,28,28))\n            sess.run(optm,feed_dict={x:batchx,y:batchy})\n            if i==1:\n                print(a,sess.run(loss,feed_dict={x:batchx,y:batchy}),sess.run(correctmean,feed_dict={x:batchx,y:batchy}))\n\n```\n\n\n\n\n\n\n\n\n\n","tags":["tensorflow"],"categories":["深度学习"]},{"title":"K-近邻算法Python实现","url":"/2018/01/30/2018-1-30/","content":"<Excerpt in index | 首页摘要>\n运用python通过计算距离来实现对某花的分类\n<!-- more -->\n## 算法解决的问题\n已知样本集（此处的样本为某花的实例数据）、给定一未知样本的数据来断此样本的类别(此处为判断属于哪一类花）\n## 解决步骤\n特征抽取后计算出未知样本到所有已知样本的距离、根据给定参数K（最好为奇数便于投票）选出K个最近的样本点、统计出类别最多的样本点的类别、最终的的分类就是该类别\n缺陷：数据的分布不均匀会导致结果的不准确\n优化方法：根据距离的远近添加相应的权重来弱化数据分布不均匀的为题（下面代码还没实现权重的添加、、以后有空再加、、、）\n个人脑洞：对于多维的数据、在二维分布上可能看不出任何规律、但在高维的空间中明显的可以分开好几个类别（如本例的某花数据在三维下就很明显了、还有支持向量机的划分方法太cool了）\n此处的样本集（非常nice的数据集大全）\n[http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)\n样本集示例：前四列为花的数据、最后为花的类别\n\n5.1,3.5,1.4,0.2,Iris-setosa\n\n5.0,3.3,1.4,0.2,Iris-setosa\n\n7.0,3.2,4.7,1.4,Iris-versicolor\n\n4.6,3.1,1.5,0.2,Iris-setosa\n\n6.4,3.2,5.3,2.3,Iris-virginica\n\n6.9,3.2,5.7,2.3,Iris-virginica\n\n4.6,3.4,1.4,0.3,Iris-setosa\n\n代码实现如下：用测试集测试可以达到96%的准确率\n\n```python\n\nimport csv\nimport math\nfrom collections import Counter\n\n#导入样本集list\n#导入测试集计算测试集到每个样本集的距离,结果保存为list\n#根据distance排名取k个投票选出最多的这个类\n\n\n#传递时要第二个参数要为空参否则会共用同一个地址\ndef readfile(local):\n    dataset=[]\n    with open(local) as file2:\n        csv_reader = csv.reader(file2)\n        for line in csv_reader:\n            dataset.append(line)\n    return dataset\n\n\ndef distance (test,train):\n    result=0.0\n    #此时每个test例如[1,2,3,4]每个train例如[1,2,3,4,a],-1除去标签\n    for i in  range(len(test)-1):\n        result=result+math.sqrt(abs((float(test[i])-float(train[i]))*(float(test[i])+float(train[i]))))\n    return result\n\ndef sort(train,test,k=3):\n    result=[]\n    sortresult=[]\n    #计算每个样本集到样本的距离\n    for i in range(len(test)):\n        for m in range(len(train)):\n            #对于每个测试实例得到距离和对应的标签\n            result.append([distance(test[i],train[m]),train[m][-1]])\n        sortresult.append(findsort(result,k))#得到每一个测试集的分类结果\n        result=[]                            #将每个测试集的距离集合清空\n    return sortresult       #最终结果\n    #得到结果集，每一个test到样本集的距离\n\n#示例输入[[3.917258917468777, 'Iris-setosa'], [4.365595716195167, 'Iris-setosa']]\ndef findsort(data,k=3):\n    result={}\n    voat=[]\n    for x in range(len(data)):\n            result.update({data[x][0]:data[x][1]})\n    #对字典进行排序从小到大\n    a=sorted(result.items(), key=lambda d: d[0])\n    for m in range(k):\n         voat.append(a[m][-1])\n    #得到列表中出现次数最多的元素\n    b=Counter(voat).most_common(1)\n    return b[0][0]\n\n#计算准确率\ndef correct(sample,predict):\n    flag=0\n    for a in range(len(sample)):\n        if(sample[a]==predict[a]):\n            flag=flag+1\n    return flag/len(sample)\n\ndef main():\n    testlist=[]\n    train=list(readfile(\"F:\\\\train.csv\"))\n    test=list(readfile(\"F:\\\\test.csv\"))\n    #k为最近邻的个数\n    output=sort(train,test,3)\n    #得到分类的结果集\n    print(output)\n    for a in range(len(test)):\n        testlist.append(test[a][-1])\n    #输出准确率\n    print(correct(testlist,output))\nmain()\n\n```\n\n\n\n\n\n\n\n\n\n\n","tags":["python"],"categories":["机器学习"]},{"title":"数据集生成器","url":"/2018/01/27/2018-1-27/","content":"<Excerpt in index | 首页摘要>\n运用java来实现自定义的数据集\n<!-- more -->\n\n使用说明这是一个用java写的用户自定义数据集生成器、目前只支持日期用户名和用户标识三个字段、由于是1.0版本功能比较少、\n为了满足大数据自定义的数据来源将继续开发(今天玩spark竟找不到想要的数据集、、)、整个项目已经发布在github上、程序的入口在main class、\n运行时要先配置好setting.properties在里面要定义好所需要的字段的种类数、注意输入必须为大于等于1的正整数、并且sum的值至少为6、\n运行成功后将在相对路径下生成result数据集、有空会用python来重写整个项目(有空练练python、其实也是挺好玩的)、项目难度不大具体源码的介绍如下、\n程序定义4个类分别为主类、日期类、标识类、用户id类、初始化自定义数量后通过三个类返回的容器进行汇总、最后通过文本文件输出\n目前需要改进的地方：日期库、、程序写死了还不能实现真正意义上的用户自定义\n\n```java\n\npublic class Mainclass {\n\t\n\tstatic int idnum ;   \t//定义不同id的个数\n\tstatic int flagnum ; \t//定义不同行为标记的个数\n\tstatic int sum ;      \t//定义数据集的总行数\n\n\t//初始化成员变量\n\tstatic {\n\t\tResourceBundle set=ResourceBundle.getBundle(\"setting\");\n\t\tidnum=Integer.parseInt(set.getString(\"idnum\"));\n\t\tflagnum=Integer.parseInt(set.getString(\"flagnum\"));\n\t\tsum=Integer.parseInt(set.getString(\"sum\"));\n\t\t}\n\t\n\n\tpublic static void main(String[] args) throws Exception{\n\t\n\t\tArrayList<String> flager= new Flag(flagnum,sum).create();\n\t\tArrayList<String> dater= new Data(sum).create();\n\t\tArrayList<String> ider= new Id(idnum,sum).create();\n\t\tArrayList<String> result= new ArrayList<String>();\n\t\t\n\t\t//将所有结果进行横向组合\n\t\tfor(int i=0;i<=sum-1;i++) {\n\t\t\tresult.add(dater.get(i)+\"    \"+ider.get(i)+\"    \"+flager.get(i));\n\t\t}\n\n\t\t//在相对路径下生成结果文件\n\t\tBufferedWriter bw=new BufferedWriter(new FileWriter(\"result.txt\"));\n\t\tIterator<String> it = result.iterator();  \n\t        while(it.hasNext()){  \n\t            bw.write(it.next());\n\t            bw.newLine();\n\t            bw.flush();\n\t        } \n        bw.close();\n\t}\n\n}\n \n \n \n \n public class Data {\n\tint sum;\n\tData(int sum){\n\t\tthis.sum=sum;\n\t}\n\tpublic ArrayList<String> create() {\n\t\tArrayList<String> data=new ArrayList<String>();\n\t\t//自定义日期库\n\t\tString datasort[]= {\"2018-1-1\",\"2018-1-2\",\"2018-1-3\",\"2018-1-4\",\"2018-1-5\",\"2018-1-6\"};\n\t\ttry {\n\t\t\tint  avg=sum/6;                        //定义一个数来平均分配日期\n\t\t\tfor(int a=0,i=-1;a<=sum-1;a++){       //因为0是必定可以被整除的所以i初始值为-1\n\t\t\t\tif(a%avg==0) {\n\t\t\t\t\ti++;\n\t\t\t\t}\n\t\t\tif(i>5){i=5;}\n\t\t\tdata.add(String.valueOf(datasort[i]));\t//日期库从0开始\n\t\t    }\n\t\t} \n\t\tcatch (Exception e) {\n\t\t\tSystem.out.println(e.getMessage()+\"sum的值至少为6\");\n\t\t}\n\t\t\n\t\treturn data;\n\t}\n}\n\n\n\n\n\npublic class Flag {\n\tint flagnum;\n\tint sum;\n\tString nameid;\n\tFlag(int flagnum,int sum){\n\t\tthis.flagnum=flagnum;\n\t\tthis.sum=sum;\n\t}\n\t\n\tpublic ArrayList<String> create() {\n\t\tArrayList<String> list=new ArrayList<String>();\n\t\t//存放生成的名字\n\t    String name[]=new String[flagnum];\n\t    for(int a=0;a<=flagnum-1;a++) {\n\t    \t//从0开始定义flag\n\t    \tnameid=String.valueOf(a);\n\t    \tname[a]=nameid;\n\t    }\n\t\t//根据名字组合随机生成id  \n\t\tfor(int a=0;a<=sum-1;a++) {\n\t\t\tlist.add(name[(int)(Math.random()*flagnum)]);\n\t\t}\n\t\treturn  list;\n\t}\n}\n\n\npublic class Id {\n\tint idnum;//不同名字的数量\n\tint sum;\n\tString nameid;\n\tId(int idnum,int sum){\n\t\tthis.idnum=idnum;\n\t\tthis.sum=sum;\t\t\n\t}\n\tpublic ArrayList<String> create() {\n\t\tArrayList<String> list=new ArrayList<String>();\n\t\t//存放生成的名字\n\t    String name[]=new String[idnum];\n\t    for(int a=0;a<=idnum-1;a++) {\n\t    \t//生成随机生成的名字组合\n\t    \tnameid=String.valueOf((char)(int)(97+Math.random()*26))+\n\t    \tString.valueOf((char)(int)(97+Math.random()*26))+\n\t    \tString.valueOf((char)(int)(97+Math.random()*26));\n\t    \tname[a]=nameid;\n\t    }\n\t\t//根据名字组合随机生成id  \n\t\tfor(int a=0;a<=sum-1;a++) {\n\t\t\tlist.add(name[(int)(Math.random()*idnum)]);\n\t\t}\n\t\treturn  list;\n\t}\n}\n\n \n //setting配置文件来定义数据集\n //————————————————————— \n //setting.properties\n //idnum=2\n //flagnum=3\n //sum=10\n //————————————————————\n```\n\n\n\n\n\n\n\n\n\n\n","tags":["java"],"categories":["大数据"]},{"title":"Java动态代理","url":"/2018/01/12/2018-1-12/","content":"<Excerpt in index | 首页摘要>\n这是一个java动态代理的小例子\n<!-- more -->\njava动态代理的作用\n1、实现一个类的方法的增强(例如类a有一个方法b()、当一个类要调用方法b()时需要给方法b()增加新的功能、但有些时候又需要调用b()的原先方法所以此时不可以重写方法b()、因此使用代理可以在不改变方法b()的基础上来增强方法、以后就使用代理类的增强方法)\n\n2、实现代理(比如类A有很多方法、你可以创建一个代理类B拥有A中的所用方法、在客户端需要调用A的方法时只需要访问B就可以达到和访问A一样的效果、不过代理B可以自己重写某个方法当客户端访问B时实际调用A中定义的方法)\n\n\n首先定义三个类一个接口、接口Buy中定义需要增强的方法、原始类Old中的实现原始方法money、定义增强类Proxyclass来实现增强方法、测试类Test来测试增强的方法\n\n```java\n\n//接口\npublic interface Buy {\n\tpublic int money(int a);\n}\n\n\n\npublic class Old implements Buy{\n//需要增强的方法\n\tpublic int money(int a) {\n\t\treturn a;\n\t}\n}\n\n\n\n//测试类\npublic class Test {\n\tpublic static void main(String[] args) {\n\t\tOld old=new Old();\n\t\tSystem.out.println(\"old money\"+old.money(44));\n\t\tBuy a=Proxyclass.getproxyclass(5);\n\t\tSystem.out.println(a.money(500));\n\t}\n}\n\n\n\n//代理类\npublic  class Proxyclass {\n\tpublic static Buy getproxyclass(int num) {\n\t\t//使用默认的类加载器\n\t\tObject proxyobj=Proxy.newProxyInstance(Old.class.getClassLoader(),new Class[] {Buy.class}, new InvocationHandler() {\n\t\t\tpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n\t\t\t\t //反射拿到原来的方法\n\t\t\t\tInteger result=(Integer)method.invoke(new Old(),args);\n\t\t\t\t//增强的方法\n\t\t\t\treturn result-num;\n\t\t\t}\n\t\t});\n\t\t//返回接口\n\t\treturn (Buy)proxyobj;\n\t}\n}\n\n        \n```\n```java\n\n\npublic interface Star {\n    public void sing();\n    public void ticket();\n\n}\n\n\n\npublic class StarHandler implements InvocationHandler {\n\n    public Star realstar=null;\n    public StarHandler(Star realstar){\n        this.realstar=realstar;\n    }\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(\"执行其他方法\");\n        if(method.getName().equals(\"sing\")){\n            method.invoke(realstar,args);\n        }\n\n        return null;\n    }\n}\n\n\n\npublic class Client {\n    public static void main(String[] args){\n        Star realStar =new Realstar();\n        StarHandler handler=new StarHandler(realStar);\n\t\t//返回一个指定接口的代理类实例，该接口可以将方法调用指派到指定的调用处理程序\n\t\t//loader - 定义代理类的类加载器\n        //interfaces - 代理类要实现的接口列表\n        //h - 指派方法调用的调用处理程序\n\t\t//相当于proxy帮你自动创建这个代理类\n        Star proxy =(Star)Proxy.newProxyInstance(ClassLoader.getSystemClassLoader()\n                ,new Class[]{Star.class},handler);\n        proxy.sing();\n        proxy.ticket();\n    }\n}\n\n\npublic class Realstar implements Star {\n    @Override\n    public void sing() {\n        System.out.println(\"reastar--sing\");\n    }\n\n    @Override\n    public void ticket() {\n        System.out.println(\"reastar--ticket\");\n    }\n}\n}\n\n```\n\njava spring框架就用了动态代理技术、能为容器中的对象生成动态代理对象、通过利用AOP思想对一些类的功能做了抽取\n\n\n\n\n\n\n\n\n\n\n","tags":["java"],"categories":["大数据"]},{"title":"基本神经网络","url":"/2017/12/10/2017-12-10/","content":"<Excerpt in index | 首页摘要>\n简单整理一下神经网络训练的步骤\n<!-- more -->\n总结一下最简单的神经网络的训练过程和原理\n通常利用数据交叉验证来提高数据利用率\n<img src=\"http://aRootUser.github.io/img/2/1.jpg\">\n交叉验证：给定一个训练集和测试集，为了最大程度的利用测试集，可以将训练集分为若干份，这里为5。第一次将fold1(折)作为测试集其余的作为训练集，第二次将fold2作为测试集，其余的作为训练集，以此类推从而达到最大化利用数据更新权重的效果\n<img src=\"http://aRootUser.github.io/img/2/2.jpg\">\n对于输入的一张图片简单将图片的输入像素点看成[1,4]的矩阵、输出层为[1,3],中间的权值为[4,3]的矩阵、和图中不同图中是左成矩阵、这里定义的是右乘矩阵、没有定义中间层、最后还要加上[1,3]偏置值得到[1,3]的输出值每一个值代表某一类别的得分、\n<img src=\"http://aRootUser.github.io/img/2/3.jpg\">\n为了更好的定以中间权值定义的好坏以及预测结果的准确程度、用损失函数来衡量、损失函数最小表示预测越准确、这里定义的是svm损失函数、\nl 表示自己定义的可容忍的长度\nyi表示正确类别的得分\nj表示其他类别的得分\n通过计算每个其他类别减去正确类别的得分的最大值的求和来表是损失函数的结果对于多个输入例如输入100张图片还要除去100相当于取平均值\n<img src=\"http://aRootUser.github.io/img/2/4.jpg\">\n为了防止权值为0从而导致输入样本的每一个值没有被充分利用例如训练得到的两个权值\n设输入的样本为[1,1,1,1]\n权重W1[0.5,0.5,0.5,0.5]    \n权重W2[1,0,0,0]\n矩阵相乘后得到的结果相同但是w2由于有三个0没有充分利用每一项所以添加w的平方项来惩罚权重为w2的情况、使其损失值变大\t\n<img src=\"http://aRootUser.github.io/img/2/5.jpg\">\n<img src=\"http://aRootUser.github.io/img/2/6.jpg\">\n分类器的作用将输出的值通过sigmoid函数映射到0至1的区间上、e的x次幂进行放大、最后通过取其作为正确类别的概率取负对数得最终其对应的损失值(因为概率越大越输出的损失值越小)\n前向传播：从输入的x一直到计算出loss、通过梯度下降算法找到一个下降方向、最终找到最低点、训练的批次数一般为2的整数次幂\n一个Epoch表示迭代完所有数据、一个迭代表示跑完当前的一个batch\n## 学习率\n每次训练跟新权重的变化要乘一个学习率来调整权值变化的大小、过大会错过最优解\n## 反向传播\n通过计算出每一个权重对最终的loss值的影响来调整权重的大小(向前传播的逆向求解)\n## 激活函数 \n对神经元的输出进行去线性化、例如sigmoid函数(由于当x过大时很容易导致梯度消失使其无法求导进行反向传播、现在一般用relu激活函数并且求导简单）\n## 过拟合问题 \ndrop-out进行处理通过迭代来弥补神经网络的复杂度\n## 过程小结 \n首先输入训练集如手写数字集、定义神经网络后、通过向前传播得到对每一个类别的输出、通过sortmax函数将输出转化为概率分布、通过与标签进行如下运算个（标签是one-hot概率）、将输出的概率分布取对数与标签值乘积在做平均值求和最后取负数-tf.reduce_sum(y_*tf.log(y))、得到交叉熵来反应结果集与标签的相似度、最后通过梯度下降法不断训练使交叉熵最小、来优化权重参数、\n\n\n\n\n\n\n\n\n\n\n","tags":["深度学习"],"categories":["深度学习"]},{"title":"Webnote","url":"/2017/12/02/2017-12-02/","content":"<Excerpt in index | 首页摘要>\n用来记录有趣的东西\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## smallnote\n\n当使用卡夫卡作为MQ时如果出现MQ数据存入的速度远远小于数据从MQ采集的速度、\n\n可直接通过netty或者mina直接从数据源采集\n\njava中wait方法释放锁、notify不释放锁直至执行完这个方法\n\nsix是兼容python2,3的一个库\nfor box, color in six.iteritems(box_to_color_map):\n迭代返回键值对\n\n\n## 2018-3-10\n币安的黑客攻击这波操作真的是6的飞起、\n\n## 2018-3-19  \n工作室搬了、怀念大长桌子、\n\n## 2018-3-25\n今天写python时碰到的小细节debug了好久、、\n``` python\n\nprint('A')\nclass MyObject(object):\n    print('B')\n    def __init__(self, name):\n        print('C')\n        self.name = name\n        print('D')\n    print(\"F\")\nprint('E')\nmy_object1 = MyObject('Hello')\n#这段程序的执行结果依次为A、B、F、E、C、D\n#类的__init__函数注意是两个下滑线、、\n#对一个存放类的set集合根据类中的flag来进行排序、True为降序排列taskset=[]\ntaskset.sort(key=lambda obj:obj.flag, reverse=True)#降序排列\n\n```\npython引用变量的规则\n首先从local(例如函数内部)开始，如果有则优先使用\n若在local没有，则会从local的封闭环境开始搜寻\n若以上都没有，则在global中搜寻\n\n\n## 2018-3-26\n立个flag每天刷一道算法题\n\n## 2018-3-29\n数学建模课中看到了机器学习的影子、不禁听的有点小激动虽然老师讲的也很简略、要是学校有深度学习的选修课就好了（我绝对不逃课）\n\n## 2018-4-1\n已无力吐槽win10的霸道更新、各种卸载后终于把更新给禁了(好想有一台Mac、、)、结果晚上就开不了机了、、吐血、、重装了系统配置都没了（还好其他盘都在、当初分好几个区是确的选择）、、\n浪费了好多时间配置都重新搭的差不多了、唯一开心的是就是系统似乎快了一点、、\n\n## 2018-4-15\n阿里的天池比赛彻底放弃了、训练了近10个小时的模型的loss也降到了0.5左右、但识别的结果并不好、可能开始对图片的切割范围过大了、框和框之间的距离拉得太近、要期中考了就不再重新折腾了、\n突然想做一个基于区块链的\"微博\"、完全去中心化、言论自由、不受政府监管、想想就好激动、会有搞头不、\n\n## 2018-4-16\n最近博客遇到个bug、就是js的动态效果突然加载不出来、debug了一晚上终于发现了错误！！主要是在HTTPS请求下引入HTTP资源造成的Mixed Content的一个错误、特别是chrome这个浏览器、拦截了所有http请求的js脚本、然后就是修改了、把所有js的外部资源链接改成https请求就行了(作为前端小白的我不知道这么说对不对)、当然不能一个个手改、找到hexo主题下的js脚本中对其链接进行修改最后生成就行了、、\npython也碰到了几个坑有空慢慢填1、浅拷贝和深拷贝 2、创建若个个类丢到list中、遍历取出list中的类并调用其方法时碰到的问题(填坑、调用方法是少加了个括号、我的天太粗心了、、当局者迷啊、)\n\n## 2018-4-25\nthe g_overmverment have no power to supervise our message、the Internet company shoud not head down to the g_overmverment\n\n## 2018-5-6\n灰常开心终于解决了ssd+inception3内存爆炸的问题、做了近半个月的安全识别差不完成了、人是会撒谎的但计算机不会、是该继续研究好久没学的hadoop、spark了\n\n## 2018-5-8\npythcharm的debug\tF8下一行 \tF7 进入函数\t\tF9 停止在下一个断点\n\n## 2018-5-15\n了解了锤子发布会、想起差不多一周前的谷歌IO、虽然两者没有比较的意义、只能说希望越大失望越大希望越大吧、不禁又有点心疼老罗、重新定义了重新定义、网上的各种表情包真的是看的迷醉、\nWe are standing at the crossroads of science and art 向伟大的乔布斯致敬！\n\n## 2018-5-16\n最讨厌排球、没有之一、大一网球课打的真的是太开心了、\n\n## 2018-5-20\n周末想手写inceptionV3、看了看源码、一个函数11个参数、、我还是太年轻了、、、不急慢慢来吧、\n\n## 2018-5-21\n玩了半个下午的wncry、还好是在虚拟机上玩、不然真的要WannaCry了、不过说好的到时间了会删除加密文件到最后还是没有删除、公共系统对他而言分分钟秒成渣、\n\n## 2018-5-23\npython的装饰器\n``` python\n\ndef common(func):\n\tprint(\"fist\")\n    def common1():\n        print(\"1\")\n        return func(\"2\")\n\tprint(\"second\")\n    return common1\n\t\n#被修饰的函数\ndef new(inputer):\n    print(inputer)\n    print(\"3\")\n\ntest=common(new)\ntest()\n#输出结果为first、second、1、2、3只要进入了common就会先执行方法外的语句\n\n```\n```python\ndef common(func):\n    def common1():\n        print(\"1\")\n        return func(\"2\")\n    return common1\n#内置语法修饰相当于帮你把被修饰的函数传入修饰函数并得到修饰后的原函数\n@common\ndef new(inputer):\n    print(inputer)\n    print(\"3\")\nnew()\n```\n\n\n```python \n#再在最外层加一层用out来接受修饰器的参数\ndef out(out):\n    def common(func):\n        def common1():\n            print(out)\n            print(\"1\")\n            return func(\"2\")\n        return common1\n    return common\n\n@out(\"out\")\ndef new(inputer):\n    print(inputer)\n    print(\"3\")\nnew()\n```\n\n```python\n#类装饰器输出结果为1、2、3\nclass Foo(object):\n    def __init__(self,func):\n        self._func=func\n    def __call__(self):\n        print(\"1\")\n        self._func()\n        print(\"3\")\n@Foo\ndef bar():\n    print(\"2\")\nbar()\n```\n在Python中，类也是对象，你可以动态的创建类。这就是当我们使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的\n元类就是用来创建这些类（对象）的，元类就是类的类，你可以这样理解为\n\n## 2018-5-25\n进过反复的思考最终决定了还是往大数据架构发展、深度学习算法学历要求太高、公式也不是一两年可以完全弄懂的、等工作一段时间之后再慢慢往那边发展、希望以后能参与分布式深度学习平台的搭建吧、tensorflow源码的阅读先告一段落了\n## 2018-5-30\n学了几天netty、还是too young啊、、\n## 2018-5-30\n第一次电话面试、好紧张啊、、个人感觉不是很好但竟然过了、我竟然紧张的连java八大数据类型都没答全、cry、\n总结几个自己没答好的问题1、基本数据类型的包装类 2、hadoop和spark mapreduce的具体区别 3、java并发包的了解、线程池\n\n","tags":["other"],"categories":["other"]}]