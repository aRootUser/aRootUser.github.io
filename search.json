[{"title":"Hdfs RPC流程","url":"/2018/09/13/2018-9-13/","content":"<Excerpt in index | 首页摘要>\n先从最基本的RPC调用的源码开始着手\n<!-- more -->\n简单总结hdfs RPC执行的全部流程\n\n\n\n## RPC调用入口\n首先为了获得代理对象会执行RPC.getProxy()中的Proxy.newInstace()获得实例\n初始化这个实例时会初始化参数InvocationHandler这个类\n调用具体代理方法时会调用InvocationHandler里面已经重写过的invoke()方法\n这个方法里定义了与远程的链接通过这个方法便能获得远程调用后方法的返回值\n\n```java\n//启动客户端\npublic static void main(String[] args) throws Exception {\n\t\tClientNamenodeProtocol namenode = RPC.getProxy(ClientNamenodeProtocol.class, 1L,\n\t\t\t\tnew InetSocketAddress(\"localhost\", 9999), new Configuration());\n\t\tString metaData = namenode.getMetaData(\"/a.a\");\n\t\tSystem.out.println(metaData);\n\t}\n\n//服务端\npublic static void main(String[] args) throws Exception {\n\t\t//工厂方法、、、、\n\t\tBuilder builder = new RPC.Builder(new Configuration());\n\t\tbuilder.setBindAddress(\"localhost\")\n\t\t.setPort(9999)\n\t\t.setProtocol(ClientNamenodeProtocol.class)\n\t\t.setInstance(new MyNameNode());\n\t\tServer server = builder.build();\n\t\tserver.start();\n\t}\n```java\nRPC.getProxy\n```java\npublic static <T> T getProxy(Class<T> protocol, long clientVersion,netSocketAddress addr, Configuration conf)\n     throws IOException {\n     return getProtocolProxy(protocol, clientVersion, addr, conf).getProxy();\n   }\n   \n//如果配置文件里没有配置返回一个默认的socketFactory\nSocketFactory getDefaultSocketFactory(){\n    \n}   \n   \n   \n//经过一系列调用得到RPC的引擎\nstatic synchronized RpcEngine getProtocolEngine(Class<?> protocol,\n      Configuration conf) {\n    RpcEngine engine = PROTOCOL_ENGINES.get(protocol);\n    if (engine == null) {\n      Class<?> impl = conf.getClass(ENGINE_PROP+\".\"+protocol.getName(),\n                                    WritableRpcEngine.class);\n      //用反射工具类实例化一个对象imp是这个引擎的全限定名，conf是配置文件 6个xml文件\n      engine = (RpcEngine)ReflectionUtils.newInstance(impl, conf);\n      //此处protocol为一开始传入的接口的全限定名\n      PROTOCOL_ENGINES.put(protocol, engine);\n    }\n    return engine;\n  }\n  \n//拿到引擎后开始调用引擎的getProxy方法\n//在writable引擎中\n//tag1----\npublic <T> ProtocolProxy<T> getProxy(){\n    //开始动态代理\n    T proxy = (T)\n    //拿到协议的类加载器\n    Proxy.newProxyInstance(protocol.getClassLoader(),new Class[] { protocol }, new Invoker(protocol, addr, ticket, conf,factory, rpcTimeout, fallbackToSimpleAuth));\n    //上方起跳\n    return new ProtocolProxy<T>(protocol, proxy,  true);\n}\n//拿到引擎后开始调用引擎的getProxy方法\n//在writable引擎中\n//getProxy方法中的动态代理拿到中的参数要实例化Invoker\n//在构造方法中主要初始化Invoker成员变量\n//重要的有Client\n//这个内部类实现了RpcInvocationHandler这个接口\n//ConnectionId是Client的静态内部类事先已经导入\n//这个类保存地址和用户ticket。客户端连接\n//服务器的唯一标识是<remoteAddress, protocol, ticket> ticket的一个例子“123,auth:SIMPLE”\n public Invoker(Class<?> protocol,\n                   InetSocketAddress address, UserGroupInformation ticket,\n                   Configuration conf, SocketFactory factory,\n                   int rpcTimeout, AtomicBoolean fallbackToSimpleAuth)\n        throws IOException {\n      this.remoteId = ConnectionId.getConnectionId(address, protocol,\n          ticket, rpcTimeout, conf);\n      this.client = CLIENTS.getClient(conf, factory);\n      this.fallbackToSimpleAuth = fallbackToSimpleAuth;\n    }\n//拿到引擎后开始调用引擎的getProxy方法\n//在writable引擎中\n//getProxy方法中的动态代理拿到中的参数要实例化Invoker\n//在构造方法中主要初始化Invoker成员变量\n//初始化成员变量时要通过getClient来获得client\n\n\n//getClient会从这里面的map中拿到getClient()方法key是socket Factory\npublic class ClientCache {\n  private Map<SocketFactory, Client> clients = new HashMap<SocketFactory, Client>();\n\n //第一次的入口\n public synchronized Client getClient(Configuration conf, SocketFactory factory) {\n    return this.getClient(conf, factory, ObjectWritable.class);\n  }\n\n\n public synchronized Client getClient(Configuration conf,\n      SocketFactory factory, Class<? extends Writable> valueClass) {\n    Client client = clients.get(factory);\n    //没有的话造一个Client第一次的话是没有的\n    if (client == null) {\n      client = new Client(valueClass, conf, factory);\n      clients.put(factory, client);\n    } else {\n      client.incCount();\n    }\n    if (Client.LOG.isDebugEnabled()) {\n      Client.LOG.debug(\"getting client out of cache: \" + client);\n    }\n    return client;\n  }\n\n}\n\n//拿到引擎后开始调用引擎的getProxy方法\n//在writable引擎中\n//getProxy方法中的动态代理拿到中的参数要实例化Invoker\n//在构造方法中主要初始化Invoker成员变量\n//初始化成员变量时要通过getClient来获得client\n//拿到Client后继续初始化成员变量\n//现在在writable的引擎内部Invoker类中\n//初始化完成后回到这里\n\n\n//tag1----对应上方\npublic <T> ProtocolProxy<T> getProxy(){\n    //开始动态代理\n    T proxy = (T)\n    //拿到协议的类加载器\n    Proxy.newProxyInstance(protocol.getClassLoader(),new Class[] { protocol }, new Invoker(protocol, addr, ticket, conf,factory, rpcTimeout, fallbackToSimpleAuth));\n    //上方起跳\n    return new ProtocolProxy<T>(protocol, proxy,  true);\n}\n\n//这是一个另外独立的类\n//类包围了服务器的代理，\n//包含其支持的方法列表。\n//一个值为null的方法列表来表示客户端和服务器有相同的协议。\npublic class ProtocolProxy<T> {\n    //接口的全限定名\n    private Class<T> protocol;\n    private T proxy;\n    private HashSet<Integer> serverMethods = null;\n    //构造方法初始化变量\n    public ProtocolProxy(Class<T> protocol, T proxy,\n      boolean supportServerMethodCheck) {\n    this.protocol = protocol;\n    //这里会对其报错但不影响RuntimeException\n    this.proxy = proxy;\n    this.supportServerMethodCheck = supportServerMethodCheck;\n  }\n\n}\n\n//new 完ProtocolProxy并返回对象然后回到一开始的地方\npublic static <T> T getProxy(Class<T> protocol, long clientVersion,netSocketAddress addr, Configuration conf)\n     throws IOException {\n     return getProtocolProxy(protocol, clientVersion, addr, conf).getProxy(.......);\n   }\n   \n//现在回到程序的入口开始执行这条语句\n\tString metaData = namenode.getMetaData(\"/a.a\");\n\t\n//调用getMetaData方法时会调用writable的invoker内部类中的invoke方法\npublic Object invoke(Object proxy, Method method, Object[] args)\n      throws Throwable {\n      long startTime = 0;\n      if (LOG.isDebugEnabled()) {\n        startTime = Time.now();\n      }\n      TraceScope traceScope = null;\n      //这个方法存疑。。。\n      if (Trace.isTracing()) {\n        traceScope = Trace.startSpan(\n            method.getDeclaringClass().getCanonicalName() +\n            \".\" + method.getName());\n        //getName直接跳到下面\n        //得到非常完整的公有、全限定名、方法名、参数\n//tag2--------------------\n      }\n      ObjectWritable value;\n      try {\n//tag3--------------------\n        value = (ObjectWritable)\n          client.call(RPC.RpcKind.RPC_WRITABLE, new Invocation(method, args),\n            remoteId, fallbackToSimpleAuth);\n      } finally {\n        if (traceScope != null) traceScope.close();\n      }\n      if (LOG.isDebugEnabled()) {\n        long callTime = Time.now() - startTime;\n        LOG.debug(\"Call: \" + method.getName() + \" \" + callTime);\n      }\n      return value.get();\n    }\n\n    \n//又进入了引擎的静态内部类\n private static class Invocation implements Writable, Configurable {\n    private String methodName;\n    private Class<?>[] parameterClasses;\n    private Object[] parameters;\n    private Configuration conf;\n    private long clientVersion;\n    private int clientMethodsHash;\n    private String declaringClassProtocolName;\n    \n    //构造方法\n    public Invocation(Method method, Object[] parameters) {\n      this.methodName = method.getName();\n      this.parameterClasses = method.getParameterTypes();\n      this.parameters = parameters;\n      rpcVersion = writableRpcVersion;\n      if (method.getDeclaringClass().equals(VersionedProtocol.class)) {\n        //VersionedProtocol is exempted from version check.\n        clientVersion = 0;\n        clientMethodsHash = 0;\n      } else {\n        this.clientVersion = RPC.getProtocolVersion(method.getDeclaringClass());\n        this.clientMethodsHash = ProtocolSignature.getFingerprint(method\n            .getDeclaringClass().getMethods());\n      }\n      //如果协议类具有ProtocolAnnotation，则获取协议注释中的名称;否则，类名就是协议名。暂时不明白作用\n      //同之前赋予了非常详细的方法名。。。\n      this.declaringClassProtocolName = \n          RPC.getProtocolName(method.getDeclaringClass());\n    }\n    \n}\n\n//重新回到tag2----开始tag3----\n//client中的call\n public Writable call(RpcKind rpcKind, Writable rpcRequest,\n      ConnectionId remoteId, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    return call(rpcKind, rpcRequest, remoteId, RPC.RPC_SERVICE_CLASS_DEFAULT,\n      fallbackToSimpleAuth);\n  }\n\n//继续在类里面重载\npublic Writable call(RpcKind rpcKind, Writable rpcRequest,\n      ConnectionId remoteId, int serviceClass,\n      AtomicBoolean fallbackToSimpleAuth) throws IOException {\n//tag4---------------------开始跳\n    final Call call = createCall(rpcKind, rpcRequest);\n//tag5--------------开始跳\n    Connection connection = getConnection(remoteId, call, serviceClass,\n      fallbackToSimpleAuth);\n    try {\n      connection.sendRpcRequest(call);                 // send the rpc request\n    } catch (RejectedExecutionException e) {\n      throw new IOException(\"connection has been closed\", e);\n    } catch (InterruptedException e) {\n      Thread.currentThread().interrupt();\n      LOG.warn(\"interrupted waiting to send rpc request to server\", e);\n      throw new IOException(e);\n    }\n\n//tag4---------------------\nCall createCall(RpcKind rpcKind, Writable rpcRequest) {\n//创建一个内部类Call\n//Writable rpcRequest封装了方法的名字、client版本还有有关方法的一组数据。。。存疑\n    return new Call(rpcKind, rpcRequest);\n  }\n\n//回到tag4---\n\n\n//进入tag5\n//Get a connection from the pool, or create a new one and add it to the pool.相同的ID可以重用\n\n//是Client类中的方法\n//ConnectionId remoteId远程的ip和端口\n//Call call 之前创建的一个类封装了方法名和参数\nprivate Connection getConnection(ConnectionId remoteId,\n      Call call, int serviceClass, AtomicBoolean fallbackToSimpleAuth)\n      throws IOException {\n    if (!running.get()) {\n      // the client is stopped\n      throw new IOException(\"The client is stopped\");\n    }\n    Connection connection;\n    /* we could avoid this allocation for each RPC by having a  \n     * connectionsId object and with set() method. We need to manage the\n     * refs for keys in HashMap properly. For now its ok.\n     */\n    do {\n      synchronized (connections) {\n        connection = connections.get(remoteId);\n        if (connection == null) {\n//tag6---------\n          connection = new Connection(remoteId, serviceClass);\n          connections.put(remoteId, connection);\n        }\n      }\n    //tag7----------------\n    } while (!connection.addCall(call));\n    \n    //we don't invoke the method below inside \"synchronized (connections)\"\n    //block above. The reason for that is if the server happens to be slow,\n    //it will take longer to establish a connection and that will slow the\n    //entire system down.\n    //tag8----------------------\n    connection.setupIOstreams(fallbackToSimpleAuth);\n    return connection;\n  }\n\n//tag6进入-------------------\n//非常重要的client的内部类reactor模式\nprivate class Connection extends Thread {\n        public Connection(ConnectionId remoteId, int serviceClass) throws IOException {\n      //第一次进来为null\n      this.remoteId = remoteId;\n      this.server = remoteId.getAddress();\n      if (server.isUnresolved()) {\n        throw NetUtils.wrapException(server.getHostName(),\n            server.getPort(),\n            null,\n            0,\n            new UnknownHostException());\n      }\n      this.rpcTimeout = remoteId.getRpcTimeout();\n      this.maxIdleTime = remoteId.getMaxIdleTime();\n      this.connectionRetryPolicy = remoteId.connectionRetryPolicy;\n      this.maxRetriesOnSasl = remoteId.getMaxRetriesOnSasl();\n      this.maxRetriesOnSocketTimeouts = remoteId.getMaxRetriesOnSocketTimeouts();\n      this.tcpNoDelay = remoteId.getTcpNoDelay();\n      this.doPing = remoteId.getDoPing();\n      //先Ping？有意思。。。。。。。true\n//------------下方高能底层操作以后慢慢来\n      if (doPing) {\n        // construct a RPC header with the callId as the ping callId\n        pingRequest = new ByteArrayOutputStream();\n        RpcRequestHeaderProto pingHeader = ProtoUtil\n            .makeRpcRequestHeader(RpcKind.RPC_PROTOCOL_BUFFER,\n                OperationProto.RPC_FINAL_PACKET, PING_CALL_ID,\n                RpcConstants.INVALID_RETRY_COUNT, clientId);\n        pingHeader.writeDelimitedTo(pingRequest);\n      }\n     // how often sends ping to the server in msecs\n     //60000\n      this.pingInterval = remoteId.getPingInterval();\n      this.serviceClass = serviceClass;\n      if (LOG.isDebugEnabled()) {\n        LOG.debug(\"The ping interval is \" + this.pingInterval + \" ms.\");\n      }\n//\"123,Sim\"和上方的一样的ticket还有RemoteId这个类\n      UserGroupInformation ticket = remoteId.getTicket();\n      //高能操作----SASL全称Simple Authentication and Security Layer，是一种用来扩充C/S模式验证能力的机制。在Postfix可以利用SASL来判断用户是否有权使用转发服务，或是辨认谁在使用你的服务器\n      // try SASL if security is enabled or if the ugi contains tokens.\n      // this causes a SIMPLE client with tokens to attempt SASL\n      boolean trySasl = UserGroupInformation.isSecurityEnabled() ||\n                        (ticket != null && !ticket.getTokens().isEmpty());\n      this.authProtocol = trySasl ? AuthProtocol.SASL : AuthProtocol.NONE;\n      \n      this.setName(\"IPC Client (\" + socketFactory.hashCode() +\") connection to \" +\n          server.toString() +\n          \" from \" + ((ticket==null)?\"an unknown user\":ticket.getUserName()));\n      this.setDaemon(true);\n    }\n}\n\n//tag6-------------完成回到一开始的tag6\n\n\n//tag7-------------进入\n\n /**\n     * Add a call to this connection's call queue and notify\n     * a listener; synchronized.\n     * Returns false if called during shutdown.\n     * @param call to add\n     * @return true if the call was added.\n     */\n    private synchronized boolean addCall(Call call) {\n      if (shouldCloseConnection.get())\n        return false;\n        // currently active calls\n      calls.put(call.id, call);\n      notify();\n      return true;\n    }\n//tag7-------------退出\n\n\n\n//tag8-------------进入\n private synchronized void setupIOstreams(\n        AtomicBoolean fallbackToSimpleAuth) {\n      if (socket != null || shouldCloseConnection.get()) {\n        return;\n      } \n      try {\n        if (LOG.isDebugEnabled()) {\n          LOG.debug(\"Connecting to \"+server);\n        }\n        if (Trace.isTracing()) {\n          Trace.addTimelineAnnotation(\"IPC client connecting to \" + server);\n        }\n        short numRetries = 0;\n        Random rand = null;\n        while (true) {\n          setupConnection();\n          InputStream inStream = NetUtils.getInputStream(socket);\n          OutputStream outStream = NetUtils.getOutputStream(socket);\n          writeConnectionHeader(outStream);\n          if (authProtocol == AuthProtocol.SASL) {\n            final InputStream in2 = inStream;\n            final OutputStream out2 = outStream;\n            UserGroupInformation ticket = remoteId.getTicket();\n            if (ticket.getRealUser() != null) {\n              ticket = ticket.getRealUser();\n            }\n            try {\n              authMethod = ticket\n                  .doAs(new PrivilegedExceptionAction<AuthMethod>() {\n                    @Override\n                    public AuthMethod run()\n                        throws IOException, InterruptedException {\n                      return setupSaslConnection(in2, out2);\n                    }\n                  });\n            } catch (Exception ex) {\n              authMethod = saslRpcClient.getAuthMethod();\n              if (rand == null) {\n                rand = new Random();\n              }\n              handleSaslConnectionFailure(numRetries++, maxRetriesOnSasl, ex,\n                  rand, ticket);\n              continue;\n            }\n            if (authMethod != AuthMethod.SIMPLE) {\n              // Sasl connect is successful. Let's set up Sasl i/o streams.\n              inStream = saslRpcClient.getInputStream(inStream);\n              outStream = saslRpcClient.getOutputStream(outStream);\n              // for testing\n              remoteId.saslQop =\n                  (String)saslRpcClient.getNegotiatedProperty(Sasl.QOP);\n              LOG.debug(\"Negotiated QOP is :\" + remoteId.saslQop);\n              if (fallbackToSimpleAuth != null) {\n                fallbackToSimpleAuth.set(false);\n              }\n            } else if (UserGroupInformation.isSecurityEnabled()) {\n              if (!fallbackAllowed) {\n                throw new IOException(\"Server asks us to fall back to SIMPLE \" +\n                    \"auth, but this client is configured to only allow secure \" +\n                    \"connections.\");\n              }\n              if (fallbackToSimpleAuth != null) {\n                fallbackToSimpleAuth.set(true);\n              }\n            }\n          }\n        \n          if (doPing) {\n            inStream = new PingInputStream(inStream);\n          }\n          this.in = new DataInputStream(new BufferedInputStream(inStream));\n\n          // SASL may have already buffered the stream\n          if (!(outStream instanceof BufferedOutputStream)) {\n            outStream = new BufferedOutputStream(outStream);\n          }\n          this.out = new DataOutputStream(outStream);\n          \n          writeConnectionContext(remoteId, authMethod);\n\n          // update last activity time\n          touch();\n\n          if (Trace.isTracing()) {\n            Trace.addTimelineAnnotation(\"IPC client connected to \" + server);\n          }\n\n          // start the receiver thread after the socket connection has been set\n          // up\n          start();\n          return;\n        }\n      } catch (Throwable t) {\n        if (t instanceof IOException) {\n          markClosed((IOException)t);\n        } else {\n          markClosed(new IOException(\"Couldn't set up IO streams\", t));\n        }\n        close();\n      }\n    }\n\n\n//tag8-------------退出\n```java\n\nnamenode启动时会在初始化方法中创造NameNodeRpcServer对象的实例 这个实例对象构造函数会通过创建RPC.Builder内部类的静态实例\n\n```java\n\nthis.clientRpcServer = new RPC.Builder(conf)\n        .setProtocol(\n            org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolPB.class)\n        .setInstance(clientNNPbService).setBindAddress(bindHost)\n        .setPort(rpcAddr.getPort()).setNumHandlers(handlerCount)\n        .setVerbose(false)\n        .setSecretManager(namesystem.getDelegationTokenSecretManager()).build();\n\n```java\n\n\n\n\n\n","tags":["hadoop"],"categories":["大数据"]},{"title":"Hdfs源码阅读","url":"/2018/08/01/2018-8-1/","content":"<Excerpt in index | 首页摘要>\n为了提高java能力、打算自己造一个简单的hdfs\n<!-- more -->\n首简单熟悉api再从hdfs的源码开始看起\nhdfs的一系列操作如下\n```java\nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.*;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.io.IOUtils;\nimport java.io.*;\nimport java.net.URI;\n\npublic class Main {\n    public class HdfsClient {\n        FileSystem fs = null;\n        public void init() throws Exception {\n            // 构造一个配置参数对象，设置一个参数：我们要访问的hdfs的URI\n            // 从而FileSystem.get()方法就知道应该是去构造一个访问hdfs文件系统的客户端，以及hdfs的访问地址\n            // new Configuration();的时候，它就会去加载jar包中的hdfs-default.xml\n            // 然后再加载classpath下的hdfs-site.xml\n            Configuration conf = new Configuration();\n            conf.set(\"fs.defaultFS\", \"hdfs://localhost:9000\");\n            /**\n             * 参数优先级： 1、客户端代码中设置的值 2、classpath下的用户自定义配置文件 3、然后是服务器的默认配置\n             */\n            conf.set(\"dfs.replication\", \"3\");\n            // 获取一个hdfs的访问客户端，根据参数，这个实例应该是DistributedFileSystem的实例\n            // fs = FileSystem.get(conf);\n            // 如果这样去获取，那conf里面就可以不要配\"fs.defaultFS\"参数，而且，这个客户端的身份标识已经是hadoop用户\n            fs = FileSystem.get(new URI(\"hdfs://localhost:9000\"), conf, \"hadoop\");\n        }\n        /**\n         * 往hdfs上传文件\n         */\n        public void testAddFileToHdfs() throws Exception {\n            // 要上传的文件所在的本地路径\n            Path src = new Path(\"/usr/redis-recommend.zip\");\n            // 要上传到hdfs的目标路径\n            Path dst = new Path(\"/aaa\");\n            fs.copyFromLocalFile(src, dst);\n            fs.close();\n        }\n        /**\n         * 从hdfs中复制文件到本地文件系统\n         */\n        public void testDownloadFileToLocal() throws IllegalArgumentException, IOException {\n            fs.copyToLocalFile(new Path(\"/text\"), new Path(\"/usr/local\"));\n            fs.close();\n        }\n        public void testMkdirAndDeleteAndRename() throws IllegalArgumentException, IOException {\n            // 创建目录\n            fs.mkdirs(new Path(\"/a1/b1/c1\"));\n            // 删除文件夹 ，如果是非空文件夹，参数2必须给值true\n            fs.delete(new Path(\"/aaa\"), true);\n            // 重命名文件或文件夹\n            fs.rename(new Path(\"/a1\"), new Path(\"/a2\"));\n\n        }\n        /**\n         * 查看目录信息，只显示文件\n         */\n        public void testListFiles() throws FileNotFoundException, IllegalArgumentException, IOException {\n            // 思考：为什么返回迭代器，而不是List之类的容器\n            RemoteIterator<LocatedFileStatus> listFiles = fs.listFiles(new Path(\"/\"), true);\n            while (listFiles.hasNext()) {\n                LocatedFileStatus fileStatus = listFiles.next();\n                System.out.println(fileStatus.getPath().getName());\n                System.out.println(fileStatus.getBlockSize());\n                System.out.println(fileStatus.getPermission());\n                System.out.println(fileStatus.getLen());\n                BlockLocation[] blockLocations = fileStatus.getBlockLocations();\n                for (BlockLocation bl : blockLocations) {\n                    System.out.println(\"block-length:\" + bl.getLength() + \"--\" + \"block-offset:\" + bl.getOffset());\n                    String[] hosts = bl.getHosts();\n                    for (String host : hosts) {\n                        System.out.println(host);\n                    }\n                }\n                \n            }\n        }\n        /**\n         * 查看文件及文件夹信息\n         */\n        public void testListAll() throws FileNotFoundException, IllegalArgumentException, IOException {\n            FileStatus[] listStatus = fs.listStatus(new Path(\"/\"));\n            String flag = \"d--             \";\n            for (FileStatus fstatus : listStatus) {\n                if (fstatus.isFile())  flag = \"f--         \";\n                System.out.println(flag + fstatus.getPath().getName());\n            }\n        }\n    }\n    /**\n     * 相对那些封装好的方法而言的更底层一些的操作方式\n     * 上层那些mapreduce   spark等运算框架，去hdfs中获取数据的时候，就是调的这种底层的api\n     */\n    public class StreamAccess {\n        FileSystem fs = null;\n        public void init() throws Exception {\n            Configuration conf = new Configuration();\n            fs = FileSystem.get(new URI(\"hdfs://localhost:9000\"), conf, \"hadoop\");\n        }\n        /**\n         * 通过流的方式上传文件到hdfs\n         * @throws Exception\n         */\n        public void testUpload() throws Exception {\n            FSDataOutputStream outputStream = fs.create(new Path(\"/text\"), true);\n            FileInputStream inputStream = new FileInputStream(\"/usr/text\");\n            IOUtils.copyBytes(inputStream, outputStream,3333333);\n        }\n        public void testDownLoadFileToLocal() throws IllegalArgumentException, IOException{\n            //先获取一个文件的输入流----针对hdfs上的\n            FSDataInputStream in = fs.open(new Path(\"/text\"));\n            //再构造一个文件的输出流----针对本地的\n            FileOutputStream out = new FileOutputStream(new File(\"/usr/local\"));\n            //再将输入流中数据传输到输出流\n            IOUtils.copyBytes(in, out, 4096);\n        }\n        /**\n         * hdfs支持随机定位进行文件读取，而且可以方便地读取指定长度\n         * 用于上层分布式运算框架并发处理数据\n         */\n        public void testRandomAccess() throws IllegalArgumentException, IOException{\n            //先获取一个文件的输入流----针对hdfs上的\n            FSDataInputStream in = fs.open(new Path(\"/test.txt\"));\n            //可以将流的起始偏移量进行自定义\n            in.seek(22);\n            //再构造一个文件的输出流----针对本地的\n            FileOutputStream out = new FileOutputStream(new File(\"/usr/test.2.txt\"));\n            IOUtils.copyBytes(in,out,19L,true);\n        }\n        /**\n         * 显示hdfs上文件的内容\n         */\n        public void testCat() throws IllegalArgumentException, IOException{\n            FSDataInputStream in = fs.open(new Path(\"/text.txt\"));\n            IOUtils.copyBytes(in, System.out, 1024);\n        }\n        public void testCat2() throws IllegalArgumentException, IOException{\n            FSDataInputStream in = fs.open(new Path(\"/weblog/input/access.log.10\"));\n            //拿到文件信息\n            FileStatus[] listStatus = fs.listStatus(new Path(\"/weblog/input/access.log.10\"));\n            //获取这个文件的所有block的信息\n            BlockLocation[] fileBlockLocations = fs.getFileBlockLocations(listStatus[0], 0L, listStatus[0].getLen());\n            //第一个block的长度\n            long length = fileBlockLocations[0].getLength();\n            //第一个block的起始偏移量\n            long offset = fileBlockLocations[0].getOffset();\n            System.out.println(length);\n            System.out.println(offset);\n            byte[] b = new byte[4096];\n            FileOutputStream os = new FileOutputStream(new File(\"d:/block0\"));\n            while(in.read(offset, b, 0, 4096)!=-1){\n                os.write(b);\n                offset += 4096;\n                if(offset>=length) return;\n            };\n            os.flush();\n            os.close();\n            in.close();\n        }\n    }\n\n}\n```\n\n## MyHdfs\n1、实现的功能namenode和datanode之间的通信\n2、datanode之间的通信\n3、简单的文件上传与下载\n4、逻辑路径的设置\n\n再捋一下思路、首先拿到一个hdfs的客户端对象、执行操作比如上传文件和目录、先给namenode发送请求、namenode去读取本地的文件里记录的目录信息、\n把ip传给客户端、然后启动所用datanode、使他们进行交互、然后客户端根据ip去找对应的namenode、然后把文件上传上去、最后是datanode之间的交互、\n并且定时发送心跳、\n\n碰到的问题总结\n\n自己写的rpc框架接口和实现都是放在服务端\n\n单例模式的使用、应为rpc调用namenode的注册表要保证其一\n\n泛型方法的使用\n\ncurrentHashMap多个datanode调用namenode的注册表示似乎没有实现线程的安全\n\n\n\n","tags":["hadoop"],"categories":["大数据"]},{"title":"Spark源码阅读","url":"/2018/07/23/2018-7-23 /","content":"<Excerpt in index | 首页摘要>\n先从整体来讲讲spark的整个流程\n<!-- more -->\n从今天开始终于要做想做了很久的事--学习spark源码。难度异常之大、无论是scala的复杂语法、还是底层复杂的RPC调用都不是短时间内捋的清的、\n但也只能硬着头皮上了、毕竟不能只做一个调包侠是吧。这篇博客长期更新、每天记录一部分、希望有一天无论是对于spark还是scala都有一种茅塞顿开的感觉、\n最后再感慨一下、上班真好！！！\n\n## spark作业提交至执行流程\n整个spark作业执行流程单位从大到小分别为DAG、stage、taskset、rdd(task)\n执行步骤为:提交作业job后首先构建生成DAG、通过DAGScheduler调度根据依赖对DAG进行切分得到stage、然后TaskScheduler接受stage后对taskset进行管理并分配给Worker、Worker执行任务\nstage:由DAGScheduler根据依赖对DAG进行切分得到的单位\ntaskest:每个stage包含若干个taskset、每个taskset包含多个task\nDAGScheduler:接收DAG后进行划分stage(上游的为ShuffleMapStage、下游为ResultStage)、\n根据每个stage的partition创建多个Task、最后以taskset的形式提交给TaskScheduler\nTaskScheduler:接受stage后创建TaskManager对Taskset进行管理、把TaskManager添加到调度池将其交给SchedulerBackend处理(他通过申请TaskScheduler、按照Task调度算法对TaskManager进行排序、然后对Taskset进行分配资源)、\n\n## spark shuffle的细节\n先从spark shuffle的问题开始说起\n早期的spark shuffle存在两个问题1、如果map阶段的输出过大容易造成内存溢出OOM 2、如果reduce的数目过多、每个map的输出结果放到的分区数目过大、会使IO的资源消耗比较严重\n所以有了如下改进方法 \n1、map输出的结果不是一次性全部输出而是一部分一部分输出、当出现内存空间不足时再将部分数据写到磁盘中\n2、所有的map输出放到一个合并到一个busket、\n3、reduce也是逐条拉取、而不是一次性读取\n\n## spark的内存优化\nTungsten(钨)直接调用sun的api操作内存、所以不用再jvm上创建额外的类和对象\n\n## spark各组件间的通信\nDriver是spark的驱动程序、Driver上有一个心跳接收器HeartbeatReceiver、用来接收excutor的心跳信息、每个活跃的excutor都会定时向接收器发送HeartBeat消息\n具体的细节如下\n\n","tags":["spark"],"categories":["大数据"]},{"title":"RPC通信机制","url":"/2018/06/05/2018-6-5/","content":"<Excerpt in index | 首页摘要>\n初步实现简单RPC\n<!-- more -->\n\n先简单的说一下流程：客户端和服务端在两个不同的节点上、客户端想要调用远程服务端的方法、通过返回Proxy.newProxyInstance得到代理对象、再重写InvocationHandler里的invoke方法\n里面主要负责两个节点之间的通信、和方法的调用。通常的方法是通过一个注册中心来注册代理方法接口和代理方法所在类的字节码文件、但我尝试了很久并不能实现真正远程Rpc调用、\n于是采用服务端直接反射来得到代理方法所在类的字节码文件、反射所需要的参数只需通过客户端传过来即可、具体实现见代码。\n\n\n```java\n//定义要调用的远程接口名称\n\npublic interface RemoteMethed{\n    String remoteMethed(String name);\n}\n\n\n\n//远程方法实现类\npublic class RemoteMethedImpl implements RemoteMethed {\n    public String remoteMethed(String name) {\n        return \"excute remote methed \" + name;\n    }\n}\n\n\n\n//消息中心的实现类\n\npublic class ServiceCenterImpl {\n    private static ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());\n    private static int port;\n\n    public ServiceCenterImpl(int port) {\n        this.port = port;\n    }\n\n    public void start() throws IOException {\n        ServerSocket server = new ServerSocket();\n        server.bind(new InetSocketAddress(port));\n        System.out.println(\"start server\");\n        try {\n            while (true) {\n                // 1.监听客户端的TCP连接，接到TCP连接后将其封装成tas不，由线程池执行\n                executor.execute(new ServiceTask(server.accept()));\n            }\n        } finally {\n            server.close();\n        }\n    }\n\n    private static class ServiceTask implements Runnable {\n        Socket clent = null;\n        public ServiceTask(Socket client) {\n            this.clent = client;\n        }\n        public void run() {\n            ObjectInputStream input = null;\n            ObjectOutputStream output = null;\n            try {\n                // 2.将客户端发送的码流反序列化成对象，反射调用服务实现者，获取执行结果\n                input = new ObjectInputStream(clent.getInputStream());\n                //注册接口的全限定名---代理方法的字节码文件\n                //接口的全限定名\n                String serviceName = input.readUTF();\n                //代理方法名\n                String methodName = input.readUTF();\n                //Class<?>它是个通配泛型，?可以代表任何类型\n                //getClass，利用这个方法就可以获得一个实例的类型类。类型类指的是代表一个类型的类\n                Class<?>[] parameterTypes = (Class<?>[])input.readObject();\n                Object[] arguments = (Object[])input.readObject();\n                //代理方法的字节码文件\n                Class methodimpl = Class.forName(serviceName+\"Impl\");\n                //获得methodName方法，方法参数为parameterTypes\n                //表示方法的对象数组\n                Object result = methodimpl.getMethod(methodName, parameterTypes)\n                                .invoke(methodimpl.newInstance(), arguments);          \n                // 3.将执行结果反序列化，通过socket发送给客户端\n                output = new ObjectOutputStream(clent.getOutputStream());\n                output.writeObject(result);\n\n\n            } catch (Exception e) {\n                e.printStackTrace();\n            } finally {\n                if (output != null) {\n                    try {\n                        output.close();\n                    } catch (IOException e) {\n                        e.printStackTrace();\n                    }\n                }\n                if (input != null) {\n                    try {\n                        input.close();\n                    } catch (IOException e) {\n                        e.printStackTrace();\n                    }\n                }\n                if (clent != null) {\n                    try {\n                        clent.close();\n                    } catch (IOException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n\n        }\n    }\n}\n\n\n//定义客户端代理类\npublic class RPCClient <T>{\n    //<T>T相当于返回任意类型 代理哪个类就把哪个类的类加载器放进去\n    //在实例化泛型类时，必须指定T的具体类型\n    public static <T> T getRemoteProxyObj( Class<?> serviceInterface, final InetSocketAddress addr) {\n        // 1.将本地的接口调用转换成JDK的动态代理，在动态代理中实现接口的远程调用\n        //返回动态代理的接口\n        //把接口传进去、通过proxy代理再次访问接口方法时会调用对应的invoke方法\n        return (T) Proxy.newProxyInstance(serviceInterface.getClassLoader(), new Class<?>[]{serviceInterface},\n                new InvocationHandler() {\n                    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n                        Socket socket = null;\n                        ObjectOutputStream output = null;\n                        ObjectInputStream input = null;\n                        try {\n                            // 2.创建Socket客户端，根据指定地址连接远程服务提供者\n                            socket = new Socket();\n                            socket.connect(addr);\n                            // 3.将远程服务调用所需的接口类、方法名、参数列表等编码后发送给服务提供者\n                            output = new ObjectOutputStream(socket.getOutputStream());\n                            output.writeUTF(serviceInterface.getName());\n                            output.writeUTF(method.getName());\n                            output.writeObject(method.getParameterTypes());\n                            output.writeObject(args);\n                            // 4.同步阻塞等待服务器返回应答，获取应答后返回\n                            input = new ObjectInputStream(socket.getInputStream());\n                            //返回接口中的方法\n                            return input.readObject();\n                        } finally {\n                            if (socket != null) socket.close();\n                            if (output != null) output.close();\n                            if (input != null) input.close();\n                        }\n                    }\n                });\n    }\n}\n\n\n//启动客户端\npublic class Startclient {\n    public static void main(String[] args) throws ClassNotFoundException {\n        new Thread(new Runnable() {\n            @Override\n            public void run(){\n                RemoteMethed service =null;\n                try {\n                    //可以通过类名直接调类的静态方法或成员变量\n                    service = RPCClient.getRemoteProxyObj(RemoteMethed.class,\n                            new InetSocketAddress(\"localhost\", 9999));\n                }\n                catch (Exception e){\n                    e.printStackTrace();\n                }\n                System.out.println(service.remoteMethed(\"hello\"));\n                try {\n                    Thread.sleep(9999999);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        }).start();\n\n    }\n}\n\n\n//开启服务端\npublic class Run {\n    public static void main(String[] args) throws IOException {\n        new Thread(new Runnable() {\n            public void run() {\n                try {\n                    ServiceCenterImpl serviceServer = new ServiceCenterImpl(9999);\n                    serviceServer.start();\n\n                } catch (IOException e) {\n                    e.printStackTrace();\n                }\n            }\n        }).start();\n\n    }\n}\n\n\n\n\n```\n### 常见问题记录\n\n```\n//流的读取有时候会出现读取不到流的情况、可以把流的创建放到循环里面\nObjectInputStream objectInputStream = new ObjectInputStream(accept.getInputStream());\nObject b = objectInputStream.readUTF();\nwhile(true){\n\t// 可以放到这里面\n    // ObjectInputStream objectInputStream = new ObjectInputStream(accept.getInputStream());\n    // Object b = objectInputStream.readUTF();\n    System.out.println(b);\n    if(b!=null){\n    System.out.println(b);\n     }\n   }\n```\n\n\n\n\n\n\n\n\n\n\n","tags":["java"],"categories":["大数据"]},{"title":"安全检测","url":"/2018/05/03/2018-5-3 /","content":"<Excerpt in index | 首页摘要>\n某比赛要求在施工通过监控对没带安全帽的人进行报警\n<!-- more -->\n先吐槽一下比赛的主办方、给的测试视屏画质极低拍摄极为敷衍、有些人连人眼都无法识别是否带了安全帽、这小小的比赛大概整了整个51假期吧、\n## 简单介绍\n这里主要提供一下思路、传统ssd(高配电脑fater-rcnn走起)+inception3、你可能会问为什么不直接用ssd进行二次训练就好了、我当初也是这么想的这不是很简单么、\n然后我先把视频一帧帧的读取并转化成图像然后手动lable(这里有个问题就是一个图像中有多个人这样训练的时候会不会造成无法收敛？我觉得会有很大的影响)、\n然后训练这个像打了码一样的图片(再次吐槽一下主办方)、结果连人都识别不出来！！！内心极度奔溃、然后就用了独创非主流方法\n## 具体步骤(非主流方法请勿模仿、)\n鉴于之前连人都识别出来的问题、我就直接调用ssd先去除人、然后对有戴和没戴安全帽的进行训练(通过inception3)、然后运行通过ssd的目标检测结果输入到inception3中进行判别\n判别的结果传给之前的显示字符串然后进行输出、下面附上源码(目录与object_detection一致)\n\n```python\n#视频的读取得到识别物体后显示出来\nimport os\nimport cv2\nimport time\nimport numpy as np\nimport tensorflow as tf\n\nfrom utils.app_utils import FPS\nfrom object_detection.utils import label_map_util\nfrom object_detection.utils import visualization_utils as vis_util\n\nCWD_PATH = os.getcwd()\n\nMODEL_NAME = 'ssd_mobilenet_v1_coco_11_06_2017'\nPATH_TO_CKPT = os.path.join(CWD_PATH, 'object_detection', MODEL_NAME, 'frozen_inference_graph.pb')\nPATH_TO_LABELS = os.path.join(CWD_PATH, 'object_detection', 'data', 'mscoco_label_map.pbtxt')\n\nNUM_CLASSES = 2\nlabel_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n\ncategories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,\n                                                            use_display_name=True)\n\ncategory_index = label_map_util.create_category_index(categories)\n\ndef detect_objects(image_np, sess, detection_graph):\n    # 增加输入图像的维度: [1, None, None, 3]\n    image_np_expanded = np.expand_dims(image_np, axis=0)\n    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n    # 得到检测框\n    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n    #得到他的得分\n    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n    # Actual detection.\n    # 这里的class是包含多个识别种类的二维数组\n    #[[100,4]]boxes 每个框的位置坐标,    scores 100个 ,     classes 100个 ,    num_detections 100个\n    (boxes, scores, classes, num_detections) = sess.run(\n        [boxes, scores, classes, num_detections],\n        feed_dict={image_tensor: image_np_expanded})\n    # Visualization of the results of a detection.\n    vis_util.visualize_boxes_and_labels_on_image_array(\n        image_np,\n        np.squeeze(boxes),\n        np.squeeze(classes).astype(np.int32),\n        np.squeeze(scores),\n        category_index,\n        use_normalized_coordinates=True,\n        line_thickness=4,\n        min_score_thresh=0.5)\n    return image_np\n\nif __name__ == '__main__':\n    detection_graph = tf.Graph()\n    with detection_graph.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    sess = tf.Session(graph=detection_graph)\n    video_capture = cv2.VideoCapture('b.mp4')\n    fps = FPS().start()\n    frame_width = int(video_capture.get(3))\n    frame_height = int(video_capture.get(4))\n    # define video output\n    out = cv2.VideoWriter('outpy.mp4', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n    count = 0\n    while video_capture.isOpened():\n        ret, frame = video_capture.read()\n        t = time.time()\n        detected_image = detect_objects(frame, sess, detection_graph)\n        fps.update()\n        cv2.imshow('Video', detected_image)\n\t\t#本来想来做个更加流畅的优化、就是格一个帧进行识别、但还是会阻塞\n        #if count % 100 == 0:\n        #    print(count)\n        # write to video file\n        #out.write(detected_image)\n        # print('[INFO] elapsed time: {:.2f}'.format(time.time() - t))\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n\n    fps.stop()\n    video_capture.release()\n    sess.close()\n    cv2.destroyAllWindows()\n\n```\n```python\n#visualization_untils\n#第160行进行如下修改、check为inception3的入口、将图片和坐标传入\n  if use_normalized_coordinates:\n    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,\n                                  ymin * im_height, ymax * im_height)\n    \n    name=check(image.copy(), left, right, top, bottom)\n\t\n\t\n##188 行处\t\n#name为全局变量、接受inception3识别结果的字符串\ndraw.text(\n        (left + margin, text_bottom - text_height - margin),\n        name,\n        fill='black',\n        font=font)\n\n```\n\n```python\n\n#check模块、inception3的入口\nimport tensorflow as tf\nimport numpy as np\nfrom pylab import array\n\ndef check(image,left, right, top, bottom):\n    got = array(image)\n    crop_img = got[int(top):int(bottom), int(left):int(right), 0:3]\n\t#载入之前自己训练的模型\n    with tf.gfile.FastGFile('output_graph.pb', 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        tf.import_graph_def(graph_def, name='')\n\n    with tf.Session() as sess:\n        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n\t\t#将传入的图片格式转化一下\n        first = tf.image.convert_image_dtype(crop_img, dtype=tf.float32)\n        # jpeg 进行编码\n        # eval()想当于将tensorflow的存储格式中提取出来以数组的格式\n        encode = tf.image.encode_jpeg(first.eval())\n        #将编码好的图片传入以decodejpeg的格式\n        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': encode.eval()})  # 图片格式是jpeg格式\n        predictions = np.squeeze(predictions)  # 把结果转为1维数据\n        top_k = predictions.argsort()[::-1]\n        if top_k[0]==1:\n            human_string=\"unsafe\"\n        else:\n            human_string=\"safe\"\n        return human_string\n        #返回给画框的代码\n```\n\n## 总结\n看似十分完美流程的过程在实际运行时由于笔记本配置低下(好想要GPU的台式机！！)、换了一台配置稍微高一点的本、但还是崩了、tensorflow开两个session的内存消耗比想象中的要大、开\n看来这操作只能是活在梦里了、希望以后能想出一种底层之间的优化(相比之前的已经做了很多IO的优化、但主要问题还是这是线性的操作、一定有卡顿来进行二次判断)\n\n## 更新！！！\n终于找到了问题所在！！原来每一帧的图像传入后都要重新加载一次graph！！所以导致内存直接爆炸！改动后可以跑的动了、但比较吃配置配置高一点的话可以更加流畅吧、\n具体改动如下、其余的改动就是要在每个调用的visualization_utils中的函数里传入初始化的graph、具体修改如下、整个项目会放到github上\n\n```python\n#主要是对main函数下的修改vediondetection.py\n\nif __name__ == '__main__':\n    #tf.Graph()生成新的图\n    detection_graph = tf.Graph()\n    inceptionsess =tf.Graph()\n    with inceptionsess.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.FastGFile('output_graph.pb', 'rb') as f:\n            serialized_graph = f.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n\n    with detection_graph.as_default():\n        od_graph_def = tf.GraphDef()\n        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n            serialized_graph = fid.read()\n            od_graph_def.ParseFromString(serialized_graph)\n            tf.import_graph_def(od_graph_def, name='')\n    sess = tf.Session(graph=detection_graph)\n    video_capture = cv2.VideoCapture('b.mp4')\n    fps = FPS().start()\n    frame_width = int(video_capture.get(3))\n    frame_height = int(video_capture.get(4))\n    # define video output\n    out = cv2.VideoWriter('outpy.mp4', cv2.VideoWriter_fourcc('M', 'J', 'P', 'G'), 10, (frame_width, frame_height))\n    count = 0\n    while video_capture.isOpened():\n        ret, frame = video_capture.read()\n        t = time.time()\n        detected_image = detect_objects(frame, sess, detection_graph,inceptionsess)\n        fps.update()\n        out.write(detected_image)\n        cv2.imshow('Video', detected_image)\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    fps.stop()\n    video_capture.release()\n    sess.close()\n    cv2.destroyAllWindows()\n```\n\n\n```python\n#对checker类的方法进行的改动\n\ndef check(image,left, right, top, bottom,inceptionsess):\n    got = array(image)\n    crop_img = got[int(top):int(bottom), int(left):int(right), 0:3]\n    # with tf.gfile.FastGFile('output_graph.pb', 'rb') as f:\n    #     graph_def = tf.GraphDef()\n    #     graph_def.ParseFromString(f.read())\n    #     tf.import_graph_def(graph_def, name='')\n    with tf.Session(graph=inceptionsess) as sess:\n        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n        # jpeg 进行编码\n        # \"\"\"Return the value of the tensor represented by this handle.\"\"\n        encode = tf.image.encode_jpeg(crop_img)\n        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': encode.eval()})  # 图片格式是jpg格式\n        predictions = np.squeeze(predictions)  # 把结果转为1维数据\n        top_k = predictions.argsort()[::-1]\n        if top_k[0]==1:\n            human_string=\"unsafe\"\n        else:\n            human_string=\"safe\"\n        return human_string\n\n```\n\n","tags":["图像识别"],"categories":["深度学习"]},{"title":"定点识别","url":"/2018/04/08/2018-4-8/","content":"<Excerpt in index | 首页摘要>\n基于object_detection训练自己的模型\n<!-- more -->\n花了不知道多少天、、主要参加一个定点识别的比赛、算是把模型搞定了、虽然结果十分的令人喜感（哈哈、不说了）、、难度有一点大（主要是各种天坑、在这里记录一下）\n\n这是阿里天池的比赛、比赛给出上万张图片主要是服装、要在每个图片上识别出服装每个关键点、并将识别结果的坐标输出、比如左袖口什么的、差不多有24个标签吧、训练集给出的是每个图片的所有关键点的坐标、我的思路是先根据坐标\n转化成矩形框(同时对x和y加上自己定义的距离数)、然后通过object_detection确定定位的位置、最后在进行输出(求两个x和两个y的平均来得到中心点)、具体步骤如下：\n\n## 根据lable切分图片\n\n这个脚本主要是根据lable对图片进行切分、根据lable创建若干个文件夹、切好的图片放到每个对应的文件加下、切分完得到几十万张图片(此刻的内心是奔溃的)、\n```python\nimport csv\nimport cv2\nimport os\n\npath=os.getcwd()\n#自己定义框的宽度wide\ndef drawcnts_and_cut(original_img,x,y,wide):\n    x1=x-wide\n    x2=x+wide\n    y1=y-wide\n    y2=y+wide\n    crop_img = original_img[y1:y2, x1:x2]\n    return  crop_img\n\ndef start(img_path,save_path,x,y):\n    original_img= cv2.imread(img_path)\n    crop_img = drawcnts_and_cut(original_img,int(x),int(y),25)\n    cv2.imwrite(save_path, crop_img)\ndef datatranslate(data):\n    splited=str(data).split()\n    return splited[0],splited[1]\n\t\n#自己根据标签数量来改\nlable=['class1', 'class2']\t\ncsv_reader = csv.reader(open('train\\\\input.csv', encoding='utf-8'))\nnum=0\nfor row in csv_reader:\n    for i in range(2,26,1):\n        photo=row[0]\n        data=row[i]\n        category=lable[i]\n        splited = str(row[i]).split(\"_\")\n        print(photo)\n        print(num)\n        if int(splited[0])!=-1:\n            lib = path + \"\\\\train\\\\\"+photo\n            savepath=path+\"\\\\output\\\\\"+str(category)+\"\\\\\"+str(category)+\"+\"+str(num)+\".jpg\"\n            num+=1\n            start(lib,savepath,splited[0],splited[1])\n\t\t\t\n```\n\n\n## 将图片转化为对应的xml文件\n\n默认的边框大小为整个图片的d、长度和宽度可以从图片中获取、最终批量的生成xml文件（突然想起比赛的图片切分后生成的30万个文件、还只能分批次的复制、一复制就卡屏、迷醉、、）\n```python\nimport os, sys\nimport glob\nfrom PIL import Image\n\n#根据实际来添加class\nlist=[\"class1\",\"class2\"]\nfor a in list:\n    path=os.getcwd()\n    #图像存储位置\n    src_img_dir = path+\"\\\\input2\\\\\"+a\n    # xml文件存放位置\n    src_xml_dir = path+\"\\\\input2\\\\\"+a\n    img_Lists = glob.glob(src_img_dir + '\\*.jpg')\n    img_basenames = [] \n    for item in img_Lists:\n        img_basenames.append(os.path.basename(item))\n    img_names = [] \n    for item in img_basenames:\n        temp1, temp2 = os.path.splitext(item)\n        img_names.append(temp1)\n    for img in img_names:\n        im = Image.open((src_img_dir + '/' + img + '.jpg'))\n        width, height = im.size\n        xml_file = open((src_xml_dir + '/' + img + '.xml'), 'w')\n        xml_file.write('<annotation>\\n')\n        xml_file.write('    <folder>'+a+'</folder>\\n')\n        xml_file.write('    <filename>' + str(img) + '.jpg' + '</filename>\\n')\n        xml_file.write('    <path>' + path +\"\\\\input2\\\\\"+a+\"\\\\\"+ str(img) + '.jpg'+ '</path>\\n')\n        xml_file.write('    <size>\\n')\n        xml_file.write('        <width>' + str(width) + '</width>\\n')\n        xml_file.write('        <height>' + str(height) + '</height>\\n')\n        xml_file.write('        <depth>3</depth>\\n')\n        xml_file.write('    </size>\\n')\n        xml_file.write('        <segmented>0</segmented>\\n')\n        xml_file.write('    <object>\\n')\n        xml_file.write('        <name>' + str(img) + '</name>\\n')\n        xml_file.write('        <pose>Unspecified</pose>\\n')\n        xml_file.write('        <truncated>1</truncated>\\n')\n        xml_file.write('        <difficult>0</difficult>\\n')\n        xml_file.write('        <bndbox>\\n')\n        xml_file.write('            <xmin>' + \"0\" + '</xmin>\\n')\n        xml_file.write('            <ymin>' + \"0\" + '</ymin>\\n')\n        xml_file.write('            <xmax>' + str(width) + '</xmax>\\n')\n        xml_file.write('            <ymax>' + str(height) + '</ymax>\\n')\n        xml_file.write('        </bndbox>\\n')\n        xml_file.write('    </object>\\n')\n        xml_file.write('</annotation>')\n\t\t\n```\n##\txml转csv文件合并csv文件\n\n要使用如下脚本将xml文件转化为csv文件、最后再把每个目录下的csv文件进行合并（注意删除重复的lable）\n\n```python\n#xml转csv文件合并csv文件\n\nimport os\nimport glob\nimport pandas as pd\nimport xml.etree.ElementTree as ET\ntag=['class1','class2']\nnum=0\n\ndef xml_to_csv(path):\n    xml_list = []\n    for xml_file in glob.glob(path + '/*.xml'):\n        tree = ET.parse(xml_file)\n        root = tree.getroot()\n        for member in root.findall('object'):\n            value = (root.find('filename').text,\n                     int(root.find('size')[0].text),\n                     int(root.find('size')[1].text),\n                     root.find('folder').text,\n                     int(member[4][0].text),\n                     int(member[4][1].text),\n                     int(member[4][2].text),\n                     int(member[4][3].text)\n                     )\n            xml_list.append(value)\n    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n    xml_df = pd.DataFrame(xml_list, columns=column_name)\n    return xml_df\n\n\ndef main():\n    for a in tag:\n        image_path = os.path.join(os.getcwd(), 'input2\\\\'+a)\n        xml_df = xml_to_csv(image_path)\n        xml_df.to_csv('data\\\\'+str(a)+'.csv',index=None)\n        print('Successfully converted xml to csv.')\n\n\nmain()\n```\n通过shell批量合并csv\n```shell\n@echo off\nE:\ncd add\ndir\ncopy *.csv all_keywords.csv\necho 合并成功！'\npause\n```\n\n## 调用object_detection前的准备\n\n下面是很有参考性的博客和官方的地址\n[https://blog.csdn.net/honk2012/article/details/79099651](https://blog.csdn.net/honk2012/article/details/79099651)\n[https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md)\n可以翻墙的话推荐下面这篇、这个towardsdatascience还是很不错的\n[https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9](https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9)\n基本后面的训练和模型的调用都是在github上的、想普通的个人电脑用ssd的一个mobile就行了、别的根本跑不动、batch设置的越大每次迭代的时间越长、如果太大电脑配置不够的话你就可以重新开机了、、\n顺便说说几个坑官方步骤中的 protoc object_detection/protos/*.proto --python_out=. 如果是在window下要下载3.4版本的3.5会有bug\nobject_detection初始化一定要先执行、不然会给你各种报错、、\n官方文档中export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim  如果是windows下执行要用这个命令(查了很久用了很多的坑爹方法、只能说项目对windows不友好)SET PYTHONPATH=%cd%;%cd%\\slim  执行目录还是不变\n注意这几个坑基本就会很顺畅了、还有一些其他小坑一时想不起来、想到了再加、\n\n\n\n\n\n","tags":["图像识别"],"categories":["深度学习"]},{"title":"博客搬家","url":"/2018/03/23/2018-3-23/","content":"<Excerpt in index | 首页摘要>\n无意间看到了Hexo的这个黑蓝主题、实在是太cool了！！抽空用了两个晚上搬家\n<!-- more -->\n原来的博客一直是用的是jekyll(差点又拼错、)、还是很方便不过还是有很多弊端\n\n1、代码高亮、现在看看原来的博客这代码高亮、、简直无法直视、虽然后来另外装了插件但还是惨不忍睹(主要是这个主题的高亮真的是太漂亮了、看了会上瘾、、)\n2、由于原来的博客用的是老外的主题为了实现想要的效果文字间的空格符有点受不了、十分影响美观、还有字体(这里支持一下国产、、)\n3、这个主题有分类功能、随着博客的增多查找也比原来的方便、\n4、也是主要原因、、就是想换、笑死、、、\n\n现在终于换好了、过程也十分折腾、也遇到了各种坑、什么Hexo的版本问题、server要独立安装、、、希望这博客可以用几年吧、、同时再次感谢maochunguang提供的主题\n\n前端真的是一个十分神奇的东西、、但真的没工夫投在上面学了、还有评论功能、看了大佬的主题demo觉得加了评论就不是十分洁简了、于是就不做了（绝不是因为懒）、、\n\n最后注意我的背景:它是会变的哦、、、\n","tags":["other"],"categories":["other"]},{"title":"基于卷积的图片识别","url":"/2018/03/21/2018-3-22/","content":"<Excerpt in index | 首页摘要>\n这篇博客主要介绍通过Tesorflow来实现对图片的识别\n<!-- more -->\n\n学习深度学习断断续续也将近半年了、从去年暑假接触tensorflow一步步从入门到放弃、又继续现在才算明白每一步做的是什么、本来想深入研究词向量分析做一个在线翻译的小项目和属于自己的siri（这一定非常cool）、在导师的建议下先从图像识别做起、语义模型的确太复杂了只能怪中国语言博大精深（笑死、、）可能做了一两年最终的结果将会出乎意料的喜感、不得不赞叹一下油管、、在线翻译实在是太强大了要是哪天能在谷歌工作就好了、不知不觉敲了好多废话、该写总结了\n以下是写的很详细详细的链接、看不懂的可以再细细的看这个链接看个权重的动态图就行了、绝对精髓\n[https://www.2cto.com/kf/201607/522441.html](https://www.2cto.com/kf/201607/522441.html)\n\n首先从输入的图片开始、mnist是28x28的单颜色通道的图片、训练时读取的是[batchsize,784]的数组、要转化为tensorflow卷积支持的输入格式[batchsize,28,28,1]、第二、三个表示几乘几的图片、最后一个表示颜色通道、这里为1因为是灰度图、接下来定义卷积的权重、就是你要定义一个移动的的过滤器来扫描这个图片以及若干个内核来存储扫描器与图片权值相乘再加上偏置值的一个结果、最终就可以得到卷积层的输出、需要定义的参数参考这篇博客十分的详细\n[https://www.cnblogs.com/qggg/p/6832342.html](https://www.cnblogs.com/qggg/p/6832342.html)\n\n卷积层得到输入后将其导入池化层、池化层大大减小了变量的个数（真的十分敬佩模型的创始人、真的太厉害了）、池化层也有类似的过滤器如果用的是max_pool相当于扫描一个区域、选出区域中最大的一个值输出、按照步长移动再扫描输出、从而最终达到简化参数的目的、池化层输出后将结果导入全连结层、然后就是固定的套路了、\n\n具体代码如下\n```python\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\n\nmnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)\nbatch_size=100\nn_batch=mnist.train.num_examples//batch_size\n\n\ndef weight_init(shape):\n    init=tf.truncated_normal(shape=shape,stddev=0.1)\n    return tf.Variable(init)\n\ndef bias_init(shape):\n    init=tf.constant(0.1,shape=shape)\n    return  tf.Variable(init)\n\ndef conv2d(input,w):\n    return tf.nn.conv2d(input,w,strides=[1,1,1,1],padding='SAME')\n\ndef pool(input):\n    return tf.nn.max_pool(input,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n\nx=tf.placeholder(tf.float32,[None,784])\ny=tf.placeholder(tf.float32,[None,10])\n#全0填充从一开始移动\ninput=tf.reshape(x,[-1,28,28,1])\n#定义卷积的深度为32\n#第一层卷积的输入[128,28,28,1]\nw_conv1=weight_init([5,5,1,16])\nb_conv1=weight_init([16])\n#定义的是same有0来填充每次管道的核心将会一次经过每个像素点\nconv1=tf.nn.relu(conv2d(input,w_conv1)+b_conv1)\n#第一层卷积输出[128,28,28,16]\n\n#池化层只在指定的2，3维度上进行池化\n#得到池化层的输出[128,14,14,16]\npool1=pool(conv1)\n\n#对应池化层的输出所以第三位为32此处定义深度为64\nw_conv2=weight_init([5,5,16,64])\nb_conv2=weight_init([64])\n\n#卷积的输出[128,14,14,64]\nconv2=tf.nn.relu(conv2d(pool1,w_conv2)+b_conv2)\n#得到池化的最终输出[128,7,7,64]\npool2=pool(conv2)\n\n#定义全连结层的权重\nweight=weight_init([7*7*64,500])\nbias=bias_init([500])\n\nnormal=tf.reshape(pool2,[-1,7*7*64])\n#[-1,1024]\noutput1=tf.nn.relu(tf.matmul(normal,weight)+bias)\nkeep=tf.placeholder(tf.float32)\n#定义dropout防止过拟合对提高准确率有很大的帮助\ndrop=tf.nn.dropout(output1,keep)\n\nweight2=weight_init([500,10])\nbias2=bias_init([10])\n#最终得到的输出数组的每一个权值不一定是0，1、Softmax然后会正则化这些权重值、使它们的总和等于1、以此构造一个有效的概率分布\nprediction=tf.nn.softmax(tf.matmul(drop,weight2)+bias2)\n\ncross_entropy=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))\n#这里用AdamOptimizer的效果要比梯度下降要好\ntrain_step=tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\ncorrect_prediction=tf.equal(tf.arg_max(prediction,1),tf.arg_max(y,1))\naccuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    for epoch in range(100):\n        for batch in range(50):\n            batch_xs,batch_ys =mnist.train.next_batch(batch_size)\n            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys,keep:0.7})\n        acc=sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels,keep:1.0})\n        print('iter'+str(epoch)+\"  correct \"+str(acc))\n    input_image = mnist.train.images[11:12]\n    # 可视化卷积层学习到的特征\n    # 输入一张图片\n    cnn1=sess.run(w_conv1, feed_dict={x:input_image})\n    conv1_reshape = sess.run(tf.reshape(cnn1, [5, 5, 1, 16]))\n    plt.figure()\n    # 放在两行两列第一个位置#将舍去数组的后两位\n    plt.subplot(2, 2, 1)\n    # 将舍去数组的后两位\n    plt.imshow(conv1_reshape[:,:,0,0])\n    plt.title('Conv1 16x28x28')\n    plt.show()\n\n```\n## 参数的计算\n假设N*N为输入图像的size、F*F是filter(卷积核)的size、stride(即卷积核每次移动的像素)是滑动的步长。\n那么一次卷积之后输出的第一个维度为(N-F)/stride +1\n\n下面是一篇关于交叉熵的问题的博客\n[http://blog.csdn.net/john_xyz/article/details/61211422](http://blog.csdn.net/john_xyz/article/details/61211422)\n笔记本配置比较一般、渴望gpu来拯救、由于训练的比较慢又要不断调整参数最终准确率在97%以上是没问题的\n## 图像识别\n一般做图像识别用到的模型在github上都开源出来了、比如inception3就有基于Tensorflow的了、用inception3训练自己模型时卷积层的参数大致是不变的改变的是顶部神经元的参数\n前面的操作差不多做的是特征提取、所以用自己的数据训练后得到的结果还是不错的、\n下面是谷歌物体识别的连接、下面的模型可以拿来直接用不用自己一层一层搭网络、里面也有已经训练好的模型(当自己想要做点什么的时候谷歌都做好了、、、)\n[https://github.com/tensorflow/models/tree/master/research/object_detection](https://github.com/tensorflow/models/tree/master/research/object_detection)\n环境搭建推荐linux、windows的坑太多浪费了好长时间、官方给的教程十分精辟、要注意每次敲命令行要严格！！！对应注释中给的目录\n最后还可以训练自己的数据集、教程官方github上也有、网上的教程也十分多参照一下就好了（不想再做验证性工作了）、、\n","tags":["cnn"],"categories":["深度学习"]},{"title":"Java Future","url":"/2018/02/22/2018-2-22/","content":"<Excerpt in index | 首页摘要>\n这篇博客主要简单介绍future模式的原理\n<!-- more -->\n**future模式的作用:** 在多线程开发中、当客户端通过发送一个请求去得到某个资源、服务端异步的在后台另起 一个线程去获取资源、而客户端无需一直等待取资源的过程、仍然可以做其他的事情、具体的过程图如下\n<img src=\"http://aRootUser.github.io/img/8/1.png\">\n**具体代码实现过程：** 定义Data接口、Realdata和futuredata都要实现这个接口、在futureClient中定义main方法、首先调用FutureClient中的call\n方法(通过wait等待被唤醒)、另起一个线程(在这个线程中装载realdata、在realdata中延迟5秒来模拟数据查询)、当数据查询完毕后装载数据\n在FutureData的setRealdata中来通过notify唤醒之前wait的方法最终得到查询结果、\n```java\n\npublic interface Data {\n\tString call();\n}\n\npublic class FutureClient{\n\tpublic static void main(String[] args) {\n\t\tFutureClient fc=new FutureClient();\n\t\t//返回futuredata、调用call方法\n\t\tData data=fc.call(\"8888\");\n\t\tSystem.out.println(\"请求成功做其他事\");\n\t\tString result=data.call();\n\t\tSystem.out.println(\"查询结果为\"+result);\n\t}\n//返回一个接口\n\tpublic Data call(String a) {\n\t\tFutureData fd=new FutureData();\n\t\tnew Thread(new Runnable() {\n\t\t\tpublic void run() {\n\t\t\t\tRealData rd=new RealData(a);\n\t\t\t\tfd.setRealdata(rd);\n\t\t\t}\n\t\t}).start();\n\t\tSystem.out.println(\"返回futuredata对象\");\n\t\treturn fd;\n\t}\n}\n\n\npublic class RealData implements Data{\n\tString result;\n\t//构造方法来实现查询\n\tpublic RealData(String realdata) {\n\t\tSystem.out.println(\"查询号码\"+realdata);\n\t\ttry {\n\t\t\tThread.sleep(5000);\n\t\t} catch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t\tSystem.out.println(\"查询完毕\");\n\t\tresult=\"1\";\n\t}\n\tpublic String call(){\n\t\treturn result;\n\t}\n\n}\n\n\npublic class FutureData implements Data{\n\tString data;\n\tRealData realdata;\n\tboolean isready=false;\n\tpublic synchronized void setRealdata(RealData realData){\n\t\tif(isready){\n\t\t\treturn;\n\t\t}\n\t\t//如果没装载进行装载真实对象\n\t\tthis.realdata=realData;\n\t\tisready=true;\n\t\tnotify();\n\t\tSystem.out.println(\"唤醒另一个线程\");\n\t}\n\tpublic  synchronized String call() {\n\t\twhile(!isready) {\n\t\t\ttry {\n\t\t\t\tSystem.out.println(\"futuredata.call\");\n\t\t\t\twait();\n\t\t\t\tSystem.out.println(\"线程已被唤醒\");\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t}\n\t\t}\n\t\treturn this.realdata.call();\n\t}\n}\n\n//运行结果如下\n//返回futuredata对象\n//请求成功做其他事\n//查询号码8888\n//查询完毕\n//唤醒另一个线程\n//线程已被唤醒\n//查询结果为1\n\n```\n\n\n\n\n\n\n\n\n","categories":["大数据"]},{"title":"Lstm入门","url":"/2018/02/10/2018-2-10/","content":"<Excerpt in index | 首页摘要>\nlstm来实现手写数字识别\n<!-- more -->\n\n## lstm 简 介\nlstm的设计解决了传统RNN对于长期时间依赖的局限性、通过训练遗忘门来决定丢弃没有用的信息、记忆门来更新lstm的状态并把状态传递给下一个lstm、每个lstm的输入包括上一个lstm的输出和状态、更多细节参考下面的博客\n[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n## lstm实现手写数字识别的基本步骤(基于tensorflow)\n由于输入的是(28,28,batchsize)的三维的数据、所以要对其进行切分将其转换成(28*batchsize,28)二维的数据然后再一行一行的将其输入值lstm、lstm内部的具体实现tensorflow内部已经封装好了只用初始化和定义遗忘率、最后lstm的最后一个输出进行softmax归一化、\n梯度下降来迭代参数从而使模型达到较高的准确率、下面的代码可以达到97%左右的准确率\n基于tensorflow的python实现\n```python\n\nfrom tensorflow.examples.tutorials.mnist import input_data\nimport tensorflow as tf\n\nmnist=input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n#设置每次训练批次数\nbatchsize=128\n\nweights=tf.Variable(tf.random_normal([28,10]))\nbases=tf.Variable(tf.random_normal([10]))\ndef setrnn(input):\n    #将输入转化为(128batches*18steps,28input)[1,0,2]表示交换的序列\n    input=tf.transpose(input,[1,0,2])\n\t#将数据转化为二维度第二维为28\n    input=tf.reshape(input,[-1,28])\n\t#将每一个图片按照行进行切分一共28行\n    split=tf.split(input,28,0)\n    lstm=tf.nn.rnn_cell.BasicLSTMCell(28,forget_bias=0.1,state_is_tuple=True)\n    output,state=tf.nn.static_rnn(lstm,split,dtype=tf.float32)\n    result=tf.matmul(output[-1],weights)+bases\n    return  result\n\nx=tf.placeholder(\"float\",[None,28,28])\ny=tf.placeholder(\"float\",[None,10])\nRnn=setrnn(x)\npredit=Rnn\nloss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predit,labels=y))\noptm=tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n#计算准确率\ncorrecrresult=tf.equal(tf.argmax(y,1),tf.argmax(predit,1))\ncorrectmean=tf.reduce_mean((tf.cast(correcrresult,tf.float32)))\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n\t#一共进行多少次迭代\n    for a in range(900):\n\t    #一次跌代的图片数量\n        total=1000\n        for i in range(total):\n            batch_x ,batchy=mnist.train.next_batch(batchsize)\n            batchx=batch_x.reshape((batchsize,28,28))\n            sess.run(optm,feed_dict={x:batchx,y:batchy})\n            if i==1:\n                print(a,sess.run(loss,feed_dict={x:batchx,y:batchy}),sess.run(correctmean,feed_dict={x:batchx,y:batchy}))\n\n```\n\n\n\n\n\n\n\n\n\n","tags":["tensorflow"],"categories":["深度学习"]},{"title":"K-近邻算法Python实现","url":"/2018/01/30/2018-1-30/","content":"<Excerpt in index | 首页摘要>\n运用python通过计算距离来实现对某花的分类\n<!-- more -->\n## 算法解决的问题\n已知样本集（此处的样本为某花的实例数据）、给定一未知样本的数据来断此样本的类别(此处为判断属于哪一类花）\n## 解决步骤\n特征抽取后计算出未知样本到所有已知样本的距离、根据给定参数K（最好为奇数便于投票）选出K个最近的样本点、统计出类别最多的样本点的类别、最终的的分类就是该类别\n缺陷：数据的分布不均匀会导致结果的不准确\n优化方法：根据距离的远近添加相应的权重来弱化数据分布不均匀的为题（下面代码还没实现权重的添加、、以后有空再加、、、）\n个人脑洞：对于多维的数据、在二维分布上可能看不出任何规律、但在高维的空间中明显的可以分开好几个类别（如本例的某花数据在三维下就很明显了、还有支持向量机的划分方法太cool了）\n此处的样本集（非常nice的数据集大全）\n[http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data](http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data)\n样本集示例：前四列为花的数据、最后为花的类别\n\n5.1,3.5,1.4,0.2,Iris-setosa\n\n5.0,3.3,1.4,0.2,Iris-setosa\n\n7.0,3.2,4.7,1.4,Iris-versicolor\n\n4.6,3.1,1.5,0.2,Iris-setosa\n\n6.4,3.2,5.3,2.3,Iris-virginica\n\n6.9,3.2,5.7,2.3,Iris-virginica\n\n4.6,3.4,1.4,0.3,Iris-setosa\n\n代码实现如下：用测试集测试可以达到96%的准确率\n\n```python\n\nimport csv\nimport math\nfrom collections import Counter\n\n#导入样本集list\n#导入测试集计算测试集到每个样本集的距离,结果保存为list\n#根据distance排名取k个投票选出最多的这个类\n\n\n#传递时要第二个参数要为空参否则会共用同一个地址\ndef readfile(local):\n    dataset=[]\n    with open(local) as file2:\n        csv_reader = csv.reader(file2)\n        for line in csv_reader:\n            dataset.append(line)\n    return dataset\n\n\ndef distance (test,train):\n    result=0.0\n    #此时每个test例如[1,2,3,4]每个train例如[1,2,3,4,a],-1除去标签\n    for i in  range(len(test)-1):\n        result=result+math.sqrt(abs((float(test[i])-float(train[i]))*(float(test[i])+float(train[i]))))\n    return result\n\ndef sort(train,test,k=3):\n    result=[]\n    sortresult=[]\n    #计算每个样本集到样本的距离\n    for i in range(len(test)):\n        for m in range(len(train)):\n            #对于每个测试实例得到距离和对应的标签\n            result.append([distance(test[i],train[m]),train[m][-1]])\n        sortresult.append(findsort(result,k))#得到每一个测试集的分类结果\n        result=[]                            #将每个测试集的距离集合清空\n    return sortresult       #最终结果\n    #得到结果集，每一个test到样本集的距离\n\n#示例输入[[3.917258917468777, 'Iris-setosa'], [4.365595716195167, 'Iris-setosa']]\ndef findsort(data,k=3):\n    result={}\n    voat=[]\n    for x in range(len(data)):\n            result.update({data[x][0]:data[x][1]})\n    #对字典进行排序从小到大\n    a=sorted(result.items(), key=lambda d: d[0])\n    for m in range(k):\n         voat.append(a[m][-1])\n    #得到列表中出现次数最多的元素\n    b=Counter(voat).most_common(1)\n    return b[0][0]\n\n#计算准确率\ndef correct(sample,predict):\n    flag=0\n    for a in range(len(sample)):\n        if(sample[a]==predict[a]):\n            flag=flag+1\n    return flag/len(sample)\n\ndef main():\n    testlist=[]\n    train=list(readfile(\"F:\\\\train.csv\"))\n    test=list(readfile(\"F:\\\\test.csv\"))\n    #k为最近邻的个数\n    output=sort(train,test,3)\n    #得到分类的结果集\n    print(output)\n    for a in range(len(test)):\n        testlist.append(test[a][-1])\n    #输出准确率\n    print(correct(testlist,output))\nmain()\n\n```\n\n\n\n\n\n\n\n\n\n\n","tags":["python"],"categories":["机器学习"]},{"title":"数据集生成器","url":"/2018/01/27/2018-1-27/","content":"<Excerpt in index | 首页摘要>\n运用java来实现自定义的数据集\n<!-- more -->\n\n使用说明这是一个用java写的用户自定义数据集生成器、目前只支持日期用户名和用户标识三个字段、由于是1.0版本功能比较少、\n为了满足大数据自定义的数据来源将继续开发(今天玩spark竟找不到想要的数据集、、)、整个项目已经发布在github上、程序的入口在main class、\n运行时要先配置好setting.properties在里面要定义好所需要的字段的种类数、注意输入必须为大于等于1的正整数、并且sum的值至少为6、\n运行成功后将在相对路径下生成result数据集、有空会用python来重写整个项目(有空练练python、其实也是挺好玩的)、项目难度不大具体源码的介绍如下、\n程序定义4个类分别为主类、日期类、标识类、用户id类、初始化自定义数量后通过三个类返回的容器进行汇总、最后通过文本文件输出\n目前需要改进的地方：日期库、、程序写死了还不能实现真正意义上的用户自定义\n\n```java\n\npublic class Mainclass {\n\t\n\tstatic int idnum ;   \t//定义不同id的个数\n\tstatic int flagnum ; \t//定义不同行为标记的个数\n\tstatic int sum ;      \t//定义数据集的总行数\n\n\t//初始化成员变量\n\tstatic {\n\t\tResourceBundle set=ResourceBundle.getBundle(\"setting\");\n\t\tidnum=Integer.parseInt(set.getString(\"idnum\"));\n\t\tflagnum=Integer.parseInt(set.getString(\"flagnum\"));\n\t\tsum=Integer.parseInt(set.getString(\"sum\"));\n\t\t}\n\t\n\n\tpublic static void main(String[] args) throws Exception{\n\t\n\t\tArrayList<String> flager= new Flag(flagnum,sum).create();\n\t\tArrayList<String> dater= new Data(sum).create();\n\t\tArrayList<String> ider= new Id(idnum,sum).create();\n\t\tArrayList<String> result= new ArrayList<String>();\n\t\t\n\t\t//将所有结果进行横向组合\n\t\tfor(int i=0;i<=sum-1;i++) {\n\t\t\tresult.add(dater.get(i)+\"    \"+ider.get(i)+\"    \"+flager.get(i));\n\t\t}\n\n\t\t//在相对路径下生成结果文件\n\t\tBufferedWriter bw=new BufferedWriter(new FileWriter(\"result.txt\"));\n\t\tIterator<String> it = result.iterator();  \n\t        while(it.hasNext()){  \n\t            bw.write(it.next());\n\t            bw.newLine();\n\t            bw.flush();\n\t        } \n        bw.close();\n\t}\n\n}\n \n \n \n \n public class Data {\n\tint sum;\n\tData(int sum){\n\t\tthis.sum=sum;\n\t}\n\tpublic ArrayList<String> create() {\n\t\tArrayList<String> data=new ArrayList<String>();\n\t\t//自定义日期库\n\t\tString datasort[]= {\"2018-1-1\",\"2018-1-2\",\"2018-1-3\",\"2018-1-4\",\"2018-1-5\",\"2018-1-6\"};\n\t\ttry {\n\t\t\tint  avg=sum/6;                        //定义一个数来平均分配日期\n\t\t\tfor(int a=0,i=-1;a<=sum-1;a++){       //因为0是必定可以被整除的所以i初始值为-1\n\t\t\t\tif(a%avg==0) {\n\t\t\t\t\ti++;\n\t\t\t\t}\n\t\t\tif(i>5){i=5;}\n\t\t\tdata.add(String.valueOf(datasort[i]));\t//日期库从0开始\n\t\t    }\n\t\t} \n\t\tcatch (Exception e) {\n\t\t\tSystem.out.println(e.getMessage()+\"sum的值至少为6\");\n\t\t}\n\t\t\n\t\treturn data;\n\t}\n}\n\n\n\n\n\npublic class Flag {\n\tint flagnum;\n\tint sum;\n\tString nameid;\n\tFlag(int flagnum,int sum){\n\t\tthis.flagnum=flagnum;\n\t\tthis.sum=sum;\n\t}\n\t\n\tpublic ArrayList<String> create() {\n\t\tArrayList<String> list=new ArrayList<String>();\n\t\t//存放生成的名字\n\t    String name[]=new String[flagnum];\n\t    for(int a=0;a<=flagnum-1;a++) {\n\t    \t//从0开始定义flag\n\t    \tnameid=String.valueOf(a);\n\t    \tname[a]=nameid;\n\t    }\n\t\t//根据名字组合随机生成id  \n\t\tfor(int a=0;a<=sum-1;a++) {\n\t\t\tlist.add(name[(int)(Math.random()*flagnum)]);\n\t\t}\n\t\treturn  list;\n\t}\n}\n\n\npublic class Id {\n\tint idnum;//不同名字的数量\n\tint sum;\n\tString nameid;\n\tId(int idnum,int sum){\n\t\tthis.idnum=idnum;\n\t\tthis.sum=sum;\t\t\n\t}\n\tpublic ArrayList<String> create() {\n\t\tArrayList<String> list=new ArrayList<String>();\n\t\t//存放生成的名字\n\t    String name[]=new String[idnum];\n\t    for(int a=0;a<=idnum-1;a++) {\n\t    \t//生成随机生成的名字组合\n\t    \tnameid=String.valueOf((char)(int)(97+Math.random()*26))+\n\t    \tString.valueOf((char)(int)(97+Math.random()*26))+\n\t    \tString.valueOf((char)(int)(97+Math.random()*26));\n\t    \tname[a]=nameid;\n\t    }\n\t\t//根据名字组合随机生成id  \n\t\tfor(int a=0;a<=sum-1;a++) {\n\t\t\tlist.add(name[(int)(Math.random()*idnum)]);\n\t\t}\n\t\treturn  list;\n\t}\n}\n\n \n //setting配置文件来定义数据集\n //————————————————————— \n //setting.properties\n //idnum=2\n //flagnum=3\n //sum=10\n //————————————————————\n```\n\n\n\n\n\n\n\n\n\n\n","tags":["java"],"categories":["大数据"]},{"title":"Java动态代理","url":"/2018/01/12/2018-1-12/","content":"<Excerpt in index | 首页摘要>\n这是一个java动态代理的小例子\n<!-- more -->\njava动态代理的作用\n1、实现一个类的方法的增强(例如类a有一个方法b()、当一个类要调用方法b()时需要给方法b()增加新的功能、但有些时候又需要调用b()的原先方法所以此时不可以重写方法b()、因此使用代理可以在不改变方法b()的基础上来增强方法、以后就使用代理类的增强方法)\n\n2、实现代理(比如类A有很多方法、你可以创建一个代理类B拥有A中的所用方法、在客户端需要调用A的方法时只需要访问B就可以达到和访问A一样的效果、不过代理B可以自己重写某个方法当客户端访问B时实际调用A中定义的方法)\n\n\n首先定义三个类一个接口、接口Buy中定义需要增强的方法、原始类Old中的实现原始方法money、定义增强类Proxyclass来实现增强方法、测试类Test来测试增强的方法\n\n```java\n\n//接口\npublic interface Buy {\n\tpublic int money(int a);\n}\n\n\n\npublic class Old implements Buy{\n//需要增强的方法\n\tpublic int money(int a) {\n\t\treturn a;\n\t}\n}\n\n\n\n//测试类\npublic class Test {\n\tpublic static void main(String[] args) {\n\t\tOld old=new Old();\n\t\tSystem.out.println(\"old money\"+old.money(44));\n\t\tBuy a=Proxyclass.getproxyclass(5);\n\t\tSystem.out.println(a.money(500));\n\t}\n}\n\n\n\n//代理类\npublic  class Proxyclass {\n\tpublic static Buy getproxyclass(int num) {\n\t\t//使用默认的类加载器\n\t\tObject proxyobj=Proxy.newProxyInstance(Old.class.getClassLoader(),new Class[] {Buy.class}, new InvocationHandler() {\n\t\t\tpublic Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n\t\t\t\t //反射拿到原来的方法\n\t\t\t\tInteger result=(Integer)method.invoke(new Old(),args);\n\t\t\t\t//增强的方法\n\t\t\t\treturn result-num;\n\t\t\t}\n\t\t});\n\t\t//返回接口\n\t\treturn (Buy)proxyobj;\n\t}\n}\n\n        \n```\n```java\n\n\npublic interface Star {\n    public void sing();\n    public void ticket();\n\n}\n\n\n\npublic class StarHandler implements InvocationHandler {\n\n    public Star realstar=null;\n    public StarHandler(Star realstar){\n        this.realstar=realstar;\n    }\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        System.out.println(\"执行其他方法\");\n        if(method.getName().equals(\"sing\")){\n            method.invoke(realstar,args);\n        }\n\n        return null;\n    }\n}\n\n\n\npublic class Client {\n    public static void main(String[] args){\n        Star realStar =new Realstar();\n        StarHandler handler=new StarHandler(realStar);\n\t\t//返回一个指定接口的代理类实例，该接口可以将方法调用指派到指定的调用处理程序\n\t\t//loader - 定义代理类的类加载器\n        //interfaces - 代理类要实现的接口列表\n        //h - 指派方法调用的调用处理程序\n\t\t//相当于proxy帮你自动创建这个代理类\n        Star proxy =(Star)Proxy.newProxyInstance(ClassLoader.getSystemClassLoader()\n                ,new Class[]{Star.class},handler);\n        proxy.sing();\n        proxy.ticket();\n    }\n}\n\n\npublic class Realstar implements Star {\n    @Override\n    public void sing() {\n        System.out.println(\"reastar--sing\");\n    }\n\n    @Override\n    public void ticket() {\n        System.out.println(\"reastar--ticket\");\n    }\n}\n}\n\n```\n\n### 其他注意点\nObject invoke方法中参数介绍\nmethod:　　指代的是我们所要调用真实对象的某个方法的Method对象\nargs:　　指代的是调用真实对象某个方法时接受的参数\n\njava spring框架就用了动态代理技术、能为容器中的对象生成动态代理对象、通过利用AOP思想对一些类的功能做了抽取\n\n\n\n\n\n\n\n\n\n\n","tags":["java"],"categories":["大数据"]},{"title":"基本神经网络","url":"/2017/12/10/2017-12-10/","content":"<Excerpt in index | 首页摘要>\n简单整理一下神经网络训练的步骤\n<!-- more -->\n总结一下最简单的神经网络的训练过程和原理\n通常利用数据交叉验证来提高数据利用率\n<img src=\"http://aRootUser.github.io/img/2/1.jpg\">\n交叉验证：给定一个训练集和测试集，为了最大程度的利用测试集，可以将训练集分为若干份，这里为5。第一次将fold1(折)作为测试集其余的作为训练集，第二次将fold2作为测试集，其余的作为训练集，以此类推从而达到最大化利用数据更新权重的效果\n<img src=\"http://aRootUser.github.io/img/2/2.jpg\">\n对于输入的一张图片简单将图片的输入像素点看成[1,4]的矩阵、输出层为[1,3],中间的权值为[4,3]的矩阵、和图中不同图中是左成矩阵、这里定义的是右乘矩阵、没有定义中间层、最后还要加上[1,3]偏置值得到[1,3]的输出值每一个值代表某一类别的得分、\n<img src=\"http://aRootUser.github.io/img/2/3.jpg\">\n为了更好的定以中间权值定义的好坏以及预测结果的准确程度、用损失函数来衡量、损失函数最小表示预测越准确、这里定义的是svm损失函数、\nl 表示自己定义的可容忍的长度\nyi表示正确类别的得分\nj表示其他类别的得分\n通过计算每个其他类别减去正确类别的得分的最大值的求和来表是损失函数的结果对于多个输入例如输入100张图片还要除去100相当于取平均值\n<img src=\"http://aRootUser.github.io/img/2/4.jpg\">\n为了防止权值为0从而导致输入样本的每一个值没有被充分利用例如训练得到的两个权值\n设输入的样本为[1,1,1,1]\n权重W1[0.5,0.5,0.5,0.5]    \n权重W2[1,0,0,0]\n矩阵相乘后得到的结果相同但是w2由于有三个0没有充分利用每一项所以添加w的平方项来惩罚权重为w2的情况、使其损失值变大\t\n<img src=\"http://aRootUser.github.io/img/2/5.jpg\">\n<img src=\"http://aRootUser.github.io/img/2/6.jpg\">\n分类器的作用将输出的值通过sigmoid函数映射到0至1的区间上、e的x次幂进行放大、最后通过取其作为正确类别的概率取负对数得最终其对应的损失值(因为概率越大越输出的损失值越小)\n前向传播：从输入的x一直到计算出loss、通过梯度下降算法找到一个下降方向、最终找到最低点、训练的批次数一般为2的整数次幂\n一个Epoch表示迭代完所有数据、一个迭代表示跑完当前的一个batch\n## 学习率\n每次训练跟新权重的变化要乘一个学习率来调整权值变化的大小、过大会错过最优解\n## 反向传播\n通过计算出每一个权重对最终的loss值的影响来调整权重的大小(向前传播的逆向求解)\n## 激活函数 \n对神经元的输出进行去线性化、例如sigmoid函数(由于当x过大时很容易导致梯度消失使其无法求导进行反向传播、现在一般用relu激活函数并且求导简单）\n## 过拟合问题 \ndrop-out进行处理通过迭代来弥补神经网络的复杂度\n## 过程小结 \n首先输入训练集如手写数字集、定义神经网络后、通过向前传播得到对每一个类别的输出、通过sortmax函数将输出转化为概率分布、通过与标签进行如下运算个（标签是one-hot概率）、将输出的概率分布取对数与标签值乘积在做平均值求和最后取负数-tf.reduce_sum(y_*tf.log(y))、得到交叉熵来反应结果集与标签的相似度、最后通过梯度下降法不断训练使交叉熵最小、来优化权重参数、\n\n\n\n\n\n\n\n\n\n\n","tags":["深度学习"],"categories":["深度学习"]},{"title":"Webnote","url":"/2017/12/02/2017-12-02/","content":"<Excerpt in index | 首页摘要>\n用来记录有趣的东西\n<!-- more -->\n<The rest of contents | 余下全文>\n\n\n## smallnote\n\n当使用卡夫卡作为MQ时如果出现MQ数据存入的速度远远小于数据从MQ采集的速度、\n\n可直接通过netty或者mina直接从数据源采集\n\njava中wait方法释放锁、notify不释放锁直至执行完这个方法\n\nsix是兼容python2,3的一个库\nfor box, color in six.iteritems(box_to_color_map):\n迭代返回键值对\n\nidea常用快捷键 alt+7 和 Ctrl+h\n\n\n\n## 2018-3-10\n币安的黑客攻击这波操作真的是6的飞起、\n\n## 2018-3-19  \n工作室搬了、怀念大长桌子、\n\n## 2018-3-25\n今天写python时碰到的小细节debug了好久、、\n``` python\n\nprint('A')\nclass MyObject(object):\n    print('B')\n    def __init__(self, name):\n        print('C')\n        self.name = name\n        print('D')\n    print(\"F\")\nprint('E')\nmy_object1 = MyObject('Hello')\n#这段程序的执行结果依次为A、B、F、E、C、D\n#类的__init__函数注意是两个下滑线、、\n#对一个存放类的set集合根据类中的flag来进行排序、True为降序排列taskset=[]\ntaskset.sort(key=lambda obj:obj.flag, reverse=True)#降序排列\n\n```\npython引用变量的规则\n首先从local(例如函数内部)开始，如果有则优先使用\n若在local没有，则会从local的封闭环境开始搜寻\n若以上都没有，则在global中搜寻\n\n\n## 2018-3-26\n立个flag每天刷一道算法题\n\n## 2018-3-29\n数学建模课中看到了机器学习的影子、不禁听的有点小激动虽然老师讲的也很简略、要是学校有深度学习的选修课就好了（我绝对不逃课）\n\n## 2018-4-1\n已无力吐槽win10的霸道更新、各种卸载后终于把更新给禁了(好想有一台Mac、、)、结果晚上就开不了机了、、吐血、、重装了系统配置都没了（还好其他盘都在、当初分好几个区是确的选择）、、\n浪费了好多时间配置都重新搭的差不多了、唯一开心的是就是系统似乎快了一点、、\n\n## 2018-4-15\n阿里的天池比赛彻底放弃了、训练了近10个小时的模型的loss也降到了0.5左右、但识别的结果并不好、可能开始对图片的切割范围过大了、框和框之间的距离拉得太近、要期中考了就不再重新折腾了、\n突然想做一个基于区块链的\"微博\"、完全去中心化、言论自由、不受政府监管、想想就好激动、会有搞头不、\n\n## 2018-4-16\n最近博客遇到个bug、就是js的动态效果突然加载不出来、debug了一晚上终于发现了错误！！主要是在HTTPS请求下引入HTTP资源造成的Mixed Content的一个错误、特别是chrome这个浏览器、拦截了所有http请求的js脚本、然后就是修改了、把所有js的外部资源链接改成https请求就行了(作为前端小白的我不知道这么说对不对)、当然不能一个个手改、找到hexo主题下的js脚本中对其链接进行修改最后生成就行了、、\npython也碰到了几个坑有空慢慢填1、浅拷贝和深拷贝 2、创建若个个类丢到list中、遍历取出list中的类并调用其方法时碰到的问题(填坑、调用方法是少加了个括号、我的天太粗心了、、当局者迷啊、)\n\n## 2018-4-25\nthe g_overmverment have no power to supervise our message、the Internet company shoud not head down to the g_overmverment\n\n## 2018-5-6\n灰常开心终于解决了ssd+inception3内存爆炸的问题、做了近半个月的安全识别差不完成了、人是会撒谎的但计算机不会、是该继续研究好久没学的hadoop、spark了\n\n## 2018-5-8\npythcharm的debug\tF8下一行 \tF7 进入函数\t\tF9 停止在下一个断点\n\n## 2018-5-15\n了解了锤子发布会、想起差不多一周前的谷歌IO、虽然两者没有比较的意义、只能说希望越大失望越大希望越大吧、不禁又有点心疼老罗、重新定义了重新定义、网上的各种表情包真的是看的迷醉、\nWe are standing at the crossroads of science and art 向伟大的乔布斯致敬！\n\n## 2018-5-16\n最讨厌排球、没有之一、大一网球课打的真的是太开心了、\n\n## 2018-5-20\n周末想手写inceptionV3、看了看源码、一个函数11个参数、、我还是太年轻了、、、不急慢慢来吧、\n\n## 2018-5-21\n玩了半个下午的wncry、还好是在虚拟机上玩、不然真的要WannaCry了、不过说好的到时间了会删除加密文件到最后还是没有删除、公共系统对他而言分分钟秒成渣、\n\n## 2018-5-23\npython的装饰器\n``` python\n\ndef common(func):\n\tprint(\"fist\")\n    def common1():\n        print(\"1\")\n        return func(\"2\")\n\tprint(\"second\")\n    return common1\n\t\n#被修饰的函数\ndef new(inputer):\n    print(inputer)\n    print(\"3\")\n\ntest=common(new)\ntest()\n#输出结果为first、second、1、2、3只要进入了common就会先执行方法外的语句\n\n```\n```python\ndef common(func):\n    def common1():\n        print(\"1\")\n        return func(\"2\")\n    return common1\n#内置语法修饰相当于帮你把被修饰的函数传入修饰函数并得到修饰后的原函数\n@common\ndef new(inputer):\n    print(inputer)\n    print(\"3\")\nnew()\n```\n\n\n```python \n#再在最外层加一层用out来接受修饰器的参数\ndef out(out):\n    def common(func):\n        def common1():\n            print(out)\n            print(\"1\")\n            return func(\"2\")\n        return common1\n    return common\n\n@out(\"out\")\ndef new(inputer):\n    print(inputer)\n    print(\"3\")\nnew()\n```\n\n```python\n#类装饰器输出结果为1、2、3\nclass Foo(object):\n    def __init__(self,func):\n        self._func=func\n    def __call__(self):\n        print(\"1\")\n        self._func()\n        print(\"3\")\n@Foo\ndef bar():\n    print(\"2\")\nbar()\n```\n在Python中，类也是对象，你可以动态的创建类。这就是当我们使用关键字class时Python在幕后做的事情，而这就是通过元类来实现的\n元类就是用来创建这些类（对象）的，元类就是类的类，你可以这样理解为\n\n## 2018-5-25\n进过反复的思考最终决定了还是往大数据架构发展、深度学习算法学历要求太高、公式也不是一两年可以完全弄懂的、等工作一段时间之后再慢慢往那边发展、希望以后能参与分布式深度学习平台的搭建吧、tensorflow源码的阅读先告一段落了\n## 2018-5-30\n学了几天netty、还是too young啊、、\n## 2018-6-12\n第一次电话面试、好紧张啊、、个人感觉不是很好但竟然过了、我竟然紧张的连java八大数据类型都没答全、cry、\n总结几个自己没答好的问题1、基本数据类型的包装类 2、hadoop和spark mapreduce的具体区别 3、java并发包的了解、线程池\n## 2018-6-22\n看完了西部世界大结局、听着魔性的BGM、入戏太深、are you real？ \n## 2018-7-17\n考完了期末考试终于开始了暑假的实习、公司第一感觉还不错、总之加油吧、\n## 2018-7-30\n简单的介绍scala的科里化\n\n```scala\n  //方法的一般定义\n  def method(a:Int):Int=a*a;\n  //方法三的科里化拆解\n  def method2(a:Int):Int=>Int = (b:Int)=>{a*b}\n  //科里化同时传入多个参数对其进行拆解、科里化是隐式转换的基础\n  def method3(a:Int)(b:Int):Int=a*b\n  \n  //函数的一般定义\n  val func=(a:Int)=>a*a\n  //函数的第二种方法定义\n  val func2:Int=>String = {a=>a.toString()}\n\n```\n\n\n简单的介绍scala的隐式转换\n```scala\n\nobject Door{\n  implicit val a=\"bbb\";\n}\nobject Spark {\n  def test()(implicit name : String = \"aaa\"): Unit ={\n    println(name)\n  }\n  def main(args: Array[String]): Unit = {\n    //通常伴随起始的import共同导入\n    import Door._\n    test()\n\ttest()(\"ccc\")\n  }\n}\n\n```\n执行过程由于导入了存在隐式转换的Object、在执行test的时候会事先在Door中查找是否有同类型的值、如果有则把其作为参数传入进去、\n如果用户自己有特定的值传入、则用户的传入值优先\n输出结果aaa ccc\n\n隐式转换第二个例子\n```scala\n\n  class RichFile(val file:File){\n        def read = Source.fromFile(file.getPath).mkString\n    }\n    \n  object Context{\n      implicit def file2RichFile(file:File) = new RichFile(file); \n    }\n  \n  object HelloImplicitConversions {\n      def main(args: Array[String]): Unit = {\n        import Context._\n        println(new File(\"E:\\\\input.txt\").read);\n      }\n    }\n```scala\n看main方法、原来的File中没有read方法、导入门面后程序会先查找File类型是否可以转换为其他的类型、发现可以将File转换为Richfile、再查找richfile中是否有\nread()方法、发现有、于是就隐式转化为richFile并调用其read方法\n\n## 2018-8-22\n两天看完了拆掉思维里的墙、可以说无论是从认知还是世界观都有很大的收获、这里通过几个小点的主题主要进行总结一下\n对于普通的年轻人要不要买房？\n作者的观点是要投资自己不要投资房子。为了论述这一点作者先后举了两个路人的例子和巴菲特的例子、他们的成功点以及和别人的差距就是在最关键的时期选择租房而不是买房、\n因为买房的房贷将会大大减少每月的收入、从而大大减少了对自己的投资严重抑制了将来的发展、作家还讲了自己的亲身经历及买房意味着结婚、意味着安定、所以说一座房子毁了\n一个年轻人的梦想毫不夸张、\n\n# 如何面对恐惧？\n首先你要相信这个世界上没有谁你都能活的下去、有时候所谓的爱只是你怕失去的一种恐惧、从而使你疯狂的依赖一个人\n\n# 关于能力的提升\n一种能力=天赋x时间 \n当做一件以前从来没有做过的事情时、不要下意识的否定自己、例如说“我不会”、对于新的事物要用于尝试、而不是从潜意识里否定自己、这样会错失很多的学习机会、如果你一直\n不做、那么你就一直没有信心、就一直都不会(举例年纪大的人不爱去接触新的事物、有时候是怕做不好被笑话、其实这是十分没必要的、孩子对学习“不感兴趣”，往往是由于自己觉得没有学好的能力，或者再怎么努力也达不到父母的要求。 \n毕业生对工作“不感兴趣”，其实是觉得自己没有能赚钱的本事，或者是害怕再怎么努力也达不到自己心里满意的目标。)\n\n对于没有做过的事要敢于尝试、不要用不敢兴趣来作为借口。说对东西都不敢兴趣的人都是不敢投入的“无兴趣一族”，那就是，他们好像从来没有想过进入当下，他们从来没有感到过乐趣。\n他们总在思考“读这本书有什么用处？”“万一做不好怎么办？”这让他们无法从任何东西中获得乐趣，自然也谈不上有什么兴趣。\n现在我们对投入有了下面的理解： 1．尝试是有可能成功，有可能失败的。 2．成功的尝试能收获到成果。 3．不成功的尝试能收获到智慧。 4．不管成不成功，投入都能带来快乐。 既然这样，为什么不停止你内心对后果的担忧，投入一些呢？\n远离让你容易获得安全感的事情:如一张刷不完的卡、以及养老般的工作、这会使你成为安全感的奴隶\n\n# 一些好的小方法\n克服恐惧的方法\n1.把恐惧的事情写在纸上至少10条(担心的事)、写到无论如何也想不出来为止 2.把纸放到一个十分安全的地方没人知道 3. 告诉自己担心的事情很有可能发生、但我要去做自己的事情、所以我要\n把恐惧安全的放在这里、做完事情以后再来取走我的恐惧 4.这时你会舒服很多然后放心去做吧 5.做完后看看你写的纸条有多少担心的发生了\n增强自信的方法\n每天记录5条个人成果(自己人为成功的地方)在一个小本子上、要注意坚持\n\n处于困境时的方法\n当你处于绝境、并且要被新来的人代替时、不妨想想新来的人会怎么做、然后你就去这么做。\n\n如何得到相对较好的选择\n\n我们生活中的选择也是一样。打破“后来”模式的最好方法，就是在进入未知领域的时候，给自己一个不做选择、观察的空间和底线，在这个之前，不要作选择的决定，一旦过了这个底线，就大胆地开始选择。这就是最好的“选择”模式。\n旅游景点买东西，你会如何决定你的购买策略？先不要急着在第一时间购买，而是先逛过去，了解一个大概的价钱，在差不多三分之一的时候才开始购买，这样最不容易被诳到。购房的时候也是一样，先让自己确定大概要看几套。把前面三分之一纯做样本，\n往往会有很好的收益。在股票市场中，高手们很少会在最高抛出，在最低买入，就是因为他们也需要一定的“观察”样本，来保证收益最大的“选择”模式。\n这个思维模式也可以很好地解决大学生毕业签约公司的焦虑：各种公司的签约要求一起来，马上签约害怕“后悔”，一直观望又担心“错过”。这个时候可以把今年的前37％的时间作为观望期，根据自己水平制定出一个自己能接受的水平，一旦看好，马上出手签约。 \n着急选择的后悔模式和总在等待的错过模式，都会让你不可避免地陷入“后来”模式，在未来为自己的决策后悔。打破这种模式的最好方式就是拿出一段时间寻找到内心的基准线，然后等到目标出现，马上出手。\n\n多参加一些技术交流会和俱乐部可以让你收获到更多的人脉\n\n# 关于安全感的看法？\n通常人会认为安全感是别人给的、作者则从更加理性的角度说明安全感是自己给别人而得到的(或者说是自己给自己的)、如果你受了伤你要帮别人减轻伤痛、如果你感到痛苦、你要帮助他人减\n轻痛苦而不是一味的寻求别人的安慰、所谓的安全感更多的是对在意的人负责的责任。而不是成为安全感的奴隶。\n但是爱不是给出去的，而是溢出来的。只有充满自己的心灵，然后还溢出去的，才是爱。\n\n# 如何长久的提升自己的幸福感\n寻找那些不能够被满足的深层兴趣，比如爱、成长、超越自己、快乐、助人、宁静……它们会让你幸福一辈子。\n我们的幸福感，很大部分就在这种“比你更好”的比较中流失。\n\n这个世界上还有一小部分人，他们有一个奇妙的心智转化器，他们好像没有痛苦按钮，只有快乐按钮，而且按钮在自己手上。比如禅师，即使兰花摔坏了不是自己想要的结果，但是总有比大发雷霆更好的选择。他们的心智模式是：不管外界怎么样，我都有能力对自己的状况负责。\n这种人总能找到当下更好的方法，因为他明白，不管外界怎么样，下一步的生活，都是他们自己的！老板发火我可以选择去沟通，也可以选择离开；孩子不听话，我可以选择去教育，又或者调整自己讲话的方式；堵车的时候我可以选择下次不在这个时间出来，也可以选择用这个时\n间听听音乐或者练练听力……这种人我们称为掌控者。\n\n\n# 心智模式\n我的理解是世界观、也就是我们的“系统”\n\n反面教材:老张只认为钱赚的越多越幸福、老张于是更少回家，更多应酬，更加努力赚钱，更大把往家里拿钱，却一次次看到老婆孩子更加冷漠的脸，也更觉得自己不幸福。像一个在瀑布下面溺水的人，他越是努力，越是下潜。 外界环境已经变化，他的内部程序还在进行，\n这个曾经让自己幸福快乐的心智模式今天却在毁灭自己。 如果没有打断，这个死循环将会像短路的电路板一样，迅速地自毁他的生命。这就是有钱人越有钱越不快乐的原因。\n\n双赢不一定是最好的选择\n作为一种心态，双赢不总是对的。每一个心智模式背后都有相应的对世界的假定，也有着相对的局限性。世界上根本不存在总是对的道理和心态，当然，包括我这句。\n落水后游向岸边是对的吗？平时是，但在旋涡里面的时候却不是。前面提到的双赢总是对的么？总想着双赢会让你在一些地方死得很惨\n\n对与过去的痛苦\n事实不是这样，虽然我们不能改变我们的过去，我们却能改变对于我们过去的看法，这才是心智模式的伟大之处。\n我们每一个人的内心都有一个这样的水杯。我们害怕失去而死死地盯着这个杯子，限制我们的眼界，僵化我们的思维，阻碍我们看到真正有价值的事情。有人的水杯叫做“专业”，有人的叫做“感情”，还有人的杯子叫做“安逸的好工作”，你的杯子叫做什么？ 无论如何，请你记住，\n不要为一个水杯约束你真正有价值的生命！\n沉没成本其实是已经损失的成本，为了这个损失而追加成本，最后只会头破血流。 已经投入并且损失的价值，会造成我们对未来投入的判断。这就是沉没成本模式。由于害怕损失，所以继续投入，到后面损失却更大。这是我们常犯的错误，沉没成本模式。\nIf you shed tears when you miss the sun，you also miss the stars． 如果你为失去太阳而哭泣，你也将失去群星。\n\n如何更新自己的世界观\n不知不觉。你需要一个机会，让自己意识到这个世界不是你想象的那个样子，你需要看到两个世界之间细小或者巨大的差异，比如说那个撞猪的司机，有了差距体验的你，才会开始慢慢地对你想象的世界有所察觉，我们称为后知后觉。\n你的心智模式决定了你会匹配到的人\n抱着“只和可以结婚的人谈恋爱”的想法和“我只选择做要从事一辈子的工作”的心智模式一样，一旦启动，结果一定是没恋爱、无工作。因为你的选择规则本身就把候选人删除掉了！\n对于机会\n第二，一个过于明确的目标，会让你对新出现的机会视而不见。想想看，如果你从18岁就开始规划你的未来，并且在未来20年只往那个方向走，想象会错过多少机会？\n对于价值的选择\n一件事情的价值，不取决于现在你判断的价值，而取决于在未来情况中的价值，这就叫做未来价值。\n我们总是混淆两个概念，一个是价值，一个是价格。一件事情有价值，也有价格。价值来自于内在系统，价格来自于社会系统。\n聪明人根据价值选择合适的价格，蠢人则通过价值选择不合理的价格。最糟糕的是一群有脑无心的人，他们不知道自己要什么价值，于是他们只好按照价格来判断价值。如果这群人还碰巧是固执而影响力很大的人，这件事情就加倍地糟糕：他们不仅仅按照价格来判断价值，而且\n还试图要求别人和他们一样。别管什么价值了，按照这个标准一起玩吧！\n价值的世界是多维的，但是价格的世界却只有一维——这样的世界没有了可能性——当世界出现唯一一条坐标轴，则意味着世间所有的人和物瞬间各就各位，每一个东西都有其明确的坐标。（为了理解这个世界的荒谬性，你可以尝试想想看，如果所有乐器只按照音量来评价高低，那\n么将会是怎么样的世界？每一个人不是好人，就是坏人！不是正确的，就是错误的！宽广的生活瞬间变成一条小胡同，你的选择也只有两种：你是进，还是退？\n\n\n# 对于成功\n如果今天的你还有家人需要负担，毕业工资不定，福利保险一个没有，创业还需要场地，家里没人没钱，你当然也可以成功，但是请不要模仿比尔·盖茨——“我有翅膀，你有吗？”\n\n我不能停止呼吸，因为明天，当太阳升起来，谁知道潮水能带来什么？\n\n如果你有一个梦想，那就去捍卫它；如果你有一个目标，那就去争取它。走起来！当你走在人生之路上，没有必要去羡慕那些走在高处的人，也没有必要轻视那些走在你后面的人，因为成功不是生命的高度，成功是生命的速度。成功在你此刻的脚下，成功就是越走越近\n\n很强，脑子不笨，手脚不慢，但是却一直没有大的发展？因为他们只知道什么是自己不想要的，却没有思考过什么是自己真正想要的。\n\n每个人都是自己生命之舟的掌控者，我们往往会因为外界的态度而改变自己的意愿。不管是三小时还是一小时，都不要把你的舵，放到他人手上。\n\n你无法掌控公司和对方部门经理要不要你，你却可以掌控你自己，让自己成为更加被需要的人。\n\n15分钟后，Lily抬头看到Helen站在她面前，脸色前所未有的灿烂，她说出了那句Lily期待很久的那句话：“你有兴趣在我们公司做HR吗？” 你看明白了吗？如果你愿意，你总是可以掌控些什么。你没有必要得到允许才开始学习，你也没有必要得到机会才开始努力。如果你愿意，\n你现在就能够为这件事情做些什么，除非你的受害者模式让你深深陷入抱怨与自怜中。\n\n你不妨把自己的梦想想象成一家上市公司的董事会，你和你的父母对于“你”这个公司都有一定的发言权。他们占有一定的股份。他们有权利发言，有权利表达观点，而你也有义务认真倾听、考虑。但记得在关于你人生的董事会上，你永远是最大的股东。\n\n由于社会对社会对于社会自我的反馈远远高于自我系统、所以我们渐渐把自我给忘了\n\n黄老师在讲完这个故事以后说：你们一定要记住，有一些人不用社会意义上的成功，也能很好地走完职业的所有阶段，在普通的职位上面活出自己生命的\n每当有老外好奇地问，你怎么懂得这么多？他就很淡定地回答，我们中国司机都这样，我是最烂的一个！\n\n\n\n# 对于受害者\n作为受害者，最大的收获是：发泄的快感、被同情、觉得自己其实是正确的。最大的损失是：觉得失落、绝望、无奈、无助、无力感。 作为掌控者，最大的收获是：找到新的可能性，自省，觉得自己可以应付一切，有动力去再尝试。最大的损失是：很有压力，面子问题。\n在受害者天堂，如果一个事情做不好，绝不是本能力有问题，而是这个事情有问题。\n你有没有买过明知道是偷回来的自行车？你知道这是不对的，是吗？但是你还是买了，因为你有一个关于自行车的受害者故事——我的车也是被偷的。 你有没有在感情上伤害过别人？你知道这样不对，是吗？但是你还是做了，因为你有一个关于爱情的受害者故事——我也是一个被伤害过的人。\n你有没有对无辜的人发过脾气？你知道这样不好，但是你还是发了，而且还觉得挺爽。因为你有一个关于情绪的受害者故事——我也是受气者，谁又哄我了？ 你有没有在职场中做过让自己恶心的事情？你知道这样不对，但是你还是做了，因为你有一个关于生存的受害者故事——为了生存嘛。我这样也是没有办法。\n哈哈、对于一些访谈节目。每天晚上，受害者天堂的人们满意地关上电视机，安心入睡。他们每一个人都在别人的受害者故事中获得不少廉价的快乐。\n在受害者天堂，女孩子很早就知道，假装无助会获得男生的帮忙。女孩子们很早学会了在楼下面假装弱不禁风，让男人帮忙提热水瓶或者行李上楼。\n在受害者天堂，职员很早就知道通过假装自己无能来获得帮助：啊，（嘴巴张大，挠头）这个我不懂，这个我做不来，能帮帮我吗？然后自己偷着干别的事情。\n因为他说如果我离开他，他就去自杀！ 你听过类似的话吗？这种话对你有效吗？这是受害者的最后一个大好处：用自我伤害来操纵他人。受害者往往也都是控制狂，如果不能控制别人，那就狠狠地伤害自己吧。毕淑敏在她的《心灵7游戏》里面，讲了这样一个受害者的故事。\n我们在这个天堂获得短暂的快乐和安全，却损失了自信、自省以及对未来的期待和盼望。最可怕的是，我们失去了对自己生命的掌控。因为受害者深深坚信，自己快乐与否、成功与否掌握在他人手中。\n\n# 对于世界\n这个世界是不公平的，你活得越久，站得越高，看得越清，你就越会意识到，世界的本质其实就是不公平。所以所有的宗教、法律都在追求公平，追求公平恰恰说明，世界是不公平的。这也是为什么很多科学家、法学家、企业家最终遁入宗教寻找安宁的原因：他们曾经努力创造一种公平，但是当他们努力到达一个很高的高度的时候，\n却发现他们依然面对那些无法改变的不公平。比如梁启超，他在戊戌政变后精神沮丧，偶尔接触佛法，拍案惊奇，写道：“社会既屡更丧乱，厌世思想，不期而自发生；对于此恶浊世界，生种种烦懑悲哀，欲求一安心立命之所；稍有根器者，则必逃遁而入于佛。”\n\n# 对于父母\n恕我孤陋寡闻，没有见识，但是我真的很少看到还有其他国家的父母像中国的父母一样，为自己的孩子作出那么多的牺牲，同时又给他们那么多的要求。他们总是把自己缺失的东西强行附加到孩子身上，并从小教育他们，这就是幸福。这种故事就发生在你我身上。下面是我的故事：\n我们的父母很容易有这样的思维方式，把自己缺失的东西放大，强加于他们的儿女身上。尤其是独生子女的家庭，儿女占用了所有的资源，所以也应该承担他们所有的希望。当资源付出到一定程度，这样一\n对儿女爱的绑架就开始布局——如果你不按照我的计划发展，我就要伤心，就要内心压抑偷偷饮泣。我这一辈子把你养大，现在过得这么累，全都是因为你！\n有讽刺意味的是，你发现唯一能让他们爽的方式往往是：先让他们不爽。\n\n# 对于拖延\n一个人等待与拖延的成本，远远高于他真正开始行动的成本行动所需要的成本，他就会慢慢陷入越等待越不行动的怪圈。我把这个模式称为“等死模式”。\n西方人说：Waiting for life is waiting to die。等待生命就是等待死亡。生命不是用来等待，而是用来穿越的。\n穿越也许会有短期痛苦，但是等死往往会带来更大的永久损失。 《战胜拖拉》的作者尼尔·菲奥里在书中写道：“我们真正的痛苦，来自于因耽误而产生的持续的焦虑，来自于因最后时刻所完成项目质量之低劣而产生的负罪感，还来自于因为失去人生中许多机会而产生的深深的悔恨。”\n“开始爱好者”最喜欢的事情，就是制订计划。计划越长越好，课程越贵越好，因为一个计划就意味着一个开始。最讨厌的事情是落实计划，因为落实计划这个事情实在是比制订计划难多了，所以“开始爱好者”一般不选择坚持，他们会选择另外一个开始。\n\n# 对于选择\n在这里提供一个有效的方法，来上新精英的职业生涯发展工作坊的学生，会发现有一个这样看似奇怪的规定。就是在上完这个课后，7天之内不准作出重大的决定。有的学员不理解，偷偷作出重大决策，一般3个月以后都后悔不迭——你在激动情况下作出来的决定，根本不足以让你坚持做下去。\n# 对于生活\nNND今后要早点回来，我老婆太漂亮了。 所以，生命是个三脚架，永远不要让自己断掉两条腿。 二、莫当漏斗人 我们的生命如何才能有意义？","tags":["other"],"categories":["other"]},{"title":"Think in Java","url":"/2001/01/02/1-1-2/","content":"<Excerpt in index | 首页摘要>\n\n<!-- more -->\n阅读笔记\n<The rest of contents | 余下全文>\nHashMap已经取代了Hashtable\n\n## 对象的初始化\n在实例化类的时候是先调用他的无参构造函数、若没有java会自动帮你创建一个、但如果你已经定义了一个构造器他就不会帮你创建默认无参构造器、此时可能会报错\ninitialize()\nthis方法只能在方法内部使用、表示调用方法的那个对象的引用\nstatic方法里面不能调用this、一般static方法是通过类来直接调用的、相当于全局方法。\n\n\n## finalize方法\n它是在 Object 类中定义的，因此所有的类都继承了它。\n子类覆盖 finalize()方法以整理系统资源或者执行其他清理工作。\n对象可能不会被回收\nfinalize() 方法是在垃圾收集器准备删除对象之前对这个对象调用的。 finalize()方法主要用来在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。\n当你用了创建对象方式以外的方式为对象分配了内存空间、此时需要用finalize()方法、例如java调用非java代码的方式\n\n## 组合（composition）与继承\n组合：为了使类实现多功能、会在类中定义成员变量、各个成员变量来自于其他的类以此来达到类的多样性、当需要向上转型时再考虑使用继承\n\n## 多态\n多态的作用是消除类型之间的耦合关系、多态方法调用允许一种类型表现出与其他相似类型的区别","tags":["java"],"categories":["java"]},{"title":"算法及深入解析Java","url":"/2001/01/01/1-1-1 /","content":"<Excerpt in index | 首页摘要>\n\n<!-- more -->\n长期跟进算法及java深入解析\n<The rest of contents | 余下全文>\n第一次参加远程面试、、然后一道简单的算法题、被虐、意识到算法是一切的根本、接下来慢慢啃吧\n## Hashmap的实现原理\nhttps://blog.csdn.net/vking_wang/article/details/14166593\n简单来讲就是hashmap是数组加链表、数组存放首个entry[]（一个类、包含、key、value、next）相当于每个链表的节点、同一个hash值依次向后链接\n再补充个常识迭代是指每次循环对一个数进行操作\n\n## 各种报错集合\n\n###java.lang.reflect.UndeclaredThrowableException\n远程RPC调用时没有加载同一个.class\n\n\n## 数组题的细节\n### int a = new int[3];\n这句话生成的数组长度为3、用0填充(非常重要)。\n\n\n求两个数组交集的方法\n```java\nclass Solution {\n    public int[] intersect(int[] nums1, int[] nums2) {\n        ArrayList temp = new ArrayList();\n        ArrayList list = new ArrayList();\n\t\t//for each循环数组、注意之前有int、十分简洁的写法\n        for(int n:nums1){\n            temp.add(n);\n        }\n        for(int m:nums2){\n\t\t\t//返回包含这个数的下标\n            int index = temp.indexOf(m);\n            if(index!=-1){\n                list.add(temp.remove(index));\n            }\n        }\n        int[] a = new int[list.size()];\n        for (int i = 0; i < list.size(); i++) {\n            a[i] = (int) list.get(i);\n        }\n        return a;\n    }\n    \n}\n//还有一种方法事先进行排序\n//Array.sort()对其进行排序\n```\n\n很好的分区方法对数读的九个区进行分区\n### list3.get(x/3*3+y/3).add(result);\n\n## 关于java抽象类的是否可以实例化\n\n```java\n\nabstract class my {\n    public void mymethod() {\n        System.out.print(\"Abstract\");\n    }\n}\n\nclass poly {\n    public static void main(String a[]) {\n        my m = new my() {};\n        m.mymethod();\n    }\n}\n\n```\n这里似乎实现了抽象类的实例化并调用了其方法、实际上这里“是创建抽象类的匿名子类的实例”、然后通过子类来调用其父类的方法\n\n","tags":["other"],"categories":["other"]}]