<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>welcome to my blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://www.shadowerli.com/"/>
  <updated>2019-10-09T13:34:40.870Z</updated>
  <id>https://www.shadowerli.com/</id>
  
  <author>
    <name>Shadowerli</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>DataNode物理结构</title>
    <link href="https://www.shadowerli.com/2019/09/20/2018-3-22/"/>
    <id>https://www.shadowerli.com/2019/09/20/2018-3-22/</id>
    <published>2019-09-19T16:00:00.000Z</published>
    <updated>2019-10-09T13:34:40.870Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>简单总结下DataNode的物理结构<br><a id="more"></a><br>分两个方向来讲述DataNode的目录结构</excerpt></p><h1 id="一、DataNode磁盘目录结构"><a href="#一、DataNode磁盘目录结构" class="headerlink" title="一、DataNode磁盘目录结构"></a>一、DataNode磁盘目录结构</h1><ol><li>比如datanode上有12个盘，同一个块池目录比如BP-1007908154-10.10.10.10-1533290355162存在于所有的盘上。</li></ol><ol><li>在HDFS-6482之前，是通过LDir这个类来存放具体的数据块的目录位置。所以存在一个很大的问题就是当由于数据块的数量非常大的时候，由于需要在内存中记录数据块的具体位置，还需要记录对应的subdirs，会对DN造成很大的内存开销。<blockquote><p>所以这个Patch的思想是通过两层subdir的方式来存放不同的数据块。具体实现是DatanodeUtil.idToBlockDir()分别根据块池id，取第二和第三个字节位来得到两层的subdir的id。这样只需要在用到的时候计算出相应目录即可。</p></blockquote></li></ol><h1 id="二、副本状态"><a href="#二、副本状态" class="headerlink" title="二、副本状态"></a>二、副本状态</h1><p>1.NameNode副本状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">enum</span> BlockUCState &#123;</span><br><span class="line">   <span class="comment">//commit状态的块收到DN的块汇报后</span></span><br><span class="line">   COMPLETE,</span><br><span class="line">   <span class="comment">//正在写入的数据块，大部分的数据块读可见，对应Replica的状态为RBW</span></span><br><span class="line">   UNDER_CONSTRUCTION,</span><br><span class="line">   <span class="comment">//如果客户端写文件超过租约后，如果最后一个数据块处于UNDER_CONSTRUCTION状态，当block恢复开始时，UnderConstruction变为UnderRecovery状态，对应Replica的状态为RUR</span></span><br><span class="line">   UNDER_RECOVERY,</span><br><span class="line">   <span class="comment">//客户端每次请求新的数据块时候，比如写文件，都会对上一个数据块进行提交。这个表示客户端已经收到这个数据块的请求了，只是还没有收到DN的块汇报</span></span><br><span class="line">   COMMITTED;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>2.DataNode副本状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//所有副本状态类的父类</span></span><br><span class="line"><span class="comment">//子类有 FinalizedReplica，ReplicaBeingWritten，ReplicaUnderRecovery，ReplicaWaitingToBeRecovered，ReplicaInPipeline</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReplicaInfo</span> <span class="keyword">extends</span> <span class="title">Block</span> <span class="keyword">implements</span> <span class="title">Replica</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//分别对应于ReplicaState</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">enum</span> ReplicaState &#123;</span><br><span class="line">    <span class="comment">/** Replica is finalized. The state when replica is not modified. */</span></span><br><span class="line">    FINALIZED(<span class="number">0</span>),</span><br><span class="line">    <span class="comment">/** Replica is being written to. */</span></span><br><span class="line">    RBW(<span class="number">1</span>),</span><br><span class="line">    <span class="comment">/** Replica is waiting to be recovered. */</span></span><br><span class="line">    RWR(<span class="number">2</span>),</span><br><span class="line">    <span class="comment">/** Replica is under recovery. */</span></span><br><span class="line">    RUR(<span class="number">3</span>),</span><br><span class="line">    <span class="comment">/** Temporary replica: created for replication and relocation only. */</span></span><br><span class="line">    TEMPORARY(<span class="number">4</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>RWR: ReplicaWaitingToBeRecovered </p><ol><li>如果client挂了之后，RWR状态下的replica将会过期，或者将出现在租约恢复的过程中(将RBW状态的Replica转为RWR)<br>1</li><li>在DN重启加载块的时候，会将所有RWR目录下的数据块标记为ReplicaWaitingToBeRecovered，并将其及副本信息一起添加到ReplicaMap中</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplicaMap</span></span>&#123;</span><br><span class="line">  <span class="comment">//池id-&gt;（块id-&gt;副本信息）</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt; map = <span class="keyword">new</span> HashMap&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>FINALIZED: FinalizedReplica</p><ol><li>表示这个块已经写入完成了，对所有用户都是可见的，最终DU等统计都是以FinalizedReplica的副本为准</li></ol><p>RBW: ReplicaBeingWritten</p><ol><li><p>通常表示一个文件中最后一个正在写入的副本</p></li><li><p>bytesAcked:表示接收到下游ack的bytes数，bytesReserved，block已经接收到的bytes数，包括写入磁盘的和在dn内存中的数据</p></li><li><p>当datanode向下一个datanode发送的数据块写成功了，并且接收到了下一个datanode的ack时，会通过finalizeBlock()提交这个数据块</p></li><li><p>在DN重启加载块的时候，会将所有RBW目录下的数据块标记为ReplicaWaitingToBeRecovered</p></li></ol><p>RUR: ReplicaUnderRecovery</p><ol><li>租约恢复时候，任意一个非Temporary状态的副本都有可能转换为RUR状态。</li><li>比如当客户端写文件中途退出时候，为了保证最后一个数据块的数据一致性，NN会通过下发恢复指令，选择一个主节点，最终通过FsDatasetImpl.initReplicaRecovery()对这个数据块进行恢复</li></ol><p>TEMPORARY: </p><ol><li>数据对客户端不可见</li><li>当DataNode成功接收了其他DataNode的数据块之后，通过DataSetImpl.createTemporary()创建tmp目录，会将这个状态的副本转换为RBW状态</li></ol><p>ReplicaInPipeline:</p><ol><li>通过DataSetImpl.createTemporary()创建的副本类型为ReplicaInPipeline类型<h2 id="各个目录文件的简单总结"><a href="#各个目录文件的简单总结" class="headerlink" title="各个目录文件的简单总结"></a>各个目录文件的简单总结</h2></li></ol><ul><li>finalized：客户端已经完成写入并提交的数据块</li><li>rbw：客户端正在写入的</li><li>tmp：比如当这个副本是Datanode在接收其他Datanode写数据块的请求时在构造BlockReceiver时调用的，即写数据块拷贝的时候，最终调用的入口为DataSetImpl.createTemporary()</li><li>in_used.lock：在初始化块池时，要根据当前的目录分析当前的状态时，会对这个目录加锁。</li></ul><h1 id="三、目录结构对应的逻辑结构"><a href="#三、目录结构对应的逻辑结构" class="headerlink" title="三、目录结构对应的逻辑结构"></a>三、目录结构对应的逻辑结构</h1><h2 id="1-目录维度"><a href="#1-目录维度" class="headerlink" title="1.目录维度"></a>1.目录维度</h2><p>FsDatasetImpl: 实现了FsDatasetSpi接口，管理DataNode上所有的数据块，一些对数据块的各种操作最终都是要访问这个类</p><p>FSVolumeImpl: 管理单个存储目录保存的所有数据块，内部通过CHM维护当前目录下块池ID对应的BlockPoolSlice的映射</p><p>FSVolumeList: 维护所有FSVolumeImpl的引用，通过FsVolumeImpl[]的AtomicReference来管理</p><p>BlockPoolSlice: 管理一个块池的所有数据块，所有的数据块是通过ReplicaMap这个类来进行管理的，ReplicaMap中通过HashMap&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt;来记录，块池id-&gt;（块id-&gt;副本信息）</p><p>BlockPoolSliceStorage: 一个BlockPoolSliceStorage用来管理名字相同的所有的BlockPoolSlice</p><h2 id="2-功能维度"><a href="#2-功能维度" class="headerlink" title="2.功能维度"></a>2.功能维度</h2><p>每个块池对应于每个BPOfferService，目前一共有41个块池，对应线上41个namespace，BPOfferService内部维护了BPServiceActor的列表，实际和NN进行交互的逻辑都是在BPServiceActor中。</p><p>BPOfferService内部还维护了NamespaceInfo的信息，只有当它向NN注册之后才会获取这个信息。</p><h1 id="四、DN启动时两个维度间的交互"><a href="#四、DN启动时两个维度间的交互" class="headerlink" title="四、DN启动时两个维度间的交互"></a>四、DN启动时两个维度间的交互</h1><h2 id="1-重启时主要过程"><a href="#1-重启时主要过程" class="headerlink" title="1.重启时主要过程"></a>1.重启时主要过程</h2><ul><li>首先DN通过配置文件获取NN的命名空间和对应的通信地址</li><li>DN根据命名空间的个数创建对应的BPOfferService，并且在每个BPOfferService中创建数量相同的BPServiceActor来维持通信</li><li>通过调用BPOfferService.start()方法启动BPOfferService下的所有BPServiceActor</li><li>BPServerActor和NN进行握手</li><li>rpc获取NamespaceInfo信息，包含了块池的ID，即BlockPoolID，BP-1007908154-10.10.10.10-1533290355162，还有代码的版本，还有ClusterID，如果失败会sleep一段时间后继续重试。拿到信息后还要进行版本的校验。因为同一组BPActor最终是在BPofferService中的，所以BPofferService只要通过加锁BPOfferService.NamespaceInfo判断是否为空已经初始化过了，来保证一个每个BPofferService中只会进行一次尝试DN初始化操作。</li><li>如果这是当前BPofferService第一个启动的Actor，还会进行初始化块池，如果块池已经初始化完成了则会跳过。</li><li>向NN进行注册，注册的时候会不断尝试直到成功。</li><li>一直执行BPServiceActor.offerService()直到退出- </li><li>发送心跳包</li><li>计算时间定时发送心跳，首先构造StorageReport</li><li>StorageReport初始化的时候会通过DataSetImpl获取每块盘下的存储信息</li><li>发送心跳包时，除了storageReport还包含DN的DU等情况的一些信息</li><li>NN接受心跳包</li><li>Rpc调用sendHeartbeat()</li><li>通过datanodeManger来处理心跳，根据dataNode的id获取dataNodeMap中的DatanodeDescriptor</li><li>最后通过DatanodeDescriptor.updateHeartbeatState()来更新心跳</li><li>每次心跳都会根据report数组来更新这个map，并且把错误的DatanodeStorage从map中移除</li><li>更新失败块的状态，normal–&gt;failed 最后对这个DatanodeDescriptor中的map进行修剪</li><li>NN上还有一个异步的线程定时来检查DatanodeDescriptor坏掉的卷上是否有数据块，如果有则通过blockManager将这些块都移除</li><li>处理从NN发送回来的信息</li><li>调用BPOfferService.processCommand()方法对命令数组进行处理，根据NN返回的cmds数组执行对应的操作</li></ul><h2 id="2-块池初始化逻辑"><a href="#2-块池初始化逻辑" class="headerlink" title="2.块池初始化逻辑"></a>2.块池初始化逻辑</h2><p>主要流程：盘目录的初始化，块池的初始化，数据块的初始化。</p><p>具体的过程：</p><ol><li>DataStorage初始化</li><li>DN上的盘目录的初始化</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//具体的盘的信息存放在DataNode.DataStorage中</span></span><br><span class="line"><span class="comment">//DataStorage extends Storage</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Storage</span> <span class="keyword">extends</span> <span class="title">StorageInfo</span> </span>&#123;</span><br><span class="line"><span class="comment">//存在已经加载完成的盘的列表</span></span><br><span class="line"><span class="keyword">protected</span> List&lt;StorageDirectory&gt; storageDirs = <span class="keyword">new</span> ArrayList&lt;StorageDirectory&gt;();</span><br><span class="line"><span class="comment">//块池的ID到其对应的BlockPoolSliceStorage的映射</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, BlockPoolSliceStorage&gt; bpStorageMap = Collections.synchronizedMap(<span class="keyword">new</span> HashMap&lt;String, BlockPoolSliceStorage&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><p>初始化DN上的存储目录，即之前通过data.dir配置项获取的</p></li><li><p>遍历保存所有的储存的StorageDirectory方法，调用每个StorageDirectory.analyzeStorage() 进行分析</p></li><li><p>加载某个盘的目录时候会通过系统调用判断这个盘目录是否可存在，是否可写，来得到这个盘的一个状态，同时还会判断hasFinalizedTmp，hasRemovedTmp目录的是否存在来判断当前的是否处于升级状态的某个阶段。通常情况下在加载完这个盘后就是Normal状态，最后会持久化Version文件到本地。当这个目录初始化完成后最终会将其添加到上述的storageDirs中。</p></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> hasPrevious = getPreviousDir().exists();</span><br><span class="line"><span class="keyword">boolean</span> hasPreviousTmp = getPreviousTmp().exists();</span><br><span class="line"><span class="keyword">boolean</span> hasRemovedTmp = getRemovedTmp().exists();</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="keyword">if</span> (hasCurrent)</span><br><span class="line">          <span class="keyword">return</span> StorageState.NORMAL;</span><br></pre></td></tr></table></figure><ul><li>DN中定义的存储目录下对应的块池的初始化</li><li>上面加载的都是盘的目录，由于这个块池是存在于所有盘的。所以BlockPoolSliceStorage.recoverTransitionRead()要在每个盘上对应的块池目录调用一次这个方法，(由于BlockPoolSliceStorage也是继承于Storage所以也是有如上两个列表来记录加载完成的目录的信息)，只不过这里对应的盘的列表就变成了对应的块池目录的列表</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (StorageLocation dataDir : dataDirs) &#123;</span><br><span class="line">  <span class="comment">//....</span></span><br><span class="line">  BlockPoolSliceStorage bpStorage = <span class="keyword">this</span>.bpStorageMap.get(bpid);</span><br><span class="line">    <span class="keyword">if</span> (bpStorage == <span class="keyword">null</span>) &#123;</span><br><span class="line">       bpStorage = <span class="keyword">new</span> BlockPoolSliceStorage( );</span><br><span class="line">    &#125;</span><br><span class="line">    bpStorage.recoverTransitionRead( )</span><br><span class="line">    addBlockPoolStorage(bpid, bpStorage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>构造BlockPoolSliceStorage对象，调用BlockPoolSliceStorage.recoverTransitionRead()对每个块池初始化</li><li>块池的初始化和上面的过程类似先analyzeStorage()分析状态，然后根据状态进行恢复，通常重启是normal状态，根据不同的状态执行对应的操作</li><li>所以最终块池目录加载完毕后DataStorage.bpStorageMap中会存在所有块池id及其对应BlockPoolSliceStorage的唯一映射。</li><li>DataSetImpl初始化，通过工厂模式创建</li><li><p>初始化volumes</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//FsVolumeLis用来存放FsVolumeImpl的结构，好处是checkDirs(), getAvailable()就不需要加锁了</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicReference&lt;FsVolumeImpl[]&gt; volumes</span><br></pre></td></tr></table></figure></li><li><p>根据DN的存储目录初始化FsVolumeImpl</p></li><li>cas并发的添加到AtomicReference&lt;FsVolumeImpl[]&gt; volumes，checkDirs(), getAvailable()</li><li>添加对blockScanner的引用，blockScanner在DN初始化后就已经完成</li><li>在volumes添加FsVolumeReference时候会在blockScanner中也添加FsVolumeReference</li><li>初始化完毕后开始在FsVolumeLis创建多个线程并发的添加块池</li><li>遍历volumes列表调用 FsVolumeImpl.addBlockPool()方法</li><li>FsVolumeImpl构造BlockPoolSlice 并将其添加到bpSlices 的Map中</li><li>首先启动和盘的数量相同的线程并行的加载每个盘下的块池目录，比如初始化每个盘下对应的块池id-&gt;BlockPoolSliceStorage的映射。</li><li>构造BlockPoolSlice时会创建current，rbw，tmp，等目录</li><li>数据块的初始化操作</li><li>块池目录加载完成后，启动多个线程对每个盘下的数据块副本进行加。</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Thread&gt; replicaAddingThreads = <span class="keyword">new</span> ArrayList&lt;Thread&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">final</span> FsVolumeImpl v : volumes.get()) &#123;</span><br><span class="line">  Thread t = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">  &#125;</span><br><span class="line">  replicaAddingThreads.add(t);</span><br><span class="line">  t.start();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (Thread t : replicaAddingThreads) &#123;</span><br><span class="line">  t.join();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ol><li>最终通过BlockPoolSlice.addToReplicasMap()在每个传入的ReplicaMap上添加各个目录下的数据块，比如Finalize和rbwDir的数据块。</li><li>最终初始化之后的结果是FsVolumeList这个类中的volumes包含了所有的盘的目录，并且每个FsVolumeImpl中记录了每个目录下的各个块的实例，最终存放在ReplicaMap.Map&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt; map这个map中块池id-&gt;（块id-&gt;副本信息）</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;excerpt in=&quot;&quot; index=&quot;&quot; |=&quot;&quot; 首页摘要=&quot;&quot;&gt;&lt;br&gt;简单总结下DataNode的物理结构&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://www.shadowerli.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="https://www.shadowerli.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>DataNode物理结构</title>
    <link href="https://www.shadowerli.com/2018/09/13/2018-9-13/"/>
    <id>https://www.shadowerli.com/2018/09/13/2018-9-13/</id>
    <published>2018-09-12T16:00:00.000Z</published>
    <updated>2019-10-09T13:22:52.605Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>简单总结下DataNode的物理结构<br><a id="more"></a><br>分两个方向来讲述DataNode的目录结构</excerpt></p><p>一、DataNode磁盘目录结构<br>比如datanode上有12个盘，同一个块池目录比如BP-1007908154-10.10.10.10-1533290355162存在于所有的盘上。</p><p>在HDFS-6482之前，是通过LDir这个类来存放具体的数据块的目录位置。所以存在一个很大的问题就是当由于数据块的数量非常大的时候，由于需要在内存中记录数据块的具体位置，还需要记录对应的subdirs，会对DN造成很大的内存开销。所以这个Patch的思想是通过两层subdir的方式来存放不同的数据块。具体实现是DatanodeUtil.idToBlockDir()分别根据块池id，取第二和第三个字节位来得到两层的subdir的id。这样只需要在用到的时候计算出相应目录即可。</p><p>二、副本状态<br>1.NameNode副本状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">enum</span> BlockUCState &#123;</span><br><span class="line">   <span class="comment">//commit状态的块收到DN的块汇报后</span></span><br><span class="line">   COMPLETE,</span><br><span class="line">   <span class="comment">//正在写入的数据块，大部分的数据块读可见，对应Replica的状态为RBW</span></span><br><span class="line">   UNDER_CONSTRUCTION,</span><br><span class="line">   <span class="comment">//如果客户端写文件超过租约后，如果最后一个数据块处于UNDER_CONSTRUCTION状态，当block恢复开始时，UnderConstruction变为UnderRecovery状态，对应Replica的状态为RUR</span></span><br><span class="line">   UNDER_RECOVERY,</span><br><span class="line">   <span class="comment">//客户端每次请求新的数据块时候，比如写文件，都会对上一个数据块进行提交。这个表示客户端已经收到这个数据块的请求了，只是还没有收到DN的块汇报</span></span><br><span class="line">   COMMITTED;</span><br><span class="line"> &#125;</span><br></pre></td></tr></table></figure></p><p>2.DataNode副本状态<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//所有副本状态类的父类</span></span><br><span class="line"><span class="comment">//子类有 FinalizedReplica，ReplicaBeingWritten，ReplicaUnderRecovery，ReplicaWaitingToBeRecovered，ReplicaInPipeline</span></span><br><span class="line"><span class="keyword">abstract</span> <span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReplicaInfo</span> <span class="keyword">extends</span> <span class="title">Block</span> <span class="keyword">implements</span> <span class="title">Replica</span> </span>&#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//分别对应于ReplicaState</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">public</span> <span class="keyword">enum</span> ReplicaState &#123;</span><br><span class="line">    <span class="comment">/** Replica is finalized. The state when replica is not modified. */</span></span><br><span class="line">    FINALIZED(<span class="number">0</span>),</span><br><span class="line">    <span class="comment">/** Replica is being written to. */</span></span><br><span class="line">    RBW(<span class="number">1</span>),</span><br><span class="line">    <span class="comment">/** Replica is waiting to be recovered. */</span></span><br><span class="line">    RWR(<span class="number">2</span>),</span><br><span class="line">    <span class="comment">/** Replica is under recovery. */</span></span><br><span class="line">    RUR(<span class="number">3</span>),</span><br><span class="line">    <span class="comment">/** Temporary replica: created for replication and relocation only. */</span></span><br><span class="line">    TEMPORARY(<span class="number">4</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>RWR: ReplicaWaitingToBeRecovered </p><p>如果client挂了之后，RWR状态下的replica将会过期，或者将出现在租约恢复的过程中(将RBW状态的Replica转为RWR)</p><p>在DN重启加载块的时候，会将所有RWR目录下的数据块标记为ReplicaWaitingToBeRecovered，并将其及副本信息一起添加到ReplicaMap中</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ReplicaMap</span></span>&#123;</span><br><span class="line">  <span class="comment">//池id-&gt;（块id-&gt;副本信息）</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt; map = <span class="keyword">new</span> HashMap&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt;();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>FINALIZED: FinalizedReplica</p><p>表示这个块已经写入完成了，对所有用户都是可见的，最终DU等统计都是以FinalizedReplica的副本为准</p><p>RBW: ReplicaBeingWritten</p><p>通常表示一个文件中最后一个正在写入的副本</p><p>bytesAcked:表示接收到下游ack的bytes数，bytesReserved，block已经接收到的bytes数，包括写入磁盘的和在dn内存中的数据</p><p>当datanode向下一个datanode发送的数据块写成功了，并且接收到了下一个datanode的ack时，会通过finalizeBlock()提交这个数据块</p><p>在DN重启加载块的时候，会将所有RBW目录下的数据块标记为ReplicaWaitingToBeRecovered</p><p>RUR: ReplicaUnderRecovery</p><p>租约恢复时候，任意一个非Temporary状态的副本都有可能转换为RUR状态。</p><p>比如当客户端写文件中途退出时候，为了保证最后一个数据块的数据一致性，NN会通过下发恢复指令，选择一个主节点，最终通过FsDatasetImpl.initReplicaRecovery()对这个数据块进行恢复</p><p>TEMPORARY: </p><p>数据不可见</p><p>当DataNode成功接收了其他DataNode的数据块之后，通过DataSetImpl.createTemporary()创建tmp目录，会将这个状态的副本转换为RBW状态</p><p>ReplicaInPipeline:</p><p>通过DataSetImpl.createTemporary()创建的副本类型为ReplicaInPipeline类型</p><p>各个目录文件的简单总结</p><p>finalized：客户端已经完成写入并提交的数据块</p><p>rbw：客户端正在写入的</p><p>tmp：比如当这个副本是Datanode在接收其他Datanode写数据块的请求时在构造BlockReceiver时调用的，即写数据块拷贝的时候，最终调用的入口为DataSetImpl.createTemporary()</p><p>in_used.lock：在初始化块池时，要根据当前的目录分析当前的状态时，会对这个目录加锁。</p><p>三、目录结构对应的逻辑结构<br>1.目录维度<br>FsDatasetImpl: 实现了FsDatasetSpi接口，管理DataNode上所有的数据块，一些对数据块的各种操作最终都是要访问这个类</p><p>FSVolumeImpl: 管理单个存储目录保存的所有数据块，内部通过CHM维护当前目录下块池ID对应的BlockPoolSlice的映射</p><p>FSVolumeList: 维护所有FSVolumeImpl的引用，通过FsVolumeImpl[]的AtomicReference来管理</p><p>BlockPoolSlice: 管理一个块池的所有数据块，所有的数据块是通过ReplicaMap这个类来进行管理的，ReplicaMap中通过HashMap&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt;来记录，块池id-&gt;（块id-&gt;副本信息）</p><p>BlockPoolSliceStorage: 一个BlockPoolSliceStorage用来管理名字相同的所有的BlockPoolSlice</p><p>2.功能维度<br>每个块池对应于每个BPOfferService，目前一共有41个块池，对应线上41个namespace，BPOfferService内部维护了BPServiceActor的列表，实际和NN进行交互的逻辑都是在BPServiceActor中。</p><p>BPOfferService内部还维护了NamespaceInfo的信息，只有当它向NN注册之后才会获取这个信息。</p><p>四、DN启动时两个维度间的交互<br>1.重启时主要过程<br>首先DN通过配置文件获取NN的命名空间和对应的通信地址</p><p>DN根据命名空间的个数创建对应的BPOfferService，并且在每个BPOfferService中创建数量相同的BPServiceActor来维持通信</p><p>通过调用BPOfferService.start()方法启动BPOfferService下的所有BPServiceActor</p><p>BPServerActor和NN进行握手</p><p>rpc获取NamespaceInfo信息，包含了块池的ID，即BlockPoolID，BP-1007908154-10.21.105.27-1533290355162，还有代码的版本，还有ClusterID，如果失败会sleep一段时间后继续重试。拿到信息后还要进行版本的校验。因为同一组BPActor最终是在BPofferService中的，所以BPofferService只要通过加锁BPOfferService.NamespaceInfo判断是否为空已经初始化过了，来保证一个每个BPofferService中只会进行一次尝试DN初始化操作。</p><p>如果这是当前BPofferService第一个启动的Actor，还会进行初始化块池，如果块池已经初始化完成了则会跳过。</p><p>向NN进行注册，注册的时候会不断尝试直到成功。</p><p>一直执行BPServiceActor.offerService()直到退出</p><p>发送心跳包</p><p>计算时间定时发送心跳，首先构造StorageReport</p><p>StorageReport初始化的时候会通过DataSetImpl获取每块盘下的存储信息</p><p>发送心跳包时，除了storageReport还包含DN的DU等情况的一些信息</p><p>NN接受心跳包</p><p>Rpc调用sendHeartbeat()</p><p>通过datanodeManger来处理心跳，根据dataNode的id获取dataNodeMap中的DatanodeDescriptor</p><p>最后通过DatanodeDescriptor.updateHeartbeatState()来更新心跳</p><p>DatanodeDescriptor内部维护了一个map，记录DatanodeStorage字符串例如[DS-be674d29-b993-45e7-bae3-d3e811d03b30,DISK,NORMAL]到DatanodeStorageInfo的映射关系，</p><p>每次心跳都会根据report数组来更新这个map，并且把错误的DatanodeStorage从map中移除</p><p>更新失败块的状态，normal–&gt;failed 最后对这个DatanodeDescriptor中的map进行修剪</p><p>NN上还有一个异步的线程定时来检查DatanodeDescriptor坏掉的卷上是否有数据块，如果有则通过blockManager将这些块都移除</p><p>处理从NN发送回来的信息</p><p>调用BPOfferService.processCommand()方法对命令数组进行处理，根据NN返回的cmds数组执行对应的操作</p><p>2.块池初始化逻辑<br>主要流程：盘目录的初始化，块池的初始化，数据块的初始化。</p><p>具体的过程：</p><p>DataStorage初始化</p><p>DN上的盘目录的初始化</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//具体的盘的信息存放在DataNode.DataStorage中</span></span><br><span class="line"><span class="comment">//DataStorage extends Storage</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="class"><span class="keyword">class</span> <span class="title">Storage</span> <span class="keyword">extends</span> <span class="title">StorageInfo</span> </span>&#123;</span><br><span class="line"><span class="comment">//存在已经加载完成的盘的列表</span></span><br><span class="line"><span class="keyword">protected</span> List&lt;StorageDirectory&gt; storageDirs = <span class="keyword">new</span> ArrayList&lt;StorageDirectory&gt;();</span><br><span class="line"><span class="comment">//块池的ID到其对应的BlockPoolSliceStorage的映射</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> Map&lt;String, BlockPoolSliceStorage&gt; bpStorageMap = Collections.synchronizedMap(<span class="keyword">new</span> HashMap&lt;String, BlockPoolSliceStorage&gt;());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>初始化DN上的存储目录，即之前通过data.dir配置项获取的</p><p>遍历保存所有的储存的StorageDirectory方法，调用每个StorageDirectory.analyzeStorage() 进行分析</p><p>加载某个盘的目录时候会通过系统调用判断这个盘目录是否可存在，是否可写，来得到这个盘的一个状态，同时还会判断hasFinalizedTmp，hasRemovedTmp目录的是否存在来判断当前的是否处于升级状态的某个阶段。通常情况下在加载完这个盘后就是Normal状态，最后会持久化Version文件到本地。当这个目录初始化完成后最终会将其添加到上述的storageDirs中。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">boolean</span> hasPrevious = getPreviousDir().exists();</span><br><span class="line"><span class="keyword">boolean</span> hasPreviousTmp = getPreviousTmp().exists();</span><br><span class="line"><span class="keyword">boolean</span> hasRemovedTmp = getRemovedTmp().exists();</span><br><span class="line"><span class="comment">//...</span></span><br><span class="line"><span class="keyword">if</span> (hasCurrent)</span><br><span class="line">          <span class="keyword">return</span> StorageState.NORMAL;</span><br></pre></td></tr></table></figure><p>DN中定义的存储目录下对应的块池的初始化</p><p>上面加载的都是盘的目录，由于这个块池是存在于所有盘的。所以BlockPoolSliceStorage.recoverTransitionRead()要在每个盘上对应的块池目录调用一次这个方法，(由于BlockPoolSliceStorage也是继承于Storage所以也是有如上两个列表来记录加载完成的目录的信息)，只不过这里对应的盘的列表就变成了对应的块池目录的列表</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (StorageLocation dataDir : dataDirs) &#123;</span><br><span class="line">  <span class="comment">//....</span></span><br><span class="line">  BlockPoolSliceStorage bpStorage = <span class="keyword">this</span>.bpStorageMap.get(bpid);</span><br><span class="line">    <span class="keyword">if</span> (bpStorage == <span class="keyword">null</span>) &#123;</span><br><span class="line">       bpStorage = <span class="keyword">new</span> BlockPoolSliceStorage( );</span><br><span class="line">    &#125;</span><br><span class="line">    bpStorage.recoverTransitionRead( )</span><br><span class="line">    addBlockPoolStorage(bpid, bpStorage);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>构造BlockPoolSliceStorage对象，调用BlockPoolSliceStorage.recoverTransitionRead()对每个块池初始化</p><p>块池的初始化和上面的过程类似先analyzeStorage()分析状态，然后根据状态进行恢复，通常重启是normal状态，根据不同的状态执行对应的操作</p><p>所以最终块池目录加载完毕后DataStorage.bpStorageMap中会存在所有块池id及其对应BlockPoolSliceStorage的唯一映射。</p><p>DataSetImpl初始化，通过工厂模式创建</p><p>初始化volumes</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//FsVolumeLis用来存放FsVolumeImpl的结构，好处是checkDirs(), getAvailable()就不需要加锁了</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> AtomicReference&lt;FsVolumeImpl[]&gt; volumes</span><br></pre></td></tr></table></figure><p>根据DN的存储目录初始化FsVolumeImpl</p><p>cas并发的添加到AtomicReference&lt;FsVolumeImpl[]&gt; volumes，checkDirs(), getAvailable()</p><p>添加对blockScanner的引用，blockScanner在DN初始化后就已经完成</p><p>在volumes添加FsVolumeReference时候会在blockScanner中也添加FsVolumeReference</p><p>初始化完毕后开始在FsVolumeLis创建多个线程并发的添加块池</p><p>遍历volumes列表调用 FsVolumeImpl.addBlockPool()方法</p><p>FsVolumeImpl构造BlockPoolSlice 并将其添加到bpSlices 的Map中</p><p>首先启动和盘的数量相同的线程并行的加载每个盘下的块池目录，比如初始化每个盘下对应的块池id-&gt;BlockPoolSliceStorage的映射。</p><p>构造BlockPoolSlice时会创建current，rbw，tmp，等目录</p><p>数据块的初始化操作</p><p>块池目录加载完成后，启动多个线程对每个盘下的数据块副本进行加载。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Thread&gt; replicaAddingThreads = <span class="keyword">new</span> ArrayList&lt;Thread&gt;();</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">final</span> FsVolumeImpl v : volumes.get()) &#123;</span><br><span class="line">  Thread t = <span class="keyword">new</span> Thread() &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">  &#125;</span><br><span class="line">  replicaAddingThreads.add(t);</span><br><span class="line">  t.start();</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span> (Thread t : replicaAddingThreads) &#123;</span><br><span class="line">  t.join();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>最终通过BlockPoolSlice.addToReplicasMap()在每个传入的ReplicaMap上添加各个目录下的数据块，比如Finalize和rbwDir的数据块。</p><p>最终初始化之后的结果是FsVolumeList这个类中的volumes包含了所有的盘的目录，并且每个FsVolumeImpl中记录了每个目录下的各个块的实例，最终存放在ReplicaMap.Map&lt;String, Map&lt;Long, ReplicaInfo&gt;&gt; map这个map中块池id-&gt;（块id-&gt;副本信息）</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;excerpt in=&quot;&quot; index=&quot;&quot; |=&quot;&quot; 首页摘要=&quot;&quot;&gt;&lt;br&gt;简单总结下DataNode的物理结构&lt;br&gt;
    
    </summary>
    
      <category term="大数据" scheme="https://www.shadowerli.com/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"/>
    
    
      <category term="hadoop" scheme="https://www.shadowerli.com/tags/hadoop/"/>
    
  </entry>
  
  <entry>
    <title>安全检测</title>
    <link href="https://www.shadowerli.com/2018/05/03/2018-5-3%20/"/>
    <id>https://www.shadowerli.com/2018/05/03/2018-5-3 /</id>
    <published>2018-05-02T16:00:00.000Z</published>
    <updated>2018-12-11T13:40:06.000Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>某比赛要求在施工通过监控对没带安全帽的人进行报警<br><a id="more"></a><br>先吐槽一下比赛的主办方、给的测试视屏画质极低拍摄极为敷衍、有些人连人眼都无法识别是否带了安全帽、这小小的比赛大概整了整个51假期吧、</excerpt></p><h2 id="简单介绍"><a href="#简单介绍" class="headerlink" title="简单介绍"></a>简单介绍</h2><p>这里主要提供一下思路、传统ssd(高配电脑fater-rcnn走起)+inception3、你可能会问为什么不直接用ssd进行二次训练就好了、我当初也是这么想的这不是很简单么、<br>然后我先把视频一帧帧的读取并转化成图像然后手动lable(这里有个问题就是一个图像中有多个人这样训练的时候会不会造成无法收敛？我觉得会有很大的影响)、<br>然后训练这个像打了码一样的图片(再次吐槽一下主办方)、结果连人都识别不出来！！！内心极度奔溃、然后就用了独创非主流方法</p><h2 id="具体步骤-非主流方法请勿模仿、"><a href="#具体步骤-非主流方法请勿模仿、" class="headerlink" title="具体步骤(非主流方法请勿模仿、)"></a>具体步骤(非主流方法请勿模仿、)</h2><p>鉴于之前连人都识别出来的问题、我就直接调用ssd先去除人、然后对有戴和没戴安全帽的进行训练(通过inception3)、然后运行通过ssd的目标检测结果输入到inception3中进行判别<br>判别的结果传给之前的显示字符串然后进行输出、下面附上源码(目录与object_detection一致)</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#视频的读取得到识别物体后显示出来</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> utils.app_utils <span class="keyword">import</span> FPS</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> label_map_util</span><br><span class="line"><span class="keyword">from</span> object_detection.utils <span class="keyword">import</span> visualization_utils <span class="keyword">as</span> vis_util</span><br><span class="line"></span><br><span class="line">CWD_PATH = os.getcwd()</span><br><span class="line"></span><br><span class="line">MODEL_NAME = <span class="string">'ssd_mobilenet_v1_coco_11_06_2017'</span></span><br><span class="line">PATH_TO_CKPT = os.path.join(CWD_PATH, <span class="string">'object_detection'</span>, MODEL_NAME, <span class="string">'frozen_inference_graph.pb'</span>)</span><br><span class="line">PATH_TO_LABELS = os.path.join(CWD_PATH, <span class="string">'object_detection'</span>, <span class="string">'data'</span>, <span class="string">'mscoco_label_map.pbtxt'</span>)</span><br><span class="line"></span><br><span class="line">NUM_CLASSES = <span class="number">2</span></span><br><span class="line">label_map = label_map_util.load_labelmap(PATH_TO_LABELS)</span><br><span class="line"></span><br><span class="line">categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,</span><br><span class="line">                                                            use_display_name=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">category_index = label_map_util.create_category_index(categories)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">detect_objects</span><span class="params">(image_np, sess, detection_graph)</span>:</span></span><br><span class="line">    <span class="comment"># 增加输入图像的维度: [1, None, None, 3]</span></span><br><span class="line">    image_np_expanded = np.expand_dims(image_np, axis=<span class="number">0</span>)</span><br><span class="line">    image_tensor = detection_graph.get_tensor_by_name(<span class="string">'image_tensor:0'</span>)</span><br><span class="line">    <span class="comment"># 得到检测框</span></span><br><span class="line">    boxes = detection_graph.get_tensor_by_name(<span class="string">'detection_boxes:0'</span>)</span><br><span class="line">    <span class="comment">#得到他的得分</span></span><br><span class="line">    scores = detection_graph.get_tensor_by_name(<span class="string">'detection_scores:0'</span>)</span><br><span class="line">    classes = detection_graph.get_tensor_by_name(<span class="string">'detection_classes:0'</span>)</span><br><span class="line">    num_detections = detection_graph.get_tensor_by_name(<span class="string">'num_detections:0'</span>)</span><br><span class="line">    <span class="comment"># Actual detection.</span></span><br><span class="line">    <span class="comment"># 这里的class是包含多个识别种类的二维数组</span></span><br><span class="line">    <span class="comment">#[[100,4]]boxes 每个框的位置坐标,    scores 100个 ,     classes 100个 ,    num_detections 100个</span></span><br><span class="line">    (boxes, scores, classes, num_detections) = sess.run(</span><br><span class="line">        [boxes, scores, classes, num_detections],</span><br><span class="line">        feed_dict=&#123;image_tensor: image_np_expanded&#125;)</span><br><span class="line">    <span class="comment"># Visualization of the results of a detection.</span></span><br><span class="line">    vis_util.visualize_boxes_and_labels_on_image_array(</span><br><span class="line">        image_np,</span><br><span class="line">        np.squeeze(boxes),</span><br><span class="line">        np.squeeze(classes).astype(np.int32),</span><br><span class="line">        np.squeeze(scores),</span><br><span class="line">        category_index,</span><br><span class="line">        use_normalized_coordinates=<span class="keyword">True</span>,</span><br><span class="line">        line_thickness=<span class="number">4</span>,</span><br><span class="line">        min_score_thresh=<span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">return</span> image_np</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    detection_graph = tf.Graph()</span><br><span class="line">    <span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">        od_graph_def = tf.GraphDef()</span><br><span class="line">        <span class="keyword">with</span> tf.gfile.GFile(PATH_TO_CKPT, <span class="string">'rb'</span>) <span class="keyword">as</span> fid:</span><br><span class="line">            serialized_graph = fid.read()</span><br><span class="line">            od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">            tf.import_graph_def(od_graph_def, name=<span class="string">''</span>)</span><br><span class="line">    sess = tf.Session(graph=detection_graph)</span><br><span class="line">    video_capture = cv2.VideoCapture(<span class="string">'b.mp4'</span>)</span><br><span class="line">    fps = FPS().start()</span><br><span class="line">    frame_width = int(video_capture.get(<span class="number">3</span>))</span><br><span class="line">    frame_height = int(video_capture.get(<span class="number">4</span>))</span><br><span class="line">    <span class="comment"># define video output</span></span><br><span class="line">    out = cv2.VideoWriter(<span class="string">'outpy.mp4'</span>, cv2.VideoWriter_fourcc(<span class="string">'M'</span>, <span class="string">'J'</span>, <span class="string">'P'</span>, <span class="string">'G'</span>), <span class="number">10</span>, (frame_width, frame_height))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> video_capture.isOpened():</span><br><span class="line">        ret, frame = video_capture.read()</span><br><span class="line">        t = time.time()</span><br><span class="line">        detected_image = detect_objects(frame, sess, detection_graph)</span><br><span class="line">        fps.update()</span><br><span class="line">        cv2.imshow(<span class="string">'Video'</span>, detected_image)</span><br><span class="line"><span class="comment">#本来想来做个更加流畅的优化、就是格一个帧进行识别、但还是会阻塞</span></span><br><span class="line">        <span class="comment">#if count % 100 == 0:</span></span><br><span class="line">        <span class="comment">#    print(count)</span></span><br><span class="line">        <span class="comment"># write to video file</span></span><br><span class="line">        <span class="comment">#out.write(detected_image)</span></span><br><span class="line">        <span class="comment"># print('[INFO] elapsed time: &#123;:.2f&#125;'.format(time.time() - t))</span></span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    fps.stop()</span><br><span class="line">    video_capture.release()</span><br><span class="line">    sess.close()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#visualization_untils</span></span><br><span class="line"><span class="comment">#第160行进行如下修改、check为inception3的入口、将图片和坐标传入</span></span><br><span class="line">  <span class="keyword">if</span> use_normalized_coordinates:</span><br><span class="line">    (left, right, top, bottom) = (xmin * im_width, xmax * im_width,</span><br><span class="line">                                  ymin * im_height, ymax * im_height)</span><br><span class="line">    </span><br><span class="line">    name=check(image.copy(), left, right, top, bottom)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">##188 行处</span></span><br><span class="line"><span class="comment">#name为全局变量、接受inception3识别结果的字符串</span></span><br><span class="line">draw.text(</span><br><span class="line">        (left + margin, text_bottom - text_height - margin),</span><br><span class="line">        name,</span><br><span class="line">        fill=<span class="string">'black'</span>,</span><br><span class="line">        font=font)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment">#check模块、inception3的入口</span></span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> pylab <span class="keyword">import</span> array</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(image,left, right, top, bottom)</span>:</span></span><br><span class="line">    got = array(image)</span><br><span class="line">    crop_img = got[int(top):int(bottom), int(left):int(right), <span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line"><span class="comment">#载入之前自己训练的模型</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'output_graph.pb'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">        graph_def = tf.GraphDef()</span><br><span class="line">        graph_def.ParseFromString(f.read())</span><br><span class="line">        tf.import_graph_def(graph_def, name=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">'final_result:0'</span>)</span><br><span class="line"><span class="comment">#将传入的图片格式转化一下</span></span><br><span class="line">        first = tf.image.convert_image_dtype(crop_img, dtype=tf.float32)</span><br><span class="line">        <span class="comment"># jpeg 进行编码</span></span><br><span class="line">        <span class="comment"># eval()想当于将tensorflow的存储格式中提取出来以数组的格式</span></span><br><span class="line">        encode = tf.image.encode_jpeg(first.eval())</span><br><span class="line">        <span class="comment">#将编码好的图片传入以decodejpeg的格式</span></span><br><span class="line">        predictions = sess.run(softmax_tensor, &#123;<span class="string">'DecodeJpeg/contents:0'</span>: encode.eval()&#125;)  <span class="comment"># 图片格式是jpeg格式</span></span><br><span class="line">        predictions = np.squeeze(predictions)  <span class="comment"># 把结果转为1维数据</span></span><br><span class="line">        top_k = predictions.argsort()[::<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> top_k[<span class="number">0</span>]==<span class="number">1</span>:</span><br><span class="line">            human_string=<span class="string">"unsafe"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            human_string=<span class="string">"safe"</span></span><br><span class="line">        <span class="keyword">return</span> human_string</span><br><span class="line">        <span class="comment">#返回给画框的代码</span></span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>看似十分完美流程的过程在实际运行时由于笔记本配置低下(好想要GPU的台式机！！)、换了一台配置稍微高一点的本、但还是崩了、tensorflow开两个session的内存消耗比想象中的要大、开<br>看来这操作只能是活在梦里了、希望以后能想出一种底层之间的优化(相比之前的已经做了很多IO的优化、但主要问题还是这是线性的操作、一定有卡顿来进行二次判断)</p><h2 id="更新！！！"><a href="#更新！！！" class="headerlink" title="更新！！！"></a>更新！！！</h2><p>终于找到了问题所在！！原来每一帧的图像传入后都要重新加载一次graph！！所以导致内存直接爆炸！改动后可以跑的动了、但比较吃配置配置高一点的话可以更加流畅吧、<br>具体改动如下、其余的改动就是要在每个调用的visualization_utils中的函数里传入初始化的graph、具体修改如下、整个项目会放到github上</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#主要是对main函数下的修改vediondetection.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="comment">#tf.Graph()生成新的图</span></span><br><span class="line">    detection_graph = tf.Graph()</span><br><span class="line">    inceptionsess =tf.Graph()</span><br><span class="line">    <span class="keyword">with</span> inceptionsess.as_default():</span><br><span class="line">        od_graph_def = tf.GraphDef()</span><br><span class="line">        <span class="keyword">with</span> tf.gfile.FastGFile(<span class="string">'output_graph.pb'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">            serialized_graph = f.read()</span><br><span class="line">            od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">            tf.import_graph_def(od_graph_def, name=<span class="string">''</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> detection_graph.as_default():</span><br><span class="line">        od_graph_def = tf.GraphDef()</span><br><span class="line">        <span class="keyword">with</span> tf.gfile.GFile(PATH_TO_CKPT, <span class="string">'rb'</span>) <span class="keyword">as</span> fid:</span><br><span class="line">            serialized_graph = fid.read()</span><br><span class="line">            od_graph_def.ParseFromString(serialized_graph)</span><br><span class="line">            tf.import_graph_def(od_graph_def, name=<span class="string">''</span>)</span><br><span class="line">    sess = tf.Session(graph=detection_graph)</span><br><span class="line">    video_capture = cv2.VideoCapture(<span class="string">'b.mp4'</span>)</span><br><span class="line">    fps = FPS().start()</span><br><span class="line">    frame_width = int(video_capture.get(<span class="number">3</span>))</span><br><span class="line">    frame_height = int(video_capture.get(<span class="number">4</span>))</span><br><span class="line">    <span class="comment"># define video output</span></span><br><span class="line">    out = cv2.VideoWriter(<span class="string">'outpy.mp4'</span>, cv2.VideoWriter_fourcc(<span class="string">'M'</span>, <span class="string">'J'</span>, <span class="string">'P'</span>, <span class="string">'G'</span>), <span class="number">10</span>, (frame_width, frame_height))</span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> video_capture.isOpened():</span><br><span class="line">        ret, frame = video_capture.read()</span><br><span class="line">        t = time.time()</span><br><span class="line">        detected_image = detect_objects(frame, sess, detection_graph,inceptionsess)</span><br><span class="line">        fps.update()</span><br><span class="line">        out.write(detected_image)</span><br><span class="line">        cv2.imshow(<span class="string">'Video'</span>, detected_image)</span><br><span class="line">        <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == ord(<span class="string">'q'</span>):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    fps.stop()</span><br><span class="line">    video_capture.release()</span><br><span class="line">    sess.close()</span><br><span class="line">    cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#对checker类的方法进行的改动</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">check</span><span class="params">(image,left, right, top, bottom,inceptionsess)</span>:</span></span><br><span class="line">    got = array(image)</span><br><span class="line">    crop_img = got[int(top):int(bottom), int(left):int(right), <span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">    <span class="comment"># with tf.gfile.FastGFile('output_graph.pb', 'rb') as f:</span></span><br><span class="line">    <span class="comment">#     graph_def = tf.GraphDef()</span></span><br><span class="line">    <span class="comment">#     graph_def.ParseFromString(f.read())</span></span><br><span class="line">    <span class="comment">#     tf.import_graph_def(graph_def, name='')</span></span><br><span class="line">    <span class="keyword">with</span> tf.Session(graph=inceptionsess) <span class="keyword">as</span> sess:</span><br><span class="line">        softmax_tensor = sess.graph.get_tensor_by_name(<span class="string">'final_result:0'</span>)</span><br><span class="line">        <span class="comment"># jpeg 进行编码</span></span><br><span class="line">        <span class="comment"># """Return the value of the tensor represented by this handle.""</span></span><br><span class="line">        encode = tf.image.encode_jpeg(crop_img)</span><br><span class="line">        predictions = sess.run(softmax_tensor, &#123;<span class="string">'DecodeJpeg/contents:0'</span>: encode.eval()&#125;)  <span class="comment"># 图片格式是jpg格式</span></span><br><span class="line">        predictions = np.squeeze(predictions)  <span class="comment"># 把结果转为1维数据</span></span><br><span class="line">        top_k = predictions.argsort()[::<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">if</span> top_k[<span class="number">0</span>]==<span class="number">1</span>:</span><br><span class="line">            human_string=<span class="string">"unsafe"</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            human_string=<span class="string">"safe"</span></span><br><span class="line">        <span class="keyword">return</span> human_string</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;excerpt in=&quot;&quot; index=&quot;&quot; |=&quot;&quot; 首页摘要=&quot;&quot;&gt;&lt;br&gt;某比赛要求在施工通过监控对没带安全帽的人进行报警&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://www.shadowerli.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="图像识别" scheme="https://www.shadowerli.com/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>定点识别</title>
    <link href="https://www.shadowerli.com/2018/04/08/2018-4-8/"/>
    <id>https://www.shadowerli.com/2018/04/08/2018-4-8/</id>
    <published>2018-04-07T16:00:00.000Z</published>
    <updated>2018-12-11T13:40:00.000Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>基于object_detection训练自己的模型<br><a id="more"></a><br>花了不知道多少天、、主要参加一个定点识别的比赛、算是把模型搞定了、虽然结果十分的令人喜感（哈哈、不说了）、、难度有一点大（主要是各种天坑、在这里记录一下）</excerpt></p><p>这是阿里天池的比赛、比赛给出上万张图片主要是服装、要在每个图片上识别出服装每个关键点、并将识别结果的坐标输出、比如左袖口什么的、差不多有24个标签吧、训练集给出的是每个图片的所有关键点的坐标、我的思路是先根据坐标<br>转化成矩形框(同时对x和y加上自己定义的距离数)、然后通过object_detection确定定位的位置、最后在进行输出(求两个x和两个y的平均来得到中心点)、具体步骤如下：</p><h2 id="根据lable切分图片"><a href="#根据lable切分图片" class="headerlink" title="根据lable切分图片"></a>根据lable切分图片</h2><p>这个脚本主要是根据lable对图片进行切分、根据lable创建若干个文件夹、切好的图片放到每个对应的文件加下、切分完得到几十万张图片(此刻的内心是奔溃的)、<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">path=os.getcwd()</span><br><span class="line"><span class="comment">#自己定义框的宽度wide</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">drawcnts_and_cut</span><span class="params">(original_img,x,y,wide)</span>:</span></span><br><span class="line">    x1=x-wide</span><br><span class="line">    x2=x+wide</span><br><span class="line">    y1=y-wide</span><br><span class="line">    y2=y+wide</span><br><span class="line">    crop_img = original_img[y1:y2, x1:x2]</span><br><span class="line">    <span class="keyword">return</span>  crop_img</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start</span><span class="params">(img_path,save_path,x,y)</span>:</span></span><br><span class="line">    original_img= cv2.imread(img_path)</span><br><span class="line">    crop_img = drawcnts_and_cut(original_img,int(x),int(y),<span class="number">25</span>)</span><br><span class="line">    cv2.imwrite(save_path, crop_img)</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">datatranslate</span><span class="params">(data)</span>:</span></span><br><span class="line">    splited=str(data).split()</span><br><span class="line">    <span class="keyword">return</span> splited[<span class="number">0</span>],splited[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#自己根据标签数量来改</span></span><br><span class="line">lable=[<span class="string">'class1'</span>, <span class="string">'class2'</span>]</span><br><span class="line">csv_reader = csv.reader(open(<span class="string">'train\\input.csv'</span>, encoding=<span class="string">'utf-8'</span>))</span><br><span class="line">num=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> csv_reader:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">26</span>,<span class="number">1</span>):</span><br><span class="line">        photo=row[<span class="number">0</span>]</span><br><span class="line">        data=row[i]</span><br><span class="line">        category=lable[i]</span><br><span class="line">        splited = str(row[i]).split(<span class="string">"_"</span>)</span><br><span class="line">        print(photo)</span><br><span class="line">        print(num)</span><br><span class="line">        <span class="keyword">if</span> int(splited[<span class="number">0</span>])!=<span class="number">-1</span>:</span><br><span class="line">            lib = path + <span class="string">"\\train\\"</span>+photo</span><br><span class="line">            savepath=path+<span class="string">"\\output\\"</span>+str(category)+<span class="string">"\\"</span>+str(category)+<span class="string">"+"</span>+str(num)+<span class="string">".jpg"</span></span><br><span class="line">            num+=<span class="number">1</span></span><br><span class="line">            start(lib,savepath,splited[<span class="number">0</span>],splited[<span class="number">1</span>])</span><br></pre></td></tr></table></figure></p><h2 id="将图片转化为对应的xml文件"><a href="#将图片转化为对应的xml文件" class="headerlink" title="将图片转化为对应的xml文件"></a>将图片转化为对应的xml文件</h2><p>默认的边框大小为整个图片的d、长度和宽度可以从图片中获取、最终批量的生成xml文件（突然想起比赛的图片切分后生成的30万个文件、还只能分批次的复制、一复制就卡屏、迷醉、、）<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os, sys</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"></span><br><span class="line"><span class="comment">#根据实际来添加class</span></span><br><span class="line">list=[<span class="string">"class1"</span>,<span class="string">"class2"</span>]</span><br><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> list:</span><br><span class="line">    path=os.getcwd()</span><br><span class="line">    <span class="comment">#图像存储位置</span></span><br><span class="line">    src_img_dir = path+<span class="string">"\\input2\\"</span>+a</span><br><span class="line">    <span class="comment"># xml文件存放位置</span></span><br><span class="line">    src_xml_dir = path+<span class="string">"\\input2\\"</span>+a</span><br><span class="line">    img_Lists = glob.glob(src_img_dir + <span class="string">'\*.jpg'</span>)</span><br><span class="line">    img_basenames = [] </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> img_Lists:</span><br><span class="line">        img_basenames.append(os.path.basename(item))</span><br><span class="line">    img_names = [] </span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> img_basenames:</span><br><span class="line">        temp1, temp2 = os.path.splitext(item)</span><br><span class="line">        img_names.append(temp1)</span><br><span class="line">    <span class="keyword">for</span> img <span class="keyword">in</span> img_names:</span><br><span class="line">        im = Image.open((src_img_dir + <span class="string">'/'</span> + img + <span class="string">'.jpg'</span>))</span><br><span class="line">        width, height = im.size</span><br><span class="line">        xml_file = open((src_xml_dir + <span class="string">'/'</span> + img + <span class="string">'.xml'</span>), <span class="string">'w'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'&lt;annotation&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;folder&gt;'</span>+a+<span class="string">'&lt;/folder&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;filename&gt;'</span> + str(img) + <span class="string">'.jpg'</span> + <span class="string">'&lt;/filename&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;path&gt;'</span> + path +<span class="string">"\\input2\\"</span>+a+<span class="string">"\\"</span>+ str(img) + <span class="string">'.jpg'</span>+ <span class="string">'&lt;/path&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;size&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;width&gt;'</span> + str(width) + <span class="string">'&lt;/width&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;height&gt;'</span> + str(height) + <span class="string">'&lt;/height&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;depth&gt;3&lt;/depth&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;/size&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;segmented&gt;0&lt;/segmented&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;object&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;name&gt;'</span> + str(img) + <span class="string">'&lt;/name&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;pose&gt;Unspecified&lt;/pose&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;truncated&gt;1&lt;/truncated&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;difficult&gt;0&lt;/difficult&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;bndbox&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;xmin&gt;'</span> + <span class="string">"0"</span> + <span class="string">'&lt;/xmin&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;ymin&gt;'</span> + <span class="string">"0"</span> + <span class="string">'&lt;/ymin&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;xmax&gt;'</span> + str(width) + <span class="string">'&lt;/xmax&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'            &lt;ymax&gt;'</span> + str(height) + <span class="string">'&lt;/ymax&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'        &lt;/bndbox&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'    &lt;/object&gt;\n'</span>)</span><br><span class="line">        xml_file.write(<span class="string">'&lt;/annotation&gt;'</span>)</span><br></pre></td></tr></table></figure></p><h2 id="xml转csv文件合并csv文件"><a href="#xml转csv文件合并csv文件" class="headerlink" title="xml转csv文件合并csv文件"></a>xml转csv文件合并csv文件</h2><p>要使用如下脚本将xml文件转化为csv文件、最后再把每个目录下的csv文件进行合并（注意删除重复的lable）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#xml转csv文件合并csv文件</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line">tag=[<span class="string">'class1'</span>,<span class="string">'class2'</span>]</span><br><span class="line">num=<span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">xml_to_csv</span><span class="params">(path)</span>:</span></span><br><span class="line">    xml_list = []</span><br><span class="line">    <span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(path + <span class="string">'/*.xml'</span>):</span><br><span class="line">        tree = ET.parse(xml_file)</span><br><span class="line">        root = tree.getroot()</span><br><span class="line">        <span class="keyword">for</span> member <span class="keyword">in</span> root.findall(<span class="string">'object'</span>):</span><br><span class="line">            value = (root.find(<span class="string">'filename'</span>).text,</span><br><span class="line">                     int(root.find(<span class="string">'size'</span>)[<span class="number">0</span>].text),</span><br><span class="line">                     int(root.find(<span class="string">'size'</span>)[<span class="number">1</span>].text),</span><br><span class="line">                     root.find(<span class="string">'folder'</span>).text,</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">0</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">1</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">2</span>].text),</span><br><span class="line">                     int(member[<span class="number">4</span>][<span class="number">3</span>].text)</span><br><span class="line">                     )</span><br><span class="line">            xml_list.append(value)</span><br><span class="line">    column_name = [<span class="string">'filename'</span>, <span class="string">'width'</span>, <span class="string">'height'</span>, <span class="string">'class'</span>, <span class="string">'xmin'</span>, <span class="string">'ymin'</span>, <span class="string">'xmax'</span>, <span class="string">'ymax'</span>]</span><br><span class="line">    xml_df = pd.DataFrame(xml_list, columns=column_name)</span><br><span class="line">    <span class="keyword">return</span> xml_df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> tag:</span><br><span class="line">        image_path = os.path.join(os.getcwd(), <span class="string">'input2\\'</span>+a)</span><br><span class="line">        xml_df = xml_to_csv(image_path)</span><br><span class="line">        xml_df.to_csv(<span class="string">'data\\'</span>+str(a)+<span class="string">'.csv'</span>,index=<span class="keyword">None</span>)</span><br><span class="line">        print(<span class="string">'Successfully converted xml to csv.'</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">main()</span><br></pre></td></tr></table></figure><p>通过shell批量合并csv<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">@echo off</span><br><span class="line">E:</span><br><span class="line">cd add</span><br><span class="line">dir</span><br><span class="line">copy *.csv all_keywords.csv</span><br><span class="line">echo 合并成功！'</span><br><span class="line">pause</span><br></pre></td></tr></table></figure></p><h2 id="调用object-detection前的准备"><a href="#调用object-detection前的准备" class="headerlink" title="调用object_detection前的准备"></a>调用object_detection前的准备</h2><p>下面是很有参考性的博客和官方的地址<br><a href="https://blog.csdn.net/honk2012/article/details/79099651" target="_blank" rel="noopener">https://blog.csdn.net/honk2012/article/details/79099651</a><br><a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md" target="_blank" rel="noopener">https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/installation.md</a><br>可以翻墙的话推荐下面这篇、这个towardsdatascience还是很不错的<br><a href="https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9" target="_blank" rel="noopener">https://towardsdatascience.com/how-to-train-your-own-object-detector-with-tensorflows-object-detector-api-bec72ecfe1d9</a><br>基本后面的训练和模型的调用都是在github上的、想普通的个人电脑用ssd的一个mobile就行了、别的根本跑不动、batch设置的越大每次迭代的时间越长、如果太大电脑配置不够的话你就可以重新开机了、、<br>顺便说说几个坑官方步骤中的 protoc object_detection/protos/*.proto –python_out=. 如果是在window下要下载3.4版本的3.5会有bug<br>object_detection初始化一定要先执行、不然会给你各种报错、、<br>官方文档中export PYTHONPATH=$PYTHONPATH:<code>pwd</code>:<code>pwd</code>/slim  如果是windows下执行要用这个命令(查了很久用了很多的坑爹方法、只能说项目对windows不友好)SET PYTHONPATH=%cd%;%cd%\slim  执行目录还是不变<br>注意这几个坑基本就会很顺畅了、还有一些其他小坑一时想不起来、想到了再加、</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;excerpt in=&quot;&quot; index=&quot;&quot; |=&quot;&quot; 首页摘要=&quot;&quot;&gt;&lt;br&gt;基于object_detection训练自己的模型&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://www.shadowerli.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="图像识别" scheme="https://www.shadowerli.com/tags/%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%AB/"/>
    
  </entry>
  
  <entry>
    <title>博客搬家</title>
    <link href="https://www.shadowerli.com/2018/03/23/2018-3-23/"/>
    <id>https://www.shadowerli.com/2018/03/23/2018-3-23/</id>
    <published>2018-03-22T16:00:00.000Z</published>
    <updated>2018-03-23T12:26:32.000Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>无意间看到了Hexo的这个黑蓝主题、实在是太cool了！！抽空用了两个晚上搬家<br><a id="more"></a><br>原来的博客一直是用的是jekyll(差点又拼错、)、还是很方便不过还是有很多弊端</excerpt></p><p>1、代码高亮、现在看看原来的博客这代码高亮、、简直无法直视、虽然后来另外装了插件但还是惨不忍睹(主要是这个主题的高亮真的是太漂亮了、看了会上瘾、、)<br>2、由于原来的博客用的是老外的主题为了实现想要的效果文字间的空格符有点受不了、十分影响美观、还有字体(这里支持一下国产、、)<br>3、这个主题有分类功能、随着博客的增多查找也比原来的方便、<br>4、也是主要原因、、就是想换、笑死、、、</p><p>现在终于换好了、过程也十分折腾、也遇到了各种坑、什么Hexo的版本问题、server要独立安装、、、希望这博客可以用几年吧、、同时再次感谢maochunguang提供的主题</p><p>前端真的是一个十分神奇的东西、、但真的没工夫投在上面学了、还有评论功能、看了大佬的主题demo觉得加了评论就不是十分洁简了、于是就不做了（绝不是因为懒）、、</p><p>最后注意我的背景:它是会变的哦、、、</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;excerpt in=&quot;&quot; index=&quot;&quot; |=&quot;&quot; 首页摘要=&quot;&quot;&gt;&lt;br&gt;无意间看到了Hexo的这个黑蓝主题、实在是太cool了！！抽空用了两个晚上搬家&lt;br&gt;
    
    </summary>
    
      <category term="other" scheme="https://www.shadowerli.com/categories/other/"/>
    
    
      <category term="other" scheme="https://www.shadowerli.com/tags/other/"/>
    
  </entry>
  
  <entry>
    <title>K-近邻算法Python实现</title>
    <link href="https://www.shadowerli.com/2018/01/30/2018-1-30/"/>
    <id>https://www.shadowerli.com/2018/01/30/2018-1-30/</id>
    <published>2018-01-29T16:00:00.000Z</published>
    <updated>2018-03-24T02:07:58.000Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>运用python通过计算距离来实现对某花的分类<br><a id="more"></a></excerpt></p><h2 id="算法解决的问题"><a href="#算法解决的问题" class="headerlink" title="算法解决的问题"></a>算法解决的问题</h2><p>已知样本集（此处的样本为某花的实例数据）、给定一未知样本的数据来断此样本的类别(此处为判断属于哪一类花）</p><h2 id="解决步骤"><a href="#解决步骤" class="headerlink" title="解决步骤"></a>解决步骤</h2><p>特征抽取后计算出未知样本到所有已知样本的距离、根据给定参数K（最好为奇数便于投票）选出K个最近的样本点、统计出类别最多的样本点的类别、最终的的分类就是该类别<br>缺陷：数据的分布不均匀会导致结果的不准确<br>优化方法：根据距离的远近添加相应的权重来弱化数据分布不均匀的为题（下面代码还没实现权重的添加、、以后有空再加、、、）<br>个人脑洞：对于多维的数据、在二维分布上可能看不出任何规律、但在高维的空间中明显的可以分开好几个类别（如本例的某花数据在三维下就很明显了、还有支持向量机的划分方法太cool了）<br>此处的样本集（非常nice的数据集大全）<br><a href="http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data</a><br>样本集示例：前四列为花的数据、最后为花的类别</p><p>5.1,3.5,1.4,0.2,Iris-setosa</p><p>5.0,3.3,1.4,0.2,Iris-setosa</p><p>7.0,3.2,4.7,1.4,Iris-versicolor</p><p>4.6,3.1,1.5,0.2,Iris-setosa</p><p>6.4,3.2,5.3,2.3,Iris-virginica</p><p>6.9,3.2,5.7,2.3,Iris-virginica</p><p>4.6,3.4,1.4,0.3,Iris-setosa</p><p>代码实现如下：用测试集测试可以达到96%的准确率</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"></span><br><span class="line"><span class="comment">#导入样本集list</span></span><br><span class="line"><span class="comment">#导入测试集计算测试集到每个样本集的距离,结果保存为list</span></span><br><span class="line"><span class="comment">#根据distance排名取k个投票选出最多的这个类</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#传递时要第二个参数要为空参否则会共用同一个地址</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readfile</span><span class="params">(local)</span>:</span></span><br><span class="line">    dataset=[]</span><br><span class="line">    <span class="keyword">with</span> open(local) <span class="keyword">as</span> file2:</span><br><span class="line">        csv_reader = csv.reader(file2)</span><br><span class="line">        <span class="keyword">for</span> line <span class="keyword">in</span> csv_reader:</span><br><span class="line">            dataset.append(line)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distance</span> <span class="params">(test,train)</span>:</span></span><br><span class="line">    result=<span class="number">0.0</span></span><br><span class="line">    <span class="comment">#此时每个test例如[1,2,3,4]每个train例如[1,2,3,4,a],-1除去标签</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span>  range(len(test)<span class="number">-1</span>):</span><br><span class="line">        result=result+math.sqrt(abs((float(test[i])-float(train[i]))*(float(test[i])+float(train[i]))))</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sort</span><span class="params">(train,test,k=<span class="number">3</span>)</span>:</span></span><br><span class="line">    result=[]</span><br><span class="line">    sortresult=[]</span><br><span class="line">    <span class="comment">#计算每个样本集到样本的距离</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(len(test)):</span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> range(len(train)):</span><br><span class="line">            <span class="comment">#对于每个测试实例得到距离和对应的标签</span></span><br><span class="line">            result.append([distance(test[i],train[m]),train[m][<span class="number">-1</span>]])</span><br><span class="line">        sortresult.append(findsort(result,k))<span class="comment">#得到每一个测试集的分类结果</span></span><br><span class="line">        result=[]                            <span class="comment">#将每个测试集的距离集合清空</span></span><br><span class="line">    <span class="keyword">return</span> sortresult       <span class="comment">#最终结果</span></span><br><span class="line">    <span class="comment">#得到结果集，每一个test到样本集的距离</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#示例输入[[3.917258917468777, 'Iris-setosa'], [4.365595716195167, 'Iris-setosa']]</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">findsort</span><span class="params">(data,k=<span class="number">3</span>)</span>:</span></span><br><span class="line">    result=&#123;&#125;</span><br><span class="line">    voat=[]</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> range(len(data)):</span><br><span class="line">            result.update(&#123;data[x][<span class="number">0</span>]:data[x][<span class="number">1</span>]&#125;)</span><br><span class="line">    <span class="comment">#对字典进行排序从小到大</span></span><br><span class="line">    a=sorted(result.items(), key=<span class="keyword">lambda</span> d: d[<span class="number">0</span>])</span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> range(k):</span><br><span class="line">         voat.append(a[m][<span class="number">-1</span>])</span><br><span class="line">    <span class="comment">#得到列表中出现次数最多的元素</span></span><br><span class="line">    b=Counter(voat).most_common(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> b[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算准确率</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">correct</span><span class="params">(sample,predict)</span>:</span></span><br><span class="line">    flag=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> range(len(sample)):</span><br><span class="line">        <span class="keyword">if</span>(sample[a]==predict[a]):</span><br><span class="line">            flag=flag+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> flag/len(sample)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    testlist=[]</span><br><span class="line">    train=list(readfile(<span class="string">"F:\\train.csv"</span>))</span><br><span class="line">    test=list(readfile(<span class="string">"F:\\test.csv"</span>))</span><br><span class="line">    <span class="comment">#k为最近邻的个数</span></span><br><span class="line">    output=sort(train,test,<span class="number">3</span>)</span><br><span class="line">    <span class="comment">#得到分类的结果集</span></span><br><span class="line">    print(output)</span><br><span class="line">    <span class="keyword">for</span> a <span class="keyword">in</span> range(len(test)):</span><br><span class="line">        testlist.append(test[a][<span class="number">-1</span>])</span><br><span class="line">    <span class="comment">#输出准确率</span></span><br><span class="line">    print(correct(testlist,output))</span><br><span class="line">main()</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;excerpt in=&quot;&quot; index=&quot;&quot; |=&quot;&quot; 首页摘要=&quot;&quot;&gt;&lt;br&gt;运用python通过计算距离来实现对某花的分类&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://www.shadowerli.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="python" scheme="https://www.shadowerli.com/tags/python/"/>
    
  </entry>
  
  <entry>
    <title>基本神经网络</title>
    <link href="https://www.shadowerli.com/2017/12/10/2017-12-10/"/>
    <id>https://www.shadowerli.com/2017/12/10/2017-12-10/</id>
    <published>2017-12-09T16:00:00.000Z</published>
    <updated>2018-12-11T13:39:34.000Z</updated>
    
    <content type="html"><![CDATA[<p><excerpt in="" index="" |="" 首页摘要=""><br>简单整理一下神经网络训练的步骤<br><a id="more"></a><br>总结一下最简单的神经网络的训练过程和原理<br>通常利用数据交叉验证来提高数据利用率<br><img src="http://aRootUser.github.io/img/2/1.jpg"><br>交叉验证：给定一个训练集和测试集，为了最大程度的利用测试集，可以将训练集分为若干份，这里为5。第一次将fold1(折)作为测试集其余的作为训练集，第二次将fold2作为测试集，其余的作为训练集，以此类推从而达到最大化利用数据更新权重的效果<br><img src="http://aRootUser.github.io/img/2/2.jpg"><br>对于输入的一张图片简单将图片的输入像素点看成[1,4]的矩阵、输出层为[1,3],中间的权值为[4,3]的矩阵、和图中不同图中是左成矩阵、这里定义的是右乘矩阵、没有定义中间层、最后还要加上[1,3]偏置值得到[1,3]的输出值每一个值代表某一类别的得分、<br><img src="http://aRootUser.github.io/img/2/3.jpg"><br>为了更好的定以中间权值定义的好坏以及预测结果的准确程度、用损失函数来衡量、损失函数最小表示预测越准确、这里定义的是svm损失函数、<br>l 表示自己定义的可容忍的长度<br>yi表示正确类别的得分<br>j表示其他类别的得分<br>通过计算每个其他类别减去正确类别的得分的最大值的求和来表是损失函数的结果对于多个输入例如输入100张图片还要除去100相当于取平均值<br><img src="http://aRootUser.github.io/img/2/4.jpg"><br>为了防止权值为0从而导致输入样本的每一个值没有被充分利用例如训练得到的两个权值<br>设输入的样本为[1,1,1,1]<br>权重W1[0.5,0.5,0.5,0.5]<br>权重W2[1,0,0,0]<br>矩阵相乘后得到的结果相同但是w2由于有三个0没有充分利用每一项所以添加w的平方项来惩罚权重为w2的情况、使其损失值变大<br><img src="http://aRootUser.github.io/img/2/5.jpg"><br><img src="http://aRootUser.github.io/img/2/6.jpg"><br>分类器的作用将输出的值通过sigmoid函数映射到0至1的区间上、e的x次幂进行放大、最后通过取其作为正确类别的概率取负对数得最终其对应的损失值(因为概率越大越输出的损失值越小)<br>前向传播：从输入的x一直到计算出loss、通过梯度下降算法找到一个下降方向、最终找到最低点、训练的批次数一般为2的整数次幂<br>一个Epoch表示迭代完所有数据、一个迭代表示跑完当前的一个batch</excerpt></p><h2 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h2><p>每次训练跟新权重的变化要乘一个学习率来调整权值变化的大小、过大会错过最优解</p><h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><p>通过计算出每一个权重对最终的loss值的影响来调整权重的大小(向前传播的逆向求解)</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>对神经元的输出进行去线性化、例如sigmoid函数(由于当x过大时很容易导致梯度消失使其无法求导进行反向传播、现在一般用relu激活函数并且求导简单）</p><h2 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h2><p>drop-out进行处理通过迭代来弥补神经网络的复杂度</p><h2 id="过程小结"><a href="#过程小结" class="headerlink" title="过程小结"></a>过程小结</h2><p>首先输入训练集如手写数字集、定义神经网络后、通过向前传播得到对每一个类别的输出、通过sortmax函数将输出转化为概率分布、通过与标签进行如下运算个（标签是one-hot概率）、将输出的概率分布取对数与标签值乘积在做平均值求和最后取负数-tf.reduce_sum(y_*tf.log(y))、得到交叉熵来反应结果集与标签的相似度、最后通过梯度下降法不断训练使交叉熵最小、来优化权重参数、</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;excerpt in=&quot;&quot; index=&quot;&quot; |=&quot;&quot; 首页摘要=&quot;&quot;&gt;&lt;br&gt;简单整理一下神经网络训练的步骤&lt;br&gt;
    
    </summary>
    
      <category term="机器学习" scheme="https://www.shadowerli.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
      <category term="机器学习" scheme="https://www.shadowerli.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
</feed>
